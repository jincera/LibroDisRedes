[["index.html", "Diseño y Arquitectura de Redes Presentación", " Diseño y Arquitectura de Redes José Incera Noviembre, 2022 Presentación Este documento contiene el material de apoyo para el curso Diseño y Arquitectura de Redes que se imparte en el Instituto Tecnológico Autónomo de México. La estructura del material en la primera parte sigue básicamente la propuesta de diseño descendente presentada por Priscilla Oppenheimer1 la cual ha sido ampliada y complementada con otras referencias bibliográficas, y a partir de nuestra propia experiencia profesional. En la segunda parte se presentan algunas tecnologías para el diseño de redes de acceso y de transporte. También se introducen nuevas tecnologías de redes definidas por software. En la tercera parte se presenta material para analizar la viabilidad financiera de un proyecto de redes. El material ha sido integrado a lo largo de varios años de impartir estas materias en los niveles de licenciatura, maestría y diplomado. En él han participado varios profesores, entre los que cabe destacar: Dr. Uciel Fragoso, Dr. José A. Incera, Dr. Marcelo Mejía, Mtro. Javier Salido y Mtro. Enrique Weitzel. Este libro ha sido escrito en RMarkdown empleando el paquete bookdown. Oppenheimer, P., Top-Down Network Design, 2nd Ed., Cisco Press, 2004, ISBN: 1587051524 "],["metodología-de-diseño-de-redes.html", "Capítulo 1 Metodología de diseño de redes 1.1 Introducción 1.2 Diseño descendente 1.3 Microsoft Solutions Framework 1.4 Análisis de riesgos 1.5 Problemas", " Capítulo 1 Metodología de diseño de redes 1.1 Introducción Es impresionante constatar la gran cantidad de redes que han sido implementadas de manera empírica y reactiva: reaccionando a las demandas inmediatas de los usuarios sin tomar el tiempo necesario para hacer una buena planeación de la misma con base en las necesidades reales de la empresa. La mayoría de estas redes están destinadas al fracaso conforme exceden una mínima complejidad: no fueron dimensionadas adecuadamente; no se contemplaron con anticipación aspectos fundamentales como la seguridad y la gestión de la red; no fueron previstos los requerimientos de escalabilidad a mediano plazo; etcétera. Es decir, este tipo de redes no fueron planificadas y por consiguiente las demandas de los usuarios tarde o temprano terminarán por exceder sus capacidades. Inspirados en las palabras de Dwigth D. Eisenhower: Nunca una batalla se ganó de acuerdo con el plan. Pero jamás una batalla se ganó sin un plan, el objetivo principal de esta obra es presentar una metodología que facilite el diseño de redes eficientes. Esta metodología, basada en un diseño descendente, permite planear los requerimientos de la red a partir de los requerimientos de negocio de las aplicaciones y usuarios de la red. Lo que se busca es proporcionar un marco operativo para hacer frente a la batalla permanente en la que se encontrará enfrentada la red debido a los factores tan dinámicos en los que ésta se verá inmersa (cambio tecnológico, nuevas aplicaciones, escenarios cambiantes de negocio y de usuarios, etc.). ¿Por qué una empresa desea una red? Prácticamente todas les redes de interés no son triviales y fueron creadas para soportar las necesidades de una empresa u organización. Antes de presentar formalmente la metodología propuesta, conviene reconocer algunas razones que pueden motivar el despliegue de la infraestructura de red, como por ejemplo: Satisfacer las necesidades de los clientes; mejorar la comunicación interna y externa; reducir el ciclo de diseño - fabricación - introducción al mercado; incrementar la productividad y reducir los costos de operación; responder con agilidad a las condiciones cambiantes del mercado. Es claro que la empresa no busca como objetivo el tener la red más avanzada tecnológicamente hablando, sino que desea alcanzar uno o varios objetivos de negocio específicos. Por ello: El mejor diseño NO es aquel que es tecnológicamente más avanzado, o el que aparece más elegante y eficiente desde el punto de vista de ingeniería. El mejor diseño es aquel que apoya con efectividad a la consecución de los objetivos de negocio y que, además, hace a la red invisible ante los ojos del usuario final. Fracasos en proyectos de tecnología de información Desde 1994, la consultora The Standish Group International ha venido realizando diversos estudios (conocidos como los reportes CHAOS) sobre la calidad de los proyectos de desarrollo de software en los Estados Unidos. La figura 1.1 presenta cómo han evolucionado estos reportes de 1994 a 2009. Figura 1.1: Resolución de proyectos de desarrollo de software. Fuente: Política digital, con base en los estudios de The Standish Group Aunque la encuesta se orientaba principalmente a proyectos de software, es bastante representativa de lo que ocurre con los proyectos de tecnología de información (TI) en general, incluidos los proyectos de infraestructura (redes, migraciones, etcétera). Generalmente, un proyecto cambiado se excedió en tiempo, en recursos, o no cumplió con sus especificaciones. Se puede observar que apenas poco más de la cuarta parte de los proyectos de TI cubre con sus expectativas iniciales. Otra encuesta indica que 53% de los proyectos de tecnología en realizados en el Reino Unido en 1999 costaron en promedio 189% más de lo originalmente estipulado. La figura 1.2 presenta algunas de las principales causas que llevan a la anulación o cambio de proyectos, de acuerdo a lo reportado por las empresas en el estudio CHAOS de 1994. Estudios subsecuentes reflejan resultados similares. Figura 1.2: Principales razones por las que un proyecto fue anulado o modificado. Fuente: The Standish Group, 1994 Como puede observarse, casi el 13% de los proyectos de TI falla porque los requerimientos no fueron suficientes. Esto no necesariamente significa que el cliente o el usuario no los haya proporcionado. En muchas ocasiones, el responsable del proyecto no los solicitó, no los entendió, o no los interpretó adecuadamente. Todos los elementos identificados en la figura 1.2 han ocurrido y ocurren regularmente en proyectos de diseño y construcción de redes y sus servicios correspondientes. Todos ellos deben ser considerados riesgos potenciales de cualquier proyecto. Sortear los escollos que imponen estos riesgos requiere de orden, método y disciplina. 1.2 Diseño descendente La figura 1.3 presenta el método de diseño llamado descendente, en el cual se estructura el contenido de estas notas. Figura 1.3: El método de diseño descendente El método inicia con un esfuerzo enfocado a comprender los objetivos de negocio de la organización que necesita la red, y de ahí a comprender los objetivos específicos que se deben fijar en términos de calidad y variedad de servicios a ofrecer. Con estos elementos, se podrán identificar las aplicaciones capaces de proporcionar los servicios necesarios y las implicaciones e impacto que dichas aplicaciones tendrán sobre la red que las soporta. La identificación de las aplicaciones y sus características permite establecer los requerimientos con los que se realiza el diseño de la red, partiendo de los servicios que debe ofrecer a los usuarios (capas superiores), y aumentando el nivel de detalle hasta llegar al diseño físico con la selección de tecnologías y equipos específicos. Como todo proceso de diseño, este método es iterativo y es consistente con el ciclo de vida de un proyecto de desarrollo de red, el cual se muestra en la figura 1.4. Figura 1.4: El ciclo de vida de un proyecto de red Si bien estas notas se centran en las dos primeras fases del ciclo de vida, y principalmente en la de diseño, las fases no son independientes. Por ejemplo, en el capítulo @ref(cap:dislog) se mostrará que durante el diseño lógico de la red se definen políticas de administración y monitoreo con las que se validará la red de producción. El proceso es continuo. Una vez que los parámetros monitoreados indican que la red es insuficiente, o cuando los requerimientos cambian, se reinicia el ciclo. 1.3 Microsoft Solutions Framework El diseño descendente es la metodología propuesta para realizar un proyecto de diseño de redes. También es necesario identificar una estrategia, una forma de trabajo que permita controlar de forma adecuada el desarrollo del proyecto. La que se presentará brevemente en este capítulo es la conocida como los Principios de Desarrollo de Infraestructura del Marco de Soluciones de Microsoft (Microsoft Solutions Framework, MSF). Microsoft Solutions Framework es un conjunto de principios y procesos que resume las mejores prácticas en proyectos de TI. Es una disciplina de trabajo, no una metodología, que ayuda a estructurar el proceso, el equipo de trabajo y la administración de riesgos en proyectos de alta tecnología. Los Principios de Desarrollo de Infraestructura son el componente de MSF que se enfoca a proyectos de infraestructura de TI, más que a proyectos de desarrollo de software. Para MSF, los cuatro componentes principales de un proyecto de diseño de redes se muestran en la figura 1.5 y son: Figura 1.5: Componentes de MSF para el desarrollo de un proyecto de TI El modelo de equipo. Explica cuáles son los principales roles y funciones que deben ser cubiertos en el proceso de organizar y estructurar nuestro equipo de trabajo. El modelo de proceso. Explica cuáles son las diferentes fases del proyecto y sobre qué aspectos debe hacerse énfasis en cada proyecto. El diseño de red. Señala, desde un punto de vista técnico, cuáles son los pasos a seguir y qué variables deben ser consideradas en el proceso de análisis y diseño de la red. El análisis de riesgos. Explica cómo se pueden detectar y evaluar los diferentes tipos de riesgo que afectan al proyecto y el tratamiento que se les debe dar con objeto de evitar que se materialicen o, si es imposible evitarlos, cómo aminorar sus efectos lo más posible. Podría decirse que el modelo de diseño descendente explica los pasos a seguir para completar el diseño de una red mientras que los Principios de Desarrollo de Infraestructura explican cómo organizar los otros tres componentes y cómo mantener balanceado el triángulo de variables a gestionar: Recursos (humanos y materiales) para realizar el proyecto; funciones que habrá de ofrecer la red y sistemas asociados; calendario que deberá cumplirse para llevar el proyecto al éxito. La base de ese triángulo es la calidad. Estos tres componentes deben estar bien apuntalados con el fin de mantener equilibrado el triángulo de calidad. MSF reconoce que en los proyectos tecnológicos actuales existe una gran cantidad de riesgos propios de la naturaleza cambiante de las mismas tecnologías, así como de su utilización en condiciones diferentes a aquellas para las que fueron desarrolladas. MSF hace énfasis en identificar y comprender los riesgos que amenazan al proyecto para poder trabajar en su control y mitigación y finalmente busca facilitar la división de la visión en porciones o versiones con alcances intermedios y realistas.       1.3.1 Modelo de proceso Figura 1.6: Las cuatro fases del modelo de proceso de MSF para el desarrollo de infraestructura El modelo de proceso marca cuatro fases para todo proyecto: visión, planeación, desarrollo y despliegue. Cada una de ellas tiene un punto claro de cierre que va acompañado con un entregable específico. Este punto de cierre se representa por el diamante azul en la figura 1.6. Es muy importante que haya un acuerdo claro, y preferentemente firmado, por todos los jugadores al final de cada fase. Visión/Alcance. La primera fase busca establecer una Visión conjunta del proyecto, determinar el alcance del mismo y establecer en forma general las condiciones iniciales de que se dispone para el proyecto. Así mismo es importante entender los elementos básicos y objetivos de negocio generales de la organización que necesita la red. La palabra clave en esta fase es Escuchar. Planeación. La segunda fase busca caracterizar todos los aspectos importantes de la red y/o infraestructura ya existente, transformar los objetivos y alcances de negocio expresados en la fase anterior a requerimientos técnicos que habrán de ser cumplidos por el diseño que se elaborará en esta. La palabra clave en esta fase es Proponer. Desarrollo. La tercera fase busca evaluar y validar el diseño propuesto, evaluar las nuevas y diferentes tecnologías propuestas para integrar la solución y proponer los ajustes necesarios al diseño y planes propuestos en la fase anterior. Las pruebas se realizan primero a nivel individual para cada nueva tecnología, y posteriormente se realizan pruebas de integración y pilotos. Esta fase concluye con la liberación de la solución/diseño propuestos y las palabras clave son Analizar y Probar. Despliegue. La última fase es propiamente el despliegue e implementación de la solución de acuerdo con el diseño propuesto. Los elementos centrales a considerar en esta etapa son la logística y la comunicación con el cliente. La palabra clave para esta fase es Actuar. Para MSF es fundamental el concepto de desarrollo por versiones mostrado en la figura 1.7. Como se verá más adelante, para una primera versión se definen algunas de las especificaciones más importantes del proyecto con las cuales se realiza una primera iteración en el modelo de proceso. Figura 1.7: En MSF el proyecto va creciendo en funcionalidad en distintas versiones Para una nueva iteración se incorporan las especificaciones que habían quedado fuera junto con las solicitudes adicionales del cliente y de los usuarios que se han ido recabando. Estos requerimientos se evalúan a la luz del triángulo de recursos y calidad para elegir los requerimientos con los que se realizará la nueva iteración, dejando los demás para versiones futuras. El diseño por versiones es conveniente para el desarrollador con el fin de minimizar los riesgos y mantener el control sobre el proyecto. También es conveniente para el cliente pues en proyectos de TI, es común que el usuario identifique con mayor claridad lo que realmente desea y necesita conforme empieza trabajando con el nuevo producto.       1.3.1.1 Fase I: Visión y alcance. (Escuchar) Figura 1.8: La fase de visión/alcance de MSF y sus entregables Es conveniente recordar que ninguna empresa diseña y construye redes porque desea tener la tecnología más novedosa. Las organizaciones suelen, o al menos debieran, tener objetivos claros y específicos sobre lo que quieren lograr o facilitar con la construcción de una red de comunicaciones, como de cualquier otro proyecto de tecnología de información. Lo que las empresas buscan con la red es alcanzar uno o varios objetivos de negocio. El proyecto tendrá éxito en la medida en la que esto se comprenda. Lo primero que debe conseguirse en esta fase, es el establecimiento de una Visión única de lo que se desea lograr. La Visión es la imagen que se forman y comparten todos los involucrados sobre lo que el proyecto les permitirá hacer cuando esté terminado. Una visión puede ser demasiado extensa y concebida en el largo plazo, en cuyo caso es conveniente descomponerla en partes más pequeñas llamadas versiones, que permitirán tener un acercamiento gradual y ordenado hacia la visión final. Es importante explicar desde el principio el concepto de desarrollo por versiones a clientes y usuarios, de manera que se puedan asignar prioridades a las especificaciones y se eviten expectativas no realistas en las primeras versiones del proyecto. Por ello es necesario definir el alcance inmediato del proyecto, es decir, hasta dónde llegará la versión actual en la que se estará trabajando, en su camino a la consecución de la visión. La mejor manera de lograr esto es definiendo un número limitado de objetivos claros y concretos, como se verá más adelante. De la figura 1.2 se infiere que el no definir los objetivos con precisión, puede tener un efecto devastador para el proyecto. Por ello, es fundamental escuchar y entender claramente las necesidades de los usuarios y de sus aplicaciones. Es importante también identificar lo que suele llamarse la cultura tecnológica reinante dentro de la empresa (tecnologías dominantes, experiencia de los usuarios y administradores, acuerdos de negocio predefinidos) y su cultura social (estructura jerárquica, grupos dominantes, apertura de comunicación, flexibilidad al cambio, etc.).    La Visión La visión es primordialmente un documento de negocios, escrito para una audiencia de negocios, por lo que se debe evitar utilizar un lenguaje demasiado técnico y, sobre todo, pensar en tecnologías específicas en esta fase. Si bien es cierto que un proyecto de diseño de red es eminentemente tecnológico y que el impacto sobre el negocio es principalmente indirecto, es extremadamente importante que la visión y los objetivos estén especificados en un lenguaje que pueda ser entendido por el cliente, y que este se sienta identificado tanto con la visión como con los objetivos. Es fundamental establecer una visión conjunta, que sea enunciada por el cliente, y que los integrantes del proyecto entiendan y compartan. Una visión que entienda que una red está al servicio del negocio. Nunca al revés. La visión es la traducción a palabras de cómo será el ambiente ideal que habrá de traer la solución. El tener una visión y objetivos compartidos proporciona una serie de beneficios a todos los involucrados, entre los que se pueden destacar: compromiso de todo el equipo para lograr los objetivos y así avanzar hacia la visión; ayuda a todos los miembros del equipo a dirigir sus esfuerzos hacia el mismo objetivo; evita posibles conflictos futuros; ayuda al equipo a identificar y aplicar los recursos de manera apropiada; le da identidad al equipo; motiva al equipo.    El alcance Una vez obtenida la visión, se procede a establecer el alcance de ESTA versión pues es probable que la visión sea demasiado amplia para poder ser lograda de una sola vez. Definir los alcances para la versión particular que se está especificando, permite mapear la visión contra la realidad actual. En este mapeo se debe tomar en cuenta aquello que el cliente considera indispensable para el éxito del proyecto. Esto permite acotar la versión actual a un número limitado de objetivos muy concretos y desplazar lo no esencial hacia versiones futuras. Para poder lograr esto es fundamental haber definido con el cliente una visión y objetivos compartidos. Sin este compromiso, el cliente bien podría tomar la posición de quererlo todo, quererlo bien, quererlo ahora: sin retardos sin costo para el usuario sin restricciones de protocolos ni de funcionalidad sin restricciones físicas ni lógicas sin errores acceso universal interconectividad entre redes facilidades de difusión Al recibir una lista como la anterior, es necesario cuestionar si el cliente realmente depende de esos requerimientos. Como se verá más adelante, este tipo de criterios puede entrar en serios conflictos con otros requerimientos de la red, lo cual puede comprometer todo el proyecto. Pero además, si no se han definido los alcances de manera conjunta, lo más probable es que los requerimientos del usuario sean vagos, incompletos, y, además, variarán durante el tiempo de vida del proyecto. La imagen y la comprensión común sobre lo que se va a hacer y los objetivos del proyecto tienen que estar totalmente claros, como también lo deben estar para el usuario las implicaciones de las decisiones que se toman en términos de restricciones futuras, costos y riesgos. Si hay algo que el cliente/usuario solicita y se considera que no se puede o que tiene implicaciones graves en términos de costo, tiempos, etc. este es el mejor momento para decirlo.      Be SMART Los objetivos de negocio y los criterios de éxito (que pueden ser los mismos), tienen que ser claros, acotados y limitados a no más de cinco, y preferentemente menos de tres. Pueden ser técnicos y de negocio, de preferencia una combinación de ambos. Vaguedades en la definición de cualquier objetivo puede conducir a no cubrir las expectativas del cliente, a no tener claro cuándo se ha cumplido (y por consiguiente a alargar el proyecto indefinidamente), y en general a situaciones que redundarán en la inconformidad y consiguiente insatisfacción del cliente. Al definir los objetivos de esta versión del proyecto, es muy importante que cumplan con los criterios SMART2: Specific.- Deben establecer claramente lo que se debe realizar (qué, quién, cuándo, cómo, por qué). Mesurable.- Deben ser determinados en términos cuantitativos, que puedan medirse para establecer si se está cumpliendo el objetivo. Achievable.- Deben ser realizables en esta versión del producto o en esta iteración del proyecto considerando las capacidades y restricciones impuestas. Realistic.- Debe tratarse de objetivos en los que se puede y se desea trabajar. Time-oriented.- Deben estar claramente especificados en un horizonte de tiempo realista. En muchas ocasiones es el cliente mismo quien no está interesado o dispuesto a establecer estos objetivos SMART. Las razones para esto pueden ser variadas, pero radican típicamente en el hecho de que el cliente mismo no tiene claro qué es lo que quiere o puede pedir. Es altamente recomendable trabajar con él para llegar a una definición precisa. La opción aquí es rechazar el proyecto, actitud por demás profesional y recomendable si la indefinición es extrema, o correr el riesgo de la insatisfacción final o de pérdidas económicas por no haber podido dimensionarlo apropiadamente.      Culminando la fase de visión/alcance El entregable en esta etapa es un documento muy completo de visión y alcance, el cual contiene típicamente: visión del negocio; objetivos de negocio y criterios de éxito definidos con características SMART; otra información de negocio; estructura corporativa a nivel macro o medio, según sea necesario; distribución geográfica de oficinas, personal y departamentos. Toda aquella información que permita posteriormente evaluar las necesidades de hoy y las posibles necesidades en términos de escalabilidad: ¿Cuánto espera el cliente crecer en el futuro y en dónde? identificar tipos de usuario, puede ser por departamento por función, rango, etc. En la siguiente fase se buscará entender cuáles son las necesidades de cada tipo de usuario; presupuesto; políticas y estándares corporativos relevantes; información técnica; requerimientos de seguridad. El documento de visión puede incluir la documentación concerniente a la red actual (si existe) y las minutas de las reuniones realizadas durante esta fase. Para poder integrar este documento de la mejor manera posible, es necesario recabar bastante información (la palabra clave aquí es escuchar). Un ejemplo del tipo de información a colectar en esta etapa es: uso que dará el usuario a la red, sin tener en cuenta cómo estará internamente implementada; tipo y número de usuarios y aplicaciones haciendo uso de la red; caracterización de aplicaciones; requerimientos geográficos; prioridades por aplicación o tipo de tráfico; interconexión a otras redes y a la Internet; expectativas de tiempo de acceso y respuesta; requerimientos de disponibilidad y confiabilidad; requerimientos de seguridad; holgura y capacidad para demanda futura de servicio; tarificación; restricciones presupuestales. Este documento permitirá iniciar con un diseño conceptual de la red. También permitirá identificar el orden en el que se responderá a los requerimientos de negocio, ayudará a cimentar el plan maestro y calendario de trabajo que serán definidos en la etapa siguiente, y dará una estimación de los recursos humanos, económicos y tecnológicos necesarios para completar el proyecto. Un buen documento para cerrar esta etapa deja sentadas las bases para traducir las necesidades y objetivos de negocios en él expresadas, a requerimientos técnicos3. Por otra parte, este documento debe reflejar claramente que se ha llegado a un acuerdo entre todos los involucrados acerca de los siguientes puntos: los objetivos de negocio; la visión del proyecto y el alcance de esta versión; el diseño conceptual de la solución propuesta; los entregables identificados; una idea general del orden de recursos necesarios; un plan para la siguiente fase; un documento de análisis de riesgos.       1.3.1.2 Fase II: Planeación. (Proponer) Figura 1.9: La fase de planeación de MSF y sus entregables En la primera fase del proyecto se enfatizó en comprender las necesidades y objetivos de negocio. Al hacerlo se fue aclarando el tipo de aplicaciones y servicios que se utilizarán y algunas de las restricciones impuestas por ellos, ya sea porque existan y se manifiesten antes del inicio del proyecto, o porque vayan a aparecer durante o después del mismo. En esta fase el resto de las restricciones impuestas por las aplicaciones y servicios deberán conocerse. Contando con esta información, se podrá avanzar en el diseño de las cuatro capas inferiores de la red. Se está aplicando el método descendente de diseño de redes al comenzar por las capas superiores (necesidades de negocio, aplicaciones y requerimientos) y con ello la funcionalidad y especificaciones necesarias para las capas más bajas se va aclarando. Es importante realizar un trabajo detallado y exhaustivo para comprender las implicaciones y restricciones impuestas por las necesidades y objetivos de negocio, así como las implicaciones y restricciones impuestas por las aplicaciones que se ejecutarán. Sin embargo, siempre existirá la posibilidad de que las aplicaciones se comporten de una manera diferente a lo esperado, por ejemplo, porque el nivel de carga es muy distinto a lo planeado, por cambios de versión, por especificaciones inexactas por parte del proveedor, etc. Por ello, se debe realizar un buen análisis de riesgos, para poder tomar decisiones apropiadas en lo que se refiere a garantizar calidad de servicio en las etapas iniciales, o inclusive posteriores al inicio de la operación del proyecto. Los entregables de esta fase están constituidos por borradores de los documentos individuales, pues el diseño no puede validarse sino hasta la siguiente fase, en la que se realiza una serie de pruebas de concepto. Es posible que esas pruebas generen cambios en el diseño propuesto. Una vez concluidas las pruebas necesarias en la Fase III, se procede a fijar el diseño y con ello el plan y el calendario maestros.      El proceso de diseño El proceso de diseño es iterativo y pasa por tres etapas, cada una agregando mayor nivel de detalle que la anterior. Diseño conceptual. El diseño conceptual ocurre durante la fase de Visión/Alcance y consiste en listar y entender los diferentes elementos de negocio que intervendrán en la solución final. Es decir, considerar y entender qué factores de organización de la compañía, distribución geográfica y características propias del negocio tendrán un impacto en el diseño de la red. Una vez conocidos estos elementos, se procede a elaborar un borrador o diseño inicial que se habrá de enfocar en representar la funcionalidad y distribución general requerida, incorporando poco o ningún detalle de tipo técnico. Este es un diseño que fácilmente podrán comprender las personas de áreas de negocios. Diseño lógico. Las siguientes etapas ocurren durante la fase de Planeación. Se realiza un primer plano técnico de la solución, sin incluir dimensionamientos, modelos ni configuraciones específicas. Diseño físico. Una vez que el diseño lógico está completo y se considera que cumple con los requisitos establecidos, se incrementa el nivel de detalle, agregando modelos, configuraciones y demás especificaciones, llegando con esto al máximo nivel de detalle posible en papel. Durante las etapas de diseño se habrán de ir integrando las tres componentes fundamentales del documento que termina esta etapa: Especificación funcional. Indica el qué debe hacerse. Plan maestro. Indica el cómo y con qué recursos la solución será desarrollada, evaluada y desplegada. Calendario maestro. Indica el cuándo se harán dichos desarrollos, evaluaciones y despliegues. Este documento debe ser considerado como un contrato entre las personas que desarrollan el proyecto, el cliente y usuarios. Es vital que haya un acuerdo claro en lo que se refiere a la funcionalidad esperada en esta versión del producto por todas las partes.    Especificación Funcional La especificación funcional es el documento de diseño propiamente, en el cual se incluyen los objetivos y requerimientos de negocio como fueron expresados en el documento de Visión/Alcance. De hecho, el documento de Visión/Alcance sirve por lo general como introducción a este documento. Para poder hacer una especificación funcional adecuada, es necesario recabar el máximo de información posible, por ejemplo: documento de visión/alcance; caracterización de la red (topología de red, flujos de información, características del tráfico); diseño de red: conceptual, lógico (requerimientos de seguridad, administración, QoS, etc.), y físico (selección de tecnologías, estándares, dispositivos, capacidades, protocolos, etcétera). La especificación funcional deberá proporcionar una indicación clara y concisa sobre cómo se cumplirá con los requerimientos de diseño y cómo se responderá a las necesidades de negocio. Si hay una limitante grave, hay que sacarla a la luz cuanto antes. También debe quedar claro de qué manera la solución propuesta se integra con los estándares y políticas corporativas. Durante la caracterización de la red, se obtendrá una definición completa de los perfiles de usuario y sus necesidades: se deberán detallar los tipos de usuario definidos por las aplicaciones que utilizan; ¿Dónde se encuentran las aplicaciones y servicios a los que tendrán acceso?; ¿Quién necesita acceso remoto y desde dónde? También se deberán identificar los requerimientos técnicos y las limitaciones de las configuraciones resultantes, y cómo responderá el diseño a los mismos. Se deberán especificar los requerimientos mínimos de hardware, software y de comunicaciones para la solución propuesta. Desde la especificación funcional se define la estrategia de administración y monitoreo: se seleccionan los métodos para recolección periódica de información; se identifican signos vitales de la red; se empiezan a documentar los procesos o pasos a seguir en caso de detectar diversas fallas en la red; se especifican los métodos de escalamiento, los reportes de fallas a proveedores de productos y servicios; se delinea la implementación de una mesa de ayuda, si ésta no existe. Los siguientes son algunos de los riesgos más importantes que deben evitarse al documentar la especificación funcional: falta de detalle que impida hacer las pruebas y/o despliegue apropiados; diseño demasiado costoso para ser implementado; demasiada información innecesaria; congelar el diseño antes de tener la información apropiada; especificación incompleta al momento de iniciar los trabajos finales.    Plan maestro El plan maestro enuncia la secuencia de tareas y actividades que habrán de realizarse e indica quién es el responsable de cada una y quiénes participan. Esto es muy importante ya que de otra manera se dejará abierta la puerta a todo tipo de riesgos y malentendidos. En el borrador del plan maestro se detalla la estrategia de pruebas y el plan piloto así como el plan y la estrategia de despliegue. Esta información permitirá dar una estimación de los recursos humanos, económicos y tecnológicos necesarios para completar el proyecto. También deberá incluir un plan de capacitación a personal técnico y a usuarios, así como una estrategia de comunicación entre los participantes. Finalmente, se debe especificar el presupuesto disponible junto con el plan de flujo financiero y de adquisiciones.    Calendario maestro El calendario maestro indica las fechas en las que se realizarán las diferentes actividades. En él debe especificarse la secuencia y duración de todas las actividades antes señaladas. Es común y recomendable que se trate de diseñar un calendario maestro que permita incluir el llamado tiempo buffer para manejar la incertidumbre. Bajo este esquema, se consideran dos fechas objetivo: una interna (fecha real) y otra externa, para el cliente. Como se observa en la figura 1.10, la diferencia entre la fecha objetivo interna y la externa es el tiempo buffer. Figura 1.10: Buffer interno para manejar la incertidumbre Esta es una práctica sana, siempre y cuando no se abuse de la misma. Como los proyectos de TI involucran una gran cantidad de variables que pueden modificar tiempo y resultados, es conveniente que el administrador del proyecto mantenga tiempos de reserva que puedan ser utilizados para cubrir los imprevistos. Dicho margen o buffer está bajo su control y se utiliza para emergencias. Es muy importante subrayar que el análisis, el diseño y las pruebas deben realizarse en forma completa, de tal manera que la especificación funcional, el plan maestro y el calendario maestro se basen en información concreta y lo más realista posible, en hechos. Los buffers de tiempo mencionados aquí serán insuficientes si se utilizan como margen de error para un proyecto mal diseñado.    Culminando la fase de planeación Para finalizar la fase de planeación es necesario que el diseño esté concluido en su totalidad. Se debe contar con un acuerdo grupal sobre los elementos desarrollados durante la planeación: especificación funcional, plan maestro, calendario maestro y una nueva iteración del análisis de riesgos.       1.3.1.3 Fase III: Desarrollo. (Analizar y probar) Figura 1.11: La fase de desarrollo de MSF y sus entregables El proceso de construir e integrar porciones de la solución para convertir la especificación en una solución completa es lo que se conoce como el desarrollo de la infraestructura. En esta fase se busca evaluar y validar el diseño, empezando por evaluar las nuevas tecnologías propuestas para integrar la solución y, eventualmente, proponer los ajustes necesarios al diseño original. Las pruebas se realizan de manera cíclica e incremental: pasando por las etapas de desarrollo, evaluación y validación contra los criterios de aceptación previamente definidos. Este ciclo se aplica a nivel individual, para cada nueva tecnología y posteriormente, para las pruebas de integración e implementación de los pilotos.    Validación de la tecnología Conforme se están validando las nuevas tecnologías seleccionadas, en esta etapa se van creando manuales de instalación y operación y otros documentos de apoyo (capacitación, bitácoras, etc.). Por lo tanto, la validación de tecnologías incluye realizar las actividades siguientes: analizar los criterios de selección de tecnologías, sobre todo si éstas son nuevas; instalar y configurar manualmente en condiciones ideales; documentar los pasos a seguir para que opere correctamente; comenzar a identificar y documentar pendientes y riesgos tecnológicos; actualizar el calendario de trabajo con base en los riesgos detectados. El desarrollar una campaña de pruebas es una tarea compleja que puede demandar muchos recursos (tiempo, equipo, personal) y que puede no arrojar los resultados esperados si no se hace correctamente. Por ello, es muy importante que se dedique el tiempo necesario para diseñar las pruebas en función de los objetivos que se persiguen. Algunos de los objetivos que deben quedar claros en esta etapa son: sacar a la luz todos los puntos que el equipo debe resolver; validar lo que se tiene contra la especificación funcional; realizar pruebas de regresión (cuando la solución falla o hace fallar algo en el ambiente de operación); determinar si la solución requiere componentes adicionales (controladores actualizados, librerías dinámicas, versiones específicas de ambientes operativos, etcétera). Es fundamental poder separar el ambiente de pruebas del de producción en las primeras etapas del proceso de evaluación: errores o problemas detectados con la solución evaluada no deben afectar a la red de producción. Esta etapa de la fase de desarrollo es conocida como de pruebas de preproducción y sus objetivos son los siguientes: probar tanto de la solución como sea posible, antes de integrar el piloto; evaluar resultados contra los objetivos y criterios de éxito; completar guías de instalación (checklists) y desarrollar procedimientos automatizados para ello (bitácoras, scripts, etcétera); desarrollar el material de capacitación completo; resolver pendientes y problemas de soporte. El automatizar en la medida de lo posible las tareas de instalación y validación es sumamente aconsejable, pues ello contribuye a disminuir tiempos y esfuerzo en la etapa de despliegue, reduce drásticamente los retardos debidos a errores humanos, proporciona lineamientos para diagnosticar y corregir problemas, y ayuda en la definición de procedimientos de respaldo y recuperación de desastres. Otros entregables que deben generarse al realizar las validaciones en esta etapa, están orientados al personal encargado de la operación de la red en producción e incluyen documentos que abarquen temas como: requerimientos especiales para mantenimiento de clientes, servidores y dispositivos de red; lineamientos para recuperación de desastres y reinstalación; monitoreo de fallas y parámetros de desempeño en operación normal; soporte y solución de problemas; procedimientos de respaldo.      Prueba de concepto Una vez que las herramientas individuales han sido evaluadas, la prueba de concepto consiste en validar la solución completa inmediatamente antes de integrarla a la red de producción. Específicamente, debe validarse que se cumple completamente con los requerimientos de diseño. Esto se hace generalmente junto con el cliente y/o personal que va a operar la red de manera cotidiana, y basándose en el plan de pruebas definido con anterioridad. Conforme se va integrando la prueba de concepto, se seguirán documentando los procesos de implementación, se desarrollarán mecanismos de automatización para la instalación y despliegue, se verificarán y complementarán las guías de instalación y se desarrollarán manuales de operación.      Prueba piloto El piloto es el momento en que se evalúa la solución dentro del ambiente de producción. Es una actividad muy importante pues valida la solución completa y su integración con los sistemas ya implementados. Además, se debe considerar al piloto como un proceso de entrenamiento hacia la fase de despliegue que permite verificar que todo lo que se ha hecho durante la fase de desarrollo está correcto y completo: procesos de instalación y automatización; identificar pendientes y darles seguimiento; realizar y probar planes de recuperación; checklist de preparación del sitio; materiales de capacitación para el usuario y para los administradores de la red. Implementar y activar el piloto puede tener serias consecuencias en la operación de los sistemas y dispositivos en la red de producción, por lo que debe haber una muy buena planeación, manteniendo una estrecha comunicación con todos los involucrados. Por ejemplo, se deberá: asegurar que se tiene el soporte técnico y los recursos necesarios para instalar y activar el piloto (identificación y acceso a los locales donde se llevará a cabo la instalación; disponibilidad de espacio, de energía eléctrica, de direcciones de red, de posibles contraseñas para acceder y configurar equipo, etcétera); identificar a usuarios del piloto, comunicarse con ellos y asegurar que existe un proceso de retroalimentación por su parte; encontrar horarios fuera y dentro de horas laborales para llevar a cabo distintos tipos de evaluación (desempeño, interoperabilidad, estrés, etcétera); prevenir a los usuarios de posibles degradaciones en la calidad de servicio durante la fase de evaluación.      Culminando la fase de desarrollo Al terminar esta fase ya no puede haber cambios en el diseño. Debe existir un acuerdo sobre las tecnologías empleadas, el plan y documentación para apoyar la capacitación de usuarios y administradores y sobre las actualizaciones al plan maestro y al calendario maestro del proyecto. Los entregables de esta fase son todos los documentos desarrollados a lo largo de las evaluaciones: material de capacitación, estrategias para el proceso de despliegue, procedimientos automatizados de instalación, checklists para configuración e instalación, guías para el personal de operaciones; etcétera.       1.3.1.4 Fase IV: Despliegue. (Actuar) Figura 1.12: La fase de despliegue de MSF y sus entregables En la última fase se lleva a cabo el despliegue e implementación de la solución de acuerdo con el diseño propuesto y se cierra el proyecto. Básicamente existen dos estrategias: despliegue en serie, en donde se parte implementando el núcleo de la red y se van agregando sitios de acuerdo a su orden de importancia, y despliegue en paralelo en el que todos los sitios se van implementando más o menos al mismo tiempo. Con la estrategia de despliegue en serie se reduce el riesgo del proyecto, la necesidad de personal especializado y la erogación de recursos. Sin embargo, aumenta el tiempo de liberación de la solución completa. La decisión dependerá, en realidad, de las características del proyecto y de los recursos disponibles. En cualquier caso, el despliegue de un sitio pasa básicamente por las mismas etapas, que son: Preparación del sitio. Se valida información obtenida a lo largo del proyecto, se realiza el plan de despliegue para el sitio y se notifica a los usuarios sobre el calendario y las perturbaciones posibles que sufrirán. Instalación de la solución. Al igual que en la etapa de desarrollo, se debe tener una estrecha comunicación con los administradores de la red para garantizar que se dispone de los recursos físicos y lógicos para llevar a cabo la instalación. Capacitación del personal. En función de los objetivos y alcances del proyecto, el plan de capacitación puede incluir a los administradores y operadores de la red, a los encargados de la mesa de ayuda, y a los usuarios finales. Estabilización. Es importante que el sistema quede estabilizado cuando aún está presente el personal responsable del diseño y se está migrando la gestión del mismo al personal de operaciones. Esta transición debería incluir la activación del sistema de reportes (mesa de ayuda), la creación de bitácoras de fallas, estrategia de solución y análisis de tendencias que permita la creación de una base de conocimiento. La etapa de estabilización termina con la aceptación final.      Culminando la fase de despliegue Una vez que se ha liberado y estabilizado el proyecto, se obtendrá la aceptación final por parte del cliente, pero para el equipo de trabajo el proyecto no ha terminado pues debe hacerse una revisión de las experiencias adquiridas a lo largo del desarrollo del proyecto que permita plasmar en un reporte final las consideraciones a tomar en cuenta para proyectos futuros similares al recién liberado.       1.4 Análisis de riesgos El análisis de riesgos es una actividad fundamental en toda metodología formal de administración de proyectos. Para MSF, se trata de uno de los cuatro componentes fundamentales y constituye una actividad continua a todo lo largo del modelo de proceso. Tiene por objetivo identificar las fuentes principales de riesgos, sus implicaciones y la forma en la que estos pueden ser controlados. Los riesgos son peligros que se presentan y amenazan el éxito del proyecto; su identificación es algo completamente deseable y su solución y mitigación es responsabilidad del equipo entero. Al identificar el riesgo global del proyecto se busca determinar cuáles son las implicaciones si el proyecto falla completamente o si no corresponde a las expectativas. Hay que empezar por establecer si el proyecto es crítico para la operación de la empresa. También es importante conocer el nivel de visibilidad y repercusión del proyecto: ¿El éxito (o fracaso) del proyecto es visible por otras áreas? ¿Por las áreas directivas? ¿Por los clientes? La respuesta a estas preguntas puede influir de manera importante en los criterios de diseño a emplear. Los riesgos se pueden originar de las más diversas fuentes, entre las más evidentes se pueden citar: definición imprecisa de visión, objetivos y restricciones; nivel de motivación en la decisión o dirección de la organización; perfil y compromiso de clientes o usuarios; presupuesto, costo, calendario y recursos humanos; características del proyecto; ambiente y proceso de desarrollo e implementación; ambiente de operaciones; nuevas tecnologías. Las restricciones del proyecto son riesgos naturales que deben ser identificados. La siguiente lista muestra algunos aspectos que deben ser típicamente tomados en cuenta durante la fase de análisis de riesgos: restricciones presupuestales y gestión del mismo; adquisición de equipo, software, licencias, etcétera; contratación / capacitación de personal; agenda: ¿Existen agendas ocultas? ¿El proyecto ya se ha retrasado? ¿Se está retomando un proyecto que fue abandonado por otro grupo? ¿Por qué?; políticas y estrategias; existencia de grupos de poder: tomadores de decisiones vs. seguidores; implicaciones del proyecto: ¿A quién beneficia el éxito del proyecto? ¿Quién lo apoya? ¿Provoca despidos de personal? ¿Cambio de funciones y de roles?; alianzas y/o políticas de adquisición de equipo, estándares internos, etcétera; aspectos personales de todos los involucrados; actitud de la empresa: innovadora o conservadora tecnológicamente.      1.4.1 Manejo de Riesgos La identificación de riesgos en un proyecto es completamente inútil si no se dan inmediatamente los pasos necesarios para evitar el riesgo o para amortiguar su impacto. El proceso de manejo de riesgos es sumamente importante y debe ser tratado con la mayor seriedad y profesionalismo. Una estrategia para administración de riesgos se muestra en la figura 1.13 y se explica en los párrafos subsecuentes. Figura 1.13: Estrategia de gestión de riesgos Es muy importante que el proyecto involucre representantes de cada uno de los roles del modelo de equipo. Cada rol estará en posición de identificar y entender diferentes tipos de riesgo y de traerlos a la atención del resto del equipo. Una vez logrado esto y que los riesgos se han puesto por escrito, se procede a analizarlos, a tratar de evaluar la posibilidad de que dichos riesgos se materialicen y, en caso de que lo hagan, a evaluar el impacto que tendrían sobre el proyecto. Conociendo y entendiendo las probabilidades e implicaciones, es posible entonces proceder a la elaboración de un plan para eliminar el riesgo, o bien, para reducir la probabilidad de que ocurra. En los casos en que la probabilidad de ocurrencia no puede ser eliminada, se debe diseñar un plan de contingencia adecuado. El plan de atención a cada riesgo debe ser asignado a un propietario, que será la persona responsable de darle seguimiento y facilitar la ejecución del plan. El paso final en el proceso es la revisión o control de los riesgos en cartera, donde se determina si el riesgo ha sido eliminado, si la ejecución del plan de atención a ese riesgo en particular está todavía en curso, o si no se puede eliminar, pero los planes de contingencia están listos. Dependiendo del resultado el riesgo se elimina o se mantiene en la lista. El documento conteniendo la lista de riesgos vigentes debe ser revisado con la periodicidad necesaria, misma que sólo puede ser estimada por los integrantes del equipo. Existirán períodos del proyecto en donde la revisión tenga que ser diaria, y periodos en los que una revisión semanal sea suficiente. Es altamente recomendable mantener el documento de evaluación de riesgos y los planes relacionados en una escala manejable. Es decir, no se deben tener demasiados riesgos siendo atacados al mismo tiempo. Nuevamente, esto depende del tamaño y complejidad del proyecto. Como regla general se debe procurar no manejar más de diez riesgos al mismo tiempo. Una forma de superar esta limitante en proyectos grandes consiste en llevar un documento de análisis de riesgo por rol del modelo de equipo, o por equipos de trabajo dentro del proyecto. Sin embargo, es importante subrayar que deberá existir un documento principal que contenga la evaluación de riesgos globales del proyecto, el cual podrá contener algunos de los riesgos que están en documentos individuales, pero no todos ellos. Caso de estudio: Cuantificación del riesgo El siguiente caso de estudio tiene por objeto mostrar cómo cuantificar el nivel de riesgo de un proyecto de redes. Se trata de un proyecto de integración de servicios entre las tres ciudades más importantes de la República Mexicana4. Cierta empresa con cobertura nacional cuenta con dos redes superpuestas: Enlaces Frame Relay en varios puntos de la República para transporte de datos, y enlaces privados TDM para transporte de voz y datos. La empresa desea migrar hacia una única red WAN multiservicios. En una primera fase, se diseña la red dorsal formada por un triángulo con puntos de presencia en México, Guadalajara y Monterrey (ver figura 1.14. Figura 1.14: Red dorsal multiservicio entre las tres principales ciudades del país Una vez definido el diseño básico de la red y el plan de actividades, se llevó a cabo una revisión detallada del proyecto tratando de identificar posibles riesgos y su impacto. En la planeación de riesgos se deciden las tácticas de manejo que se utilizarán para disminuir cada uno y posteriormente se evalúa el nuevo impacto que podrían tener, una vez aplicadas dichas tácticas. El análisis de impacto y la planeación de riesgos se realizó en grupo y con ayuda de expertos. Cada riesgo se evaluó según su probabilidad de ocurrencia y su impacto en el proyecto. Estos criterios fueron calificados de la siguiente manera: Probabilidad de ocurrencia Impacto 1 Muy poco probable (0-20%) 1 Mínimo 2 Poco probable (20-40%) 2 Poco 3 Puede ocurrir (40-60%) 3 Moderado 4 Probable (60-80%) 4 Alto 5 Muy probable (80-100%) 5 Extremo Los riesgos asociados al proyecto y su evaluación se presentan en la siguiente tabla. Riesgo Descripción Probabilidad/Impacto (A) ENTORNO DE NEGOCIO A1 Fondos no asignados 1/5 A2 Proyecto no ha sido justificado 2/5 A3 Alta dirección no ha dado soporte 4/4 (B) ENTORNO DE PROYECTO B1 Objetivos no claros o no identificados 4/3 B2 Alcances incompletos o no definidos 5/3 B3 Estimados y costos no validados 4/3 B4 Criterios de aceptación no claros 3/4 B5 Mala comunicación 4/4 B6 Pérdida de interés del patrocinador 2/4 (C) EL CLIENTE C1 No entiende un entorno de proyectos 2/3 C2 Sin autoridad para tomar decisiones 3/1 C3 Personal no participa en el proyecto 2/3 C4 Insiste en utilizar equipo obsoleto de su propiedad 3/4 C5 Tiempos largos de instalación en sitios remotos 3/4 C6 No permite acceso a instalaciones 2/3 C7 No tiene experiencia en proyectos similares 3/4 C8 No está comprometido con el proyecto 1/2 (D) EL USUARIO D1 No involucrado en def. requerimientos 2/2 D2 Demanda capacitación no factible 1/3 D3 No está involucrado 1/3 D4 No entiende el impacto 2/2 D5 No tiene experiencia en proyectos similares 2/3 D6 No entiende un entorno de proyectos 2/3 D7 No está comprometido con proy. 1/2 (E) LA SOLUCIÓN TÉCNICA E1 No ha sido realizada antes 2/3 E2 Basado en métodos o he-rramientas no probadas 3/3 E3 Se requiere de expertos para algunos equipos 2/4 (F) CALIDAD F1 Req. calidad no bien documentados 1/2 F2 Req. calidad no son entendidos 2/3 F3 No se asegura la calidad del proyecto 2/2 (G) PROVEEDORES Y OTROS REC. HUMANOS G1 No hay equipos en mercado local 4/4 G2 No hay proveedor de enlaces 1/4 G3 Proveedor inestable económicamente o en situación desconocida 1/5 G4 Tiempos de entrega muy prolongados 3/4 G5 Falla de enlaces contratados 1/4 G6 Falla de equipos entregados 1/5 G7 Personal no tiene conocimientos req. 3/4 G8 Personal especializado no disponible 2/4 G9 Huelgas y paros laborales 1/3 (H) ADMINISTRACIÓN DE PROYECTOS H1 Administrador de proyectos con experiencia no ha sido asignado 3/4 H2 Adm. proyectos no tiene experiencia en proyectos de esta magnitud 3/3 H3 No se cuenta con una metodología formal de administración de proyectos 1/4 (I) FACTORES EXTERNOS I1 Actos del gobierno 1/1 I2 Depreciación del tipo de cambio 2/3 I3 Cambios en el Mercado 1/3 I4 Legislaciones 1/3 Los riesgos se colocan en una matriz de impacto contra probabilidad: Para cada riesgo, se propone un plan de manejo. El énfasis se concentra en aquellos riesgos colocados en el cuadrante superior derecho de la matriz anterior. Se tratará de eliminarlos o de llevarlos al cuadrante inferior izquierdo. Los riesgos asociados al proyecto, su evaluación, el plan de manejo y su nueva evaluación si se aplica el plan, se presentan en la siguiente tabla. Riesgo Descripción Prob./Impacto Plan Nva. Eval. (A) ENTORNO DEL NEGOCIO A1 Fondos no asignados 1/5 Asume riesgo 1/5 A2 Proyecto no ha sido justificado 2/5 Identifica actores y justifica 1/5 A3 Alta dirección no ha dado soporte 4/4 Ajusta alcances p/obtener soporte 2/4 (B) ENTORNO DEL NEGOCIO B1 Objetivos no claros o no identificados 4/3 Clarifica con actores 2/2 B2 Alcances incompletos o no definidos 5/3 Completa y define 3/2 B3 Estimados y costos no validados 4/3 Valida con los actores 2/2 B4 Criterios de aceptación no claros 3/4 Explica criterios a los actores 1/2 B5 Mala comunicación 4/4 Establece y refuerza plan comunic. 2/2 B6 Pérdida de interés del patrocinador 2/4 Encuestas periódicas de satisfacción 2/3 (C) EL CLIENTE C1 No entiende un entorno de proyectos 2/3 Integra al cliente en el proyecto 1/2 C2 Sin autoridad para tomar decisiones 3/1 Asume riesgo 3/1 C3 Personal no participa en el proyecto 2/3 Asume riesgo 2/3 C4 Insiste en utilizar equipo obsoleto de su propiedad 3/4 Clarifica requerimientos; motiva y compromete para que acepte el cambio 2/4 C5 Tiempos largos de instalación en sitios remotos 3/4 Informar sobre la importancia de respetar calendario. Involucrar personal del cliente con responsabilidades 2/3 C6 No permite acceso a instalaciones 2/3 Establece horarios de acceso y controles por si surgen problemas 1/3 C7 No tiene experiencia en proyectos similares 3/4 Involucra más al cliente 1/2 C8 No está comprometido con el proyecto 1/2 Asume riesgo 1/2 (D) EL USUARIO D1 No involucrado en def. de requerimientos 2/2 Asume riesgo 2/2 D2 Demanda capacitación no factible 1/3 Asume riesgo 1/3 D3 No está involucrado 1/3 Asume riesgo 1/3 D4 No entiende el impacto 2/2 Asume riesgo 2/2 D5 No tiene experiencia en proyectos similares 2/3 Involúcralo más en el proyecto 2/1 D6 No entiende un entorno de proyectos 2/3 Involúcralo más en el proyecto 1/2 D7 No está comprometido con proy. 1/2 Asume riesgo 1/2 (E) LA SOLUCIÓN TÉCNICA E1 No ha sido realizada antes 2/3 Encontrar expertos para las áreas relevantes 2/1 E2 Basado en métodos o herramientas no probadas 3/3 Encontrar expertos para las áreas relevantes 3/1 E3 Se requiere de expertos para algunos equipos 2/4 Encontrar expertos para las áreas relevantes 2/2 (F) CALIDAD F1 Req. de calidad no bien documentados 1/2 Asume riesgo 1/2 F2 Req. de calidad no son entendidos 2/3 Aclara requerimientos a los actores 1/3 F3 No se asegura la calidad del proyecto 2/2 Asume riesgo 2/2 (G) PROVEEDORES Y OTROS REC. HUMANOS G1 No hay equipos en mercado local 4/4 Busca en otro mercado e importa 4/2 G2 No hay proveedor de enlaces 1/4 Busca otras soluciones: más enlaces de menor capacidad; otra tecnología; etc. 1/2 G3 Proveedor inestable económicamente o en situación desconocida 1/5 Busca proveedores secundarios; apalanca vía fianzas y seguros 1/3 G4 Tiempos de entrega muy prolongados 3/4 Estima tiempos en exceso 3/2 G5 Falla de enlaces contratados 1/4 Resuelve problema con proveedor; busca enlaces alternos 1/2 G6 Falla de equipos entregados 1/5 Resuelve problema o busca proveedor alterno con entregas rápidas 1/1 G7 Personal no tiene conocimientos requeridos 3/4 Capacita al personal 2/4 G8 Personal especializado no disponible 2/4 Contrata consultor experto; capacita 2/2 G9 Huelgas y paros laborales 1/3 Asume riesgo 1/3 (H) ADMINISTRACIÓN DE PROYECTOS H1 Administrador de proyectos con experiencia no ha sido asignado 3/4 Busca administrador con más experiencia 2/3 H2 Adm. proyectos no tiene experiencia en proyectos de esta magnitud 3/3 Busca administrador con más experiencia 1/3 H3 No se cuenta con una metodología formal de administración de proyectos 1/4 Implanta administrador y metodología 1/2 (I) FACTORES EXTERNOS I1 Actos del gobierno 1/1 Asume riesgo 1/1 I2 Depreciación del tipo de cambio 2/3 Asume riesgo 2/3 I3 Cambios en el Mercado 1/3 Asume riesgo 1/3 I4 Legislaciones 1/3 Asume riesgo 1/3 Con las re-evaluaciones se colocan nuevamente en la matriz de impacto contra probabilidad. Cada celda en la matriz recibe una ponderación reflejando el peso relativo de un impacto en esa celda. El factor de riesgo del proyecto, se deriva del promedio ponderado de los riesgos identificados. \\[\\text{Promedio ponderado} = \\frac{\\sum\\limits_{i=1}^5\\sum\\limits_{j=1}^5 n_{i,j}\\cdot p_{i,j}}{N}= 1.7,\\] donde \\(N\\) es el número de riesgos considerados y \\(n_{i,j}\\) los riesgos en la celda \\(\\{i,j\\}\\) la cual tiene un peso \\(p_{i,j}\\). El nivel de riesgo se asocia tomando como referencia una tabla como la siguiente: Riesgo del proyecto Rango Muy bajo 0 a 0.49 Bajo 0.5 a 1.49 Medio bajo 1.5 a 3.99 Medio 4.0 a 5.99 Medio alto 6.0 a 7.49 Alto 7.5 a 8.49 Muy alto 8.5 a 9.0 1.5 Problemas Problema 1.1 Describa brevemente en qué consiste el método descendente de diseño de redes visto en clase. Problema 1.2 Mencione tres de las principales razones por las que un proyecto de tecnología de información puede fallar. Problema 1.3 De acuerdo a los reportes CHAOS de The Standish Group las principales causas de fracaso en los proyectos de TI no tienen que ver con aspectos técnicos o de ingeniería. Explique brevemente esta afirmación. Problema 1.4 ¿Por qué es mejor realizar un proceso de diseño descendente y cuál es la condición esencial para iniciar el proceso? Problema 1.5 El modelo de proceso de MSF cuenta típicamente con cinco etapas: Visión, Planeación, Desarrollo, Estabilización y Despliegue ejecutadas en ese orden. Sin embargo, en la metodología presentada se siguieron únicamente cuatro de ellas. ¿Está usted de acuerdo con ello? ¿Por qué? Problema 1.6 ¿En qué consisten las fases del modelo de proceso propuesto por MSF? ¿Cuáles son los entregables en cada una de ellas? Problema 1.7 ¿Por qué es importante tener una visión clara y compartida, así como objetivos SMART en un proyecto MSF? Problema 1.8 . Nombre las etapas faltantes en el diagrama de ciclo de vida de un proyecto de red. Mencione dónde entra cada una de estas etapas en el modelo de proceso de MSF. Problema 1.9 De acuerdo al modelo de proceso de MSF, ¿Cuándo y dónde se determina el qué, cómo y cuándo de un proyecto de tecnología? Problema 1.10 Si varios requerimientos de diseño entraran en conflicto, ¿cómo se puede obtener una guía para definir el diseño de red más apropiado? Problema 1.11 Al proponer su modelo de proceso, Microsoft pretende integrar las mejores ideas de las populares metodologías de cascada y espiral de desarrollo de software. Explique brevemente en qué consiste esta afirmación. Problema 1.12 Se le contrata en una cadena de tiendas departamentales para desarrollar un proyecto cuyo objetivo es reducir los tiempos de respuesta del sistema en cajas para reducir el tiempo que deben esperar los clientes al pagar. De acuerdo a los lineamientos del modelo de proceso de MSF, ¿el planteamiento del objetivo es correcto? ¿Por qué? Problema 1.13 De acuerdo a la fase de desarrollo en el modelo de proceso de MSF, . ¿Qué es la prueba de concepto? ¿Qué es el piloto? ¿Qué consideraciones se deben tener en cuenta para pasar de la prueba de concepto al piloto? Problema 1.14 En las primeras etapas del modelo de proceso, se generan los borradores del plan maestro, del calendario maestro y de la especificación funcional. . ¿Por qué son borradores? ¿En cuáles se definen los objetivos SMART? ¿Quién los realiza y quién los autoriza? Problema 1.15 Investigue cuáles son los integrantes del modelo de equipo propuesto por MSF y mencione brevemente la función de cada uno de ellos. Problema 1.16 Para los proyectos pushed by technology (PT) y pulled by demand (PD), tambien llamados market pulled, Describa muy brevemente en qué consisten y roporcione un ejemplo de cada uno. ¿Considera que debería modificarse de alguna manera la metodología vista en clase en función del tipo de proyecto (PT, PD)? ¿Qué factores considera críticos para un análisis de retorno en función del tipo de proyecto? Problema 1.17 Suponga que la Comisión Federal de Comunicaciones (FCC) de los Estados Unidos decide reasignar las bandas de espectro para televisión UHF para acceso a internet con radios cognitivos, en el año X. Suponga una iniciativa similar en México para el año X+2. ¿Esta iniciativa sería pushed by technology, by demand, o simplemente una moda? Problema 1.18 Del documento NETWORK PLANNING AND DESIGN de R. Van Slyke5, lea las primeras dos secciones y el caso de estudio del anexo B, y responda las siguientes preguntas: Suponiendo que en su empresa se va a desarrollar un gran proyecto de desarrollo de redes a lo largo del año, identifique 10 riesgos técnicos y 10 de factores externos que podrían presentarse. Posiciónelos en una matriz de probabilidad/impacto. Justifique su respuesta. ¿Cuál es la estrategia organizacional para TI en su empresa? ¿Están claramente identificadas las políticas para desarrollo y actualización de tecnologías? Explique brevemente. Suponga que, similar a las tarjetas IAVE, la SCT desarrolla un sistema para pagar las casetas de cobro a través del teléfono celular. ¿Esta aplicación sería push-driven o pull-driven? ¿La tecnología SMS exhibe un comportamiento de economía de escala o de economía de red? Explique brevemente. En este contexto, una empresa encuestadora orientada al segmento de jóvenes que utiliza SMS para sus evaluaciones, ¿sería push-driven o pull-driven? En la medida de lo posible, relacione los 12 puntos de la metodología propuesta en el documento con las cuatro fases del modelo de proceso MSF. ¿Cuáles son las principales diferencias entre ambos? Revise los portales de Amazon y Barnes and Noble y comente brevemente sobre la forma en que cada uno ha diversificado su oferta de productos desde la fecha en que fue escrito el documento. Responda las cuatro primeras preguntas el cuestionario del anexo B. Problema 1.19 Para el análisis de riesgos de un proyecto, se ha propuesto que los riesgos identificados se coloquen en una matriz. ¿Qué contienen los renglones y columnas de esta matriz? ¿Para qué se asigna una ponderación a cada celda en la matriz? Problema 1.20 ¿Qué diferencia hay entre mitigar un riesgo y hacer un plan de contingencia? Problema 1.21 Para cierto proyecto, se han identificado los riesgos que aparecen en la tabla siguiente. Suponiendo que tanto la probabilidad (Pr) de ocurrencia como su impacto (Im) pueden tomar valores de 1 a 3, complete la tabla y otorgue una calificación final al proyecto. Dada la vaguedad de la pregunta, debe justificar sólidamente los valores que asigne. Riesgo Pr Im Justificación Falta soporte Alta Dirección Criterios de aceptación no claros Tiempos largos de instalación en sitio Cliente inmediato no tiene autoridad para tomar decisiones Usuario no está involucrado Solución con base en tecnologías no probadas o no conocidas No se tienen estrategias de control de calidad El proveedor de servicios (carrier) falla o quiebra Hay una devaluación de la moneda No hay líder de proyectos o no tiene experiencia Para algunos investigadores, las siglas pueden tener significados ligeramente distintos, por ejemplo: Relevantes y Tangibles. En el capítulo siguiente serán definidos con precisión algunos requerimientos técnicos Johansson, R.; Aplicación de metodologías de administración de proyectos para implantar un proyecto de red; Tesina Ing. Telemática, ITAM, 2001. http://cis.poly.edu/rvslyke/ndr1.pdf "],["requerimientos-técnicos.-compromisos-y-restricciones.html", "Capítulo 2 Requerimientos técnicos. Compromisos y restricciones 2.1 Escalabilidad 2.2 Disponibilidad 2.3 Confiabilidad 2.4 Desempeño 2.5 Seguridad 2.6 Administración 2.7 Facilidad de uso 2.8 Adaptabilidad 2.9 Costo-beneficio 2.10 Conflictos entre requerimientos 2.11 Otras métricas relevantes 2.12 Problemas", " Capítulo 2 Requerimientos técnicos. Compromisos y restricciones Durante la fase de visión y alcance se identificaron las necesidades de negocio, el entorno de trabajo y se empezó a reconocer el tipo de aplicaciones que soportarán los objetivos del proyecto. Para el diseño de la red, los requerimientos de negocio se traducen en requerimientos técnicos. Como se mencionó en el capítulo anterior, los objetivos del proyecto deben ser SMART, por lo que los requerimientos técnicos deben ser cuantificables y especificarse en términos concretos. En este capítulo se introducirán brevemente algunos de los requerimientos técnicos encontrados más frecuentemente en redes de comunicaciones. Específicamente, se presentan los requerimientos de:    Escalabilidad Desempeño Administración Adaptabilidad Disponibilidad Seguridad Facilidad de uso Costo-beneficio Algunos de estos requerimientos son mutuamente exclusivos, por lo que se requiere de compromisos entre ellos. Estos compromisos deben estar claramente alineados con los objetivos del proyecto. 2.1 Escalabilidad El requerimiento de escalabilidad (scalability) se refiere básicamente a la capacidad de crecimiento de la red y puede llegar a ser uno de los objetivos centrales para medianas y grandes empresas inmersas en una estrategia de adquisiciones, fusiones, y/o crecimiento acelerado. En este contexto, crecimiento abarca varias dimensiones. Se debe discutir claramente con el cliente cuáles son sus planes a corto (un año), mediano (dos años) y largo plazo (cinco años) para agregar nuevos usuarios, equipos y aplicaciones de negocio. También deberá discutirse si se tienen planeados cambios en las políticas de operación (por ejemplo, comercio electrónico) y/o en las principales líneas de negocio. Esto es muy importante pues escalar una red puede llegar a ser sumamente difícil si no se planea desde el principio. Por ejemplo, algunas tecnologías son inherentemente no escalables, como ocurre con redes planas basadas en equipos de conmutación y que utilizan protocolos que generan muchas tramas de difusión. La escalabilidad será confrontada con el tiempo de vida promedio de las tecnologías en que se basa el diseño propuesto. Es común considerar que la infraestructura de base (cableado, enlaces) tiene un tiempo de vida útil de 10 a 15 años. Sin embargo, en los últimos años se ha observado un cambio dramático en la tasa de rotación de infraestructura. A partir de finales del siglo XX se observó un tiempo de obsolescencia de la infraestructura de cableado de únicamente seis años, sobre todo en el núcleo de la red, debido a las continuas mejoras tecnológicas y a la reducción de costos en este rubro (en particular, en fibra óptica). Este tiempo de obsolescencia sigue siendo vigente en redes que no han desplegado fibra óptica monomodal. Para los equipos de conmutación (enrutadores, conmutadores, concentradores), el tiempo de vida actual oscila entre los tres y los cinco años. Otro aspecto que debe tomarse en consideración al evaluar la escalabilidad necesaria en la red, es que los paradigmas clásicos de dimensionamiento de redes están perdiendo fuerza. Tradicionalmente, la planeación de capacidad para redes empresariales se hacía basándose en una distribución Pareto: 80% del tráfico queda en la red local departamental y 20% va a otros lados. Este paradigma ha sido cada vez más cuestionado en la actualidad. De hecho, se observa que la relación se está invirtiendo debido, entre otros factores, a: El uso creciente de granjas de servidores (clusters, blade servers) y de servidores de aplicaciones; el modelo de hospedaje externo de servidores (hosting); la concentración de información en infraestructura especializada (SANs, NAS); la difusión de información corporativa en intranets; el creciente modelo de comunicaciones inter-empresas (extranets). 2.2 Disponibilidad La disponibilidad (availability) indica cuánto tiempo la red está en operación en un determinado intervalo de tiempo (año, mes, día, hora, ). Generalmente se representa como un porcentaje del período evaluado. \\[\\text{Disponibilidad}=\\frac{\\text{Tiempo en operación}}{% \\text{Período evaluado}}\\] De acuerdo a su disponibilidad, los sistemas pueden clasificarse de la siguiente manera: No administrado 90% Administrado 99% Bien administrado 99.9% Tolerante a fallos 99.99% Alta disponibilidad 99.999% Muy alta disponibilidad 99.9999% Ultra alta disponibilidad 99.99999% La disponibilidad necesaria debe definirse con precisión, pues cada 9 adicional, si bien aumenta en un orden de magnitud la fiabilidad del sistema, puede resultar sumamente costoso. Para saber cuánto invertir en este requerimiento, debe partirse por evaluar el costo para la empresa de que una aplicación de misión crítica deje de operar. Las aplicaciones de misión crítica son todos aquellos procesos en los que se basa el núcleo de negocio de la empresa. Un fallo en una aplicación crítica deja a la empresa sin poder operar. Un requerimiento de disponibilidad típico para aplicaciones de misión crítica es de 99.98%. La disponibilidad se puede determinar más fácilmente a partir de los valores de tiempo medio entre fallos (mean time between failures, MTBF) y tiempo medio de reparación (mean time to repair, MTTR). \\[\\text{Disponibilidad}= A = \\frac{\\texttt{MTBF}}{\\texttt{MTBF}+ \\texttt{MTTR}}\\] Se prefiere esta métrica pues puede ocurrir que muchas fallas de muy corta duración den un valor de disponibilidad adecuado aunque en la práctica no se pueda trabajar con el sistema. MTBF y MTTR son cifras para componentes y equipos. Como la red da un servicio, algunos autores prefieren los términos MTBSO (Mean time between service outages) y MTTSR (Mean time to service repair). Es muy importante considerar que los valores de MTBF y MTTR son valores promedio en los que puede haber una gran variabilidad. Esto es particularmente cierto para el MTTR, en el cual se engloban muchos factores muy variados como el tiempo en que se detecta la falla, el necesario para aislar el equipo, para repararlo, y el tiempo necesario para restablecer el equipo e integrarlo a la infraestructura de producción. Para un equipo de red, un MTBF deseable es del orden de decenas de miles de horas. Para un sistema completo, es de miles de horas, pues la disponibilidad de un sistema depende de la manera en la que sus componentes están interconectados: Figura 2.1: Disponibilidad de sistemas con componentes en serie y en paralelo Dado que \\(0\\leq A_i\\leq 1\\), de la figura 2.1 se confirma que con un mayor número de dispositivos o sub-sistemas en serie, la disponibilidad disminuye (es decir, aumenta la probabilidad de fallos en el sistema). A mayor número de dispositivos con la misma funcionalidad en paralelo, la disponibilidad aumenta. Es evidente que el uso de equipos redundantes aumenta la disponibilidad del sistema. Para sistemas similares que no están directamente relacionados entre sí, los MTBF (y en cierta medida, la disponibilidad) de cada uno suelen considerarse como variables aleatorias independientes idénticamente distribuidas. Ejemplo 2.1 Considere una empresa que tiene \\(N=500\\) computadoras personales con un MTBF de \\(10,000\\,\\text{hr}\\). El número de incidentes por fallos esperado por día es de: \\[X = N\\times\\frac{t}{\\texttt{MTBF}+\\texttt{MTTR}}\\approx N\\times\\frac{t}{\\texttt{MTBF}}% = 500\\times \\frac{8760}{365\\times 10000}=1.2\\,\\text{fallos/dia}\\] Tal vez se justifique una persona dedicada a dar mantenimiento a las computadoras. Si se adquirieran equipos con un MTBF de \\(40,000\\,\\text{hr}\\), entonces se tendrían 9 fallos por mes. 2.3 Confiabilidad La confiabilidad (reliability) se refiere a las características aleatorias de los fallos. Se define como la probabilidad de que el sistema no falle antes de \\(t\\) horas de operación y se especifica en términos del MTBF de los componentes. Frecuentemente se considera que las fallas obedecen a un proceso de Poisson, por lo que el intervalo entre fallos tiene una distribución exponencial. Por lo tanto, \\[R=e^{-\\frac{t}{\\texttt{MTBF}}}\\] Ejemplo 2.2 Considere un equipo con un \\(\\texttt{MTBF}=10,000\\,\\text{horas}\\). Su confiabilidad para un año será de \\(R = 41.64\\%\\). Si el MTBFaumenta a \\(20,000\\,\\text{horas}\\), la confiabilidad únicamente crece a \\(R =64.53\\%\\). Como fue el caso para el requerimiento de disponibilidad, la confiabilidad de un sistema depende de la interconexión entre sus componentes. Para una topología en serie, la confiabilidad se calcula así: \\[R_s = e^{-t\\bigl(\\frac{1}{\\texttt{MTBF}_1}+\\frac{1}{\\texttt{MTBF}_2}% +\\cdots+\\frac{1}{\\texttt{MTBF}_n}\\bigr)},\\] mientras que para un sistema con componentes similares en paralelo, la confiabilidad se determina por: \\[R_p=1-(1-R_1)\\times(1-R_2)\\times \\cdots\\times (1-R_n).\\] Ejemplo 2.3 Considere un sistema con tres componentes en serie cuyos MTBF son respectivamente de \\(20\\,k\\), \\(25\\,k\\) y \\(30\\,k\\) horas. Para un año, la confiabilidad del sistema es: \\(R = 34\\%\\). 2.4 Desempeño Los requerimientos de desempeño de la red (network performance) también llamados prestaciones de la red, se definen con base en un conjunto de métricas cuantitativas sobre el comportamiento de la red, como el ancho de banda, la utilización, el rendimiento, la carga ofrecida, la tasa de error, la eficiencia, el retardo y su variabilidad (jitter). Es importante identificar las expectativas que el usuario tiene sobre el desempeño de la red. Estas expectativas están fuertemente ligadas a las características de la red existente y a los planes de crecimiento de la misma. 2.4.1 Ancho de banda Técnicamente, el ancho de banda es una medida del rango de frecuencias que conforman una señal analógica (o la mayor parte de su potencia) y está medida en Hertz. En los sistemas digitales, representa el número de símbolos por segundo o baudios que pueden ser transmitidos por un sistema de comunicaciones. Dependiendo de la técnica de codificación, cada baudio puede representar uno o más bits, por lo que el ancho de banda también se emplea informalmente como una medida de la capacidad del canal de comunicación. Esa es la definición que se seguirá en este documento: Es la cantidad nominal (o teórica) de información que puede ser transportada por unidad de tiempo. Generalmente se expresa en bits/s. 2.4.2 Utilización Es una medida de la cantidad de tráfico transportada en relación con la capacidad total. En primera instancia se podría pensar que el objetivo de utilización debería ser cercano al 100% pero en realidad esto no es así: En las redes informáticas los paquetes suelen llegar en ráfagas y se debe dejar un margen para poder absorber esas ráfagas sin que haya pérdidas. En redes que tienen un control de acceso por contención (por ejemplo, ethernet), la eficiencia (ver más adelante) disminuye rápidamente conforme aumenta la utilización. Los procesos de llegada y de salida de paquetes son procesos aleatorios. En la mayoría de los casos, la dinámica de estos procesos requiere que, para una tasa de pérdida determinada, el tamaño de los buffers (y por consiguiente, el tiempo de espera) aumente exponencialmente conforme la utilización se acerca al 100%. Ejemplo 2.4 Un modelo de la teoría de colas muy común para evaluar métricas de desempeño en redes de conmutación de paquetes, es la cola \\(M/M/1\\) 6. La cola \\(M/M/1\\) supone que la llegada de los paquetes es un proceso de Poisson (el intervalo entre paquetes tiene una distribución aleatoria exponencial) y que la tasa de servicio (la longitud del paquete) también es exponencial. En este modelo, la utilización es el cociente entre la tasa de llegadas y la tasa de servicio y se representa por \\(\\rho\\). El valor esperado para el tamaño de la cola se calcula como: \\[E[N]=\\frac{\\rho}{1-\\rho}\\] Suponga que cinco usuarios generan tráfico con una tasa media de 10 paquetes por segundo cada uno y que el tamaño medio de paquete es de 1,024 bits. Los cinco usuarios comparten un enlace E07. Modelando este escenario como una cola \\(M/M/1\\): \\[\\begin{aligned} \\rho = \\frac{5\\times 10\\times 1,024}{64,000}&amp;=0.8\\\\ E[N] = \\frac{0.8}{0.2}&amp;=4 \\end{aligned}\\] El número medio de paquetes encolados es de cuatro. Sin embargo, si se agrega solamente un usuario más al sistema, entonces \\(\\rho= 0.96\\) y \\(E[N]= 24\\). Los parámetros típicos para dimensionar una red informática son los siguientes: Enlaces punto a punto y redes con control de acceso arbitrado: \\(U\\approx 70\\%\\) Redes ethernet: \\(U\\approx 37\\%\\) Los mecanismos de contención utilizados en ethernet, y derivados de la red Aloha, hacen que cuando la red empieza a rebasar este valor, el número de colisiones para acceder al medio crezca demasiado. Sin embargo, se debe tener presente que esto no aplica a ethernet conmutado, la tecnología dominante en la actualidad. Si en el puerto de un conmutador ethernet se tiene conectado un solo equipo, se trata de un enlace punto a punto y la utilización puede crecer hasta el 70%. 2.4.3 Rendimiento En este trabajo, rendimiento (throughput) se define como la cantidad de información transmitida sin error por unidad de tiempo. Idealmente, el rendimiento aumenta linealmente con la carga ofrecida a la red. Esto se cumple sólo hasta un cierto punto tras el cual se degrada debido a factores como la tasa de errores, la dinámica de protocolos, el desempeño de los equipos intermedios y el modo de acceso. El rendimiento puede ser calculado para toda la red, para una trayectoria, para un enlace o para un dispositivo de conmutación. En este último caso, el rendimiento se define como la tasa a la que el dispositivo puede conmutar paquetes, y puede variar de acuerdo al tamaño medio del paquete. La tasa máxima de conmutación se conoce como wire speed y es igual a: \\[\\text{Wire speed}=\\frac{\\text{Ancho de banda}}{\\text{Tamaño de paquete}}\\] Ejemplo 2.5 Para una red 10baseT, considerando tramas de tamaño mínimo, la tasa máxima de conmutación de paquetes es: \\[\\frac{10\\times 10^6}{(64+20)\\times 8}=14,480\\,\\text{p/s},\\] donde los 20 octetos en el denominador corresponden a 8 de preámbulo y 12 del intervalo entre tramas. Si se hace el mismo cálculo para un tamaño de trama de 1,500 bytes, entonces el rendimiento sería de \\(822\\,\\text{p/s}\\). Desde el punto de vista del usuario, la métrica de rendimiento de interés es la tasa de información percibida en la capa de aplicación del modelo de referencia para la interconexión de sistemas abiertos (OSI, Open Systems Interconnection). Esta métrica es informalmente conocida como goodput. Por ejemplo, en una red de baja velocidad se podría eliminar cualquier mecanismo de compresión. En ese caso, tal vez el rendimiento a nivel enlace aumente pero ciertamente el goodput se vería penalizado. Un caso similar ocurriría si la mayoría de los paquetes que circulan por la red fueran retransmisiones debidas a algún equipo que no esté trabajando correctamente. También conviene recordar que no todas las aplicaciones necesitan o pueden generar un goodput elevado. Considere, por ejemplo, una sesión interactiva de terminal virtual, sobre todo, con una interfaz de texto. 2.4.4 Tasa de error Evidentemente, los datos recibidos deben ser iguales a los transmitidos. De no ser así, la trama debe ser emitida nuevamente, disminuyendo el rendimiento de la red. La tasa de error es una medida del número de errores detectados. En medios físicos y redes WAN generalmente se expresa en bits afectados (bit error rate) mientras que en redes LAN se habla de tasa de tramas afectadas (frame error rate). Antiguamente la tasa de error en los medios físicos era relativamente elevada. Esto ha cambiado radicalmente en la actualidad, sobre todo con la aparición de la fibra óptica, aunque también ha habido mejoras en las demás tecnologías. Algunas fuentes típicas de error son la siguientes: Interferencia electromagnética (cable no blindado); picos de corriente (medios cableados); factores ambientales (microondas y satélites); impedancias no acopladas (redes locales); fallas de equipo (todos los casos). Dada la penetración de los sistemas digitales en la actualidad, llama la atención que en la lista anterior no se consideren errores de software en los equipos terminales y dispositivos de red. En realidad, este tipo de error suele detectarse rápidamente en las etapas de validación del equipo; es relativamente poco frecuente que un equipo en producción presente fallas de programación. Algunas cifras típicas de tasa de error son las siguientes: Alambre de cobre: \\(BER\\approx 10^{-6}\\) Fibra óptica: \\(BER\\approx 10^{-12}\\) Enlaces satelitales: \\(BER\\approx 10^{-5}\\). La tasa de error de los enlaces satelitales depende en gran medida de la banda (frecuencia) que se utilice y de las condiciones atmosféricas. La cifra anterior no considera la corrección automática de errores por el receptor (forward error correction, FEC), una técnica muy popular basada en transmisión de información redundante, lo cual permite reducir sustancialmente la tasa efectiva de error. Para redes LAN, una tasa de error considerada aceptable es detectar, en promedio, una trama errónea por cada \\(10^6\\) bytes transmitidos. Aunque se habla de tramas erróneas, la cifra se expresa en función del número de octetos para evitar el tener que tomar en cuenta el tamaño de las tramas. En redes tipo ethernet, se deben detectar menos de 0.1% de tramas en colisión. En primera instancia, esta cifra puede parecer demasiado baja pues las colisiones son un fenómeno natural de competencia en este tipo de redes. Sin embargo, se debe recordar que la mayoría de las colisiones se presentan durante la transmisión del preámbulo, antes de iniciar propiamente la transmisión de una trama y por lo tanto, no son tomadas en cuenta. 2.4.5 Eficiencia La eficiencia es una medida de la sobrecarga o trabajo extra necesario para la transmisión de información en relación con la capacidad total del medio. También puede representar la cantidad útil de información en relación con la cantidad transmitida. Se ve afectada directamente por las características de los protocolos utilizados: tamaño de los encabezados, acuses de recibo, paso de estafetas (token); etc. Ejemplo 2.6 Del ejemplo 2.5 se obtuvo que en ethernet a \\(10\\,Mb/s\\) se pueden enviar \\(14,480\\) tramas de \\(64\\) bytes. Considerando únicamente la sobrecarga del encabezado MAC, en la trama sólo hay \\(64 - 18 = 46\\) bytes de carga útil, por lo que la eficiencia es: \\[\\mathcal{E} = \\frac{46\\times 14,480\\times 8}{10\\times 10^6}\\times 100\\%=53.20\\%.\\] Si el tamaño de las tramas cambia a 1,500 bytes, la eficiencia aumenta a: \\[\\mathcal{E} = \\frac{1,482\\times 812\\times 8}{10\\times 10^6}\\times 100\\%=96.20\\%.\\] Ejemplo 2.7 En transmisiones de voz sobre IP, cada paquete transporta un cierto intervalo de muestras (típicamente, \\(10\\), \\(20\\) o \\(40\\,ms\\)) cuyo tamaño depende del tipo de códec utilizado. Los paquetes suelen contener encabezados de tres protocolos que contribuyen en 40 bytes al tamaño final del paquete: RTP(12 bytes), UDP(8 bytes) e IP(Ver. 4 sin opciones: 20 bytes). Ignorando por ahora el encabezado MAC y suponiendo un códec PCM a \\(64\\,kb/s\\) (G.711), si el paquete transporta \\(20\\,ms\\) de información, su eficiencia es la siguiente: Se generan \\(1/20\\,ms = 50\\,\\text{p/s}\\). Cada paquete tiene su propio encabezado por lo que se genera una sobrecarga de \\(50\\times 40\\times 8 =16\\,kb/s\\). El ancho de banda necesario para transportar la información es entonces de \\(16\\,kb/s + 64\\,kb/s = 80\\,kb/s\\) y la eficiencia es: \\[\\mathcal{E}=\\frac{64,000}{80,000}\\times 100\\%=80\\%.\\] Es claro que una manera de aumentar la eficiencia es aumentando la carga útil (payload) por paquete para prorratear mejor el costo de los encabezados. Sin embargo, paquetes de mayor tamaño tienen una mayor probabilidad de error y sobre todo en redes de baja velocidad pueden introducir retardo y jitter en flujos concurrentes. 2.4.6 Retardo y variabilidad Retardo (latencia) es el tiempo transcurrido entre la emisión de un paquete y su llegada al extremo opuesto (retardo en una dirección), o bien, el arribo de su respuesta (retardo de ida y vuelta, RTT). Afecta a las aplicaciones interactivas: Estudios recientes indican que la mayoría de los usuarios esperan que algo ocurra en la pantalla tras una décima de segundo. La variabilidad en el retardo, el jitter, es un fenómeno que afecta principalmente a las aplicaciones multimedia. Tanto el retardo como el jitter  dependen de factores como el nivel de congestión, la típica emisión en ráfagas de las aplicaciones tradicionales y el desempeño de los enrutadores (por ejemplo, durante la actualización de tablas de ruteo; tiempo de convergencia tras una falla; etc.). Jitter Se genera principalmente debido al tiempo de espera en las colas de los dispositivos de red. Como se ha señalado, el tiempo de espera aumenta exponencialmente con la utilización (en una disciplina de servicio FIFO). Afecta a las aplicaciones multimedia pues las muestras transportadas por la red deben ser liberadas exactamente con las mismas características temporales (cadencia e intervalo entre muestras) con las que fueron tomadas. Una práctica común para compensar las variaciones sufridas en la red, es agregar un sello de tiempo a las muestras y utilizar un buffer de reproducción en el receptor en el que se almacenan (y retrasan) temporalmente los paquetes recibidos. En principio, este buffer debe poder almacenar tantas muestras como para absorber la variabilidad más grande esperada, pero en aplicaciones interactivas no puede ser demasiado grande pues se pierde la sensación de continuidad necesaria en estos casos. Cuando se desconocen los requerimientos reales de jitter, una práctica común es recomendar que éste no exceda el 2% del valor de latencia especificado. Elementos de retardo Los principales elementos de retardo en una red se muestran en la figura 2.2: Figura 2.2: Principales elementos de retardo en una red Tiempo de procesamiento: \\(t_{pr}\\). En los equipos terminales, está relacionado con el tratamiento del paquete en la pila de protocolos y en el mecanismo de manejo de interrupciones. Para sistemas de muy alto desempeño, se deben buscar implementaciones que minimicen el número de transferencias a memoria durante el procesamiento del paquete por los distintos procesos que intervienen en su manejo (zero copy stacks). En los nodos de conmutación está relacionado con la arquitectura interna del dispositivo para seleccionar la interfaz de salida y llevar el paquete hacia ella. Un valor típico para equipos de no muy alto desempeño es de entre \\(10\\) y \\(50\\,\\mu s\\). Para algunas arquitecturas, este valor está en función del tamaño del paquete. El \\(t_{pr}\\) también puede incluir el tiempo medio de espera en los buffers del dispositivo. Tiempo de acceso al medio: \\(t_a\\). Es el intervalo de espera para poder iniciar la transmisión y depende del protocolo de acceso al medio particular (contención, espera de autorización, de la ranura de tiempo, etc.). Tiempo de transmisión: \\(t_t\\). También llamado de serialización, indica el tiempo requerido para colocar el paquete en el medio y es igual a la longitud del paquete dividida entre la velocidad de transmisión. Tiempo de propagación: \\(t_p\\). Es el tiempo que se requiere para propagar la energía (en cualquier formato) de un punto a otro. Se calcula como la distancia del medio dividida entre la velocidad de propagación. La velocidad de propagación de las ondas electromagnéticas es la velocidad de la luz: \\(c \\approx 3\\times 10^8\\,m/s\\)8. La velocidad de propagación tanto en cobre como en fibra óptica suele ser tomada como \\(\\frac{2}{3} c\\), aunque los valores más exactos que se tienen hasta el año de 2002 son de \\(224,844\\,km/s\\) en un alambre de cobre y de \\(194,865\\,km/s\\) en una fibra óptica multimodal. Ejemplo 2.8 Considere la red de la figura 2.2 con las siguientes características:  La red LAN en el origen es 10BaseT;  la red LAN en el destino es 100BaseT;  las entidades se encuentran a \\(900\\,km\\) de distancia y están interconectadas con un enlace \\(E0\\);  el origen envía una trama de \\(1\\,kB\\) y espera el acuse de recibo de \\(64\\) bytes. Para calcular el RTT, se tomarán en cuenta las siguientes consideraciones:  El tiempo de procesamiento en el origen y el destino se ignora;  el retardo de propagación en las redes locales se ignora;  el tiempo de procesamiento en los enrutadores es de \\(10\\,\\mu s\\);  \\(t_{to},~t_{td}~\\text{y}~t_{tw}\\) son los tiempos de serialización de las dos tramas en el origen, en el destino y en el enlace WAN, respectivamente. \\[\\begin{aligned} t_{to} &amp;=\\frac{(1,024+64)\\times 8}{10^6}=0.87\\,ms\\\\ t_{td} &amp;=\\frac{(1,024+64)\\times 8}{10^7}=0.087\\,ms\\\\ t_{tw} &amp;=\\frac{(1,024+64)\\times 8}{64,000}=136\\,ms\\\\ t_{pr} &amp;=0.04\\,ms\\\\ t_p&amp;=2\\times\\frac{900}{240,000}=7.5\\,ms\\\\ \\texttt{RTT}&amp;= t_{to}+t_{td}+t_{tw}+t_{pr}+t_p=144.49\\,ms \\end{aligned}\\] El principal elemento de retardo es el tiempo de serialización en el enlace WAN. Este es el cuello de botella. Se dice que esta red está limitada en ancho de banda. Ejemplo 2.9 Se retoman las condiciones del ejemplo anterior, pero el enlace de fibra óptica se sustituye por un enlace satelital: Figura 2.3: Principales elementos de retardo en una red satelital Todos los valores quedan igual excepto el retardo de propagación. El valor actualizado de \\(t_p\\). y el RTT resultante son de: \\[\\begin{aligned} t_p&amp;=2\\times\\frac{2\\times 36,000}{300,000}=480\\,ms\\\\ \\texttt{RTT}&amp;= t_{to}+t_{td}+t_{tw}+t_{pr}+t_p=616.99\\,ms \\end{aligned}\\] El principal elemento de retardo es el retardo de propagación en el enlace WAN. Esta red está limitada en latencia. Hay muy poco que la tecnología pueda hacer para reducir el RTT en este tipo de red. Caso de estudio: Evaluación de retardo Los ejemplos anteriores proporcionan un límite inferior del retardo de ida y vuelta apreciado entre dos sitios separados una distancia de \\(900\\,km\\). En el presente caso se muestra un estudio real sobre mediciones del retardo observado al consultar un servidor de base de datos a través de distintas redes: LAN, WAN terrestre, satelital dedicado y satelital compartido. Las mediciones se hacen con un analizador de protocolos del lado del cliente en una configuración como la mostrada en la figura 2.4. Figura 2.4: Configuración recomendada para evaluar el retardo de ida y vuelta Como puede observarse, para este tipo de estudios el RTT se mide en el extremo del cliente (el que iniciará la solicitud). Es importante activar filtros en el analizador de manera que solamente se observe el tráfico entre los equipos involucrados. Ambiente de red local En la primera evaluación, se colocan cliente y servidor en la misma red local. Esto permite configurar y probar la maqueta así como obtener un límite inferior para el tiempo de respuesta. La conversación capturada se muestra en la tabla siguiente. La columna del intervalo de tiempo despliega la diferencia entre tramas consecutivas. No. Tamaño Tiempo Dirección Banderas Contenido 1 76 0.000 \\(C\\rightarrow S\\) .AP... Binario 2 74 0.010 \\(S\\rightarrow C\\) .AP... Binario SELECT COUNT (COD CLIENTE) FROM (MG CLIENTES) WHERE (COD CLIENTE) = x 4 139 0.000 \\(S\\rightarrow C\\) .AP... Binario 5 79 0.000 \\(C\\rightarrow S\\) .AP... Binario 6 140 0.000 \\(S\\rightarrow C\\) .AP... RA-01403 no data found   Si bien desde el punto de vista de la aplicación solamente se está realizando una operación sencilla, seis paquetes han sido intercambiados en la consulta. Con el primer paquete el cliente envía información de control al servidor; \\(10\\,ms\\) después, el servidor responde. Este retraso puede deberse, por ejemplo, al cambio de contexto en el equipo destino para activar la tarea correspondiente del manejador de base de datos. En el paquete 3, el cliente está enviando los datos correspondientes a la consulta; muy probablemente los paquetes 4 y 5 son acuses de recibo del protocolo de control. Finalmente, la respuesta llega en el paquete 6. Los intervalos entre todos los demás paquetes son demasiado pequeños para ser capturados por el analizador de protocolos. Toda la transacción toma alrededor de \\(10\\,ms\\). Ambiente WAN terrestre Esta vez, el servidor se encuentra a \\(900\\,km\\) de distancia del cliente y los dos sitios se interconectan por medio de un enlace \\(E0\\) terrestre basado en fibra óptica. Los resultados son los siguientes: No. Tamaño Tiempo Dirección Banderas Contenido 1 76 0.000 \\(C\\rightarrow S\\) .AP... Binario 2 74 0.090 \\(S\\rightarrow C\\) .AP... Binario SELECT COUNT (COD CLIENTE) FROM (MG CLIENTES) WHERE (COD CLIENTE) = x 4 139 0.100 \\(S\\rightarrow C\\) .AP... Binario 5 79 0.000 \\(C\\rightarrow S\\) .AP... Binario 6 140 0.050 \\(S\\rightarrow C\\) .AP... RA-01403 no data found       Se siguen generando seis paquetes en este intercambio, pero los intervalos entre los paquetes emitidos por el cliente y las respuestas del servidor son considerablemente mayores. Por supuesto, la diferencia se atribuye, sobre todo, al retardo de propagación en la red WAN. Toda la transacción toma ahora alrededor de \\(250\\,ms\\). Ambiente WAN satelital dedicado Para este escenario, cliente y servidor se interconectan a través de un enlace satelital SCPC (Single Channel Per Carrier) dedicado únicamente a la comunicación entre los dos sitios. Las tramas observadas en este caso son: No. Tamaño Tiempo Dirección Banderas Contenido 1 76 0.000 \\(C\\rightarrow S\\) .AP... Binario 2 76 0.800 \\(C\\rightarrow S\\) .AP... Binario 3 74 0.850 \\(S\\rightarrow C\\) .AP... Binario SELECT COUNT (COD CLIENTE) FROM (MG CLIENTES) WHERE (COD CLIENTE) = x 5 64 190 \\(S\\rightarrow C\\) .A... Vacío 6 139 0.360 \\(S\\rightarrow C\\) .AP... Binario 7 79 0.000 \\(C\\rightarrow S\\) .AP... Binario 8 140 0.520 \\(S\\rightarrow C\\) .AP... RA-01403 no data found       La diferencia de tiempos ya es muy notoria. Una consulta que llevó solamente \\(10\\,ms\\) sobre una red de área local y \\(250\\,ms\\) sobre un enlace terrestre, ahora tarda \\(2.730\\,s\\) a través de este enlace. Estos tiempos ya son más que suficientes para que el usuario note una diferencia. Hay dos paquetes de más. El segundo paquete transmitido de la fuente al destino \\(800\\,ms\\) después del primero es muy probablemente una retransmisión del primero al terminar el tiempo de espera de la respuesta. El quinto paquete es un acuse de recibo del paquete así duplicado. El principal elemento de retardo en este escenario es el retardo de propagación a través del enlace satelital. Un aumento en el ancho de banda del enlace, no tendrá ningún impacto apreciable en el retardo percibido. Considere ahora el escenario normal en el que se realizan varias consultas para obtener la información con la que llena una sola pantalla. Suponiendo que se requieran únicamente tres consultas y que la respuesta a las mismas no sea muy grande, se requiere de casi 9 segundos ¡para llenar una sola pantalla de información! Ambiente WAN satelital compartido En este escenario, la conexión cliente-servidor es TDMA (Time Division Multiple Access) compartido. Antes de poder enviar información, hay que solicitar y esperar la asignación de una ranura de tiempo, lo cual introduce retardos variables. Las tramas observadas en este escenario son:    No. Tamaño Tiempo Dirección Banderas Contenido 1 76 0.000 \\(C\\rightarrow S\\) .AP... Binario 2 74 0.608 \\(S\\rightarrow C\\) .AP... Binario SELECT COUNT (COD CLIENTE) FROM (MG CLIENTES) WHERE (COD CLIENTE) = x 4 58 1.887 \\(S\\rightarrow C\\) .A... Vacío 5 139 0.011 \\(S\\rightarrow C\\) .AP... Binario 6 79 0.000 \\(C\\rightarrow S\\) .AP... Binario 7 140 0.783 \\(S\\rightarrow C\\) .AP... RA-01403 no data found       Efectivamente, hay una variabilidad mayor en las diferencias de retardo observadas. El cuarto paquete, con un retardo diferencial de \\(1.887\\,s\\), es muy probablemente una réplica del segundo paquete enviado por el servidor dado que el tercer paquete se ha retrasado demasiado esperando el acceso al canal. El retardo total observado es de \\(3.29\\,s\\). También es interesante observar algunas gráficas sobre los retardos observados en los tres escenarios. Figura 2.5: Retardos observados en los enlaces (a) de fibra óptica; (b) satelital dedicado; (c) satelital compartido En la figura 2.5 se muestra cómo los retardos en cualquiera de los tres enlaces pueden incrementarse considerablemente con respecto al retardo mínimo teórico, o incluso con respecto al retardo promedio, dependiendo del porcentaje de uso del ancho de banda en un instante cualquiera. Recuerde que el retardo mínimo teórico en el enlace terrestre es de \\(144\\,ms\\) y en la primer gráfica de la figura se observa cómo los picos de retardo pueden alcanzar los \\(2\\,s\\) con relativa facilidad, y en casos extremos pueden llegar a más de \\(7\\,s\\). Se logra percibir una variabilidad en el retraso a lo largo del tiempo, que puede coincidir con las actividades durante la jornada laboral. En los datos obtenidos del canal satelital dedicado (segunda gráfica de la figura 2.5), se muestra un retardo medio mayor que en el enlace terrestre debido a la latencia. También se alcanza a distinguir una mayor variabilidad, pero se considera razonable. Los datos recabados para el enlace satelital compartido (tercer gráfica de la figura @ref[fig:delay3e)) muestran que el retardo medio es mucho mayor, pero lo que es más evidente es su enorme variabilidad a lo largo del periodo evaluado. En este tipo de enlaces es muy difícil ofrecer servicios interactivos y francamente improbable servicios de tiempo real. 2.5 Seguridad La seguridad es uno de los aspectos más importantes en el diseño de la red, sobre todo si se contempla que ésta tenga acceso a Internet o a Extranets y debe ser tomada en consideración desde las primeras fases de diseño. El objetivo es buscar garantías de que el diseño ofrece alguna protección contra pérdida o daño de datos y recursos. Los incidentes de seguridad no deben afectar la capacidad de operación de las empresas. Los objetivos de seguridad pueden entrar en conflicto con otros requerimientos como costo, facilidad de uso, redundancia y escalabilidad. Considérese, por ejemplo, el caso en el que toda la información debe pasar por un único punto para ser cifrada/descifrada, lo que puede provocar cuellos de botella y representa un punto de falla. Cuando se desea aplicar una política eficaz de seguridad, se debe involucrar profundamente a los empleados. Estudios recientes indican que entre los principales problemas de seguridad en las empresas destacan los virus introducidos por empleados al instalar software indebido, los errores humanos, y los actos de vandalismo por empleados descontentos. El tema de seguridad se estudiará con mayor detalle en el capítulo \\[c:dislog\\]. 2.6 Administración Otro elemento que debe considerarse desde las primeras etapas de diseño es la administración de la red. Como se presenta en el capítulo  5, una red bien administrada trae grandes beneficios para la organización. Si el cliente ya cuenta con políticas de administración, puede conocer con precisión cuáles son sus requerimientos de administración. En caso contrario, la terminología propuesta por el modelo OSI puede servir como punto de entrada para tratar de identificar sus necesidades. El modelo de OSI divide el problema de gestión en cinco subsistemas, los cuales se presentan a continuación en el orden en el que típicamente son atendidos por las empresas: Gestión de fallas. Tiene por objetivo detectar, aislar y corregir problemas, reportarlos y darles seguimiento. Gestión de configuración. Orientada a controlar, identificar, colectar información y documentar los objetos administrados (hardware, software, cuentas de usuarios, etc.). Gestión de desempeño. Su función es satisfacer los acuerdos de nivel de servicio (Service Level Agreement, SLA) de manera eficiente, y prever planes de expansión. Gestión de seguridad. Busca monitorear y evaluar las políticas de seguridad, administrar llaves y contraseñas, etc. Gestión de la contabilidad. Este subsistema pretende identificar quién utiliza los recursos, cuánto y para qué. Útil también para planear cambios de capacidad. 2.7 Facilidad de uso Este requerimiento está muy relacionado con los requerimientos de administración y depende de la experiencia del personal responsable de la red y de los usuarios. Busca simplificar en lo posible que la red sea transparente al usuario final a través de mecanismos como servidores de configuración automática (por ejemplo, DHCP), políticas de asignación de nombres, sistemas de seguridad basados en biometría, etc. 2.8 Adaptabilidad Un buen diseño de red debe facilitar la adaptación a nuevas tecnologías y cambios en la operación. La red es una entidad inmersa en un ambiente de continuas transformaciones. Durante el análisis de la red, debe quedar claro si no se contemplan cambios en el corto y mediano plazo en aspectos como: Protocolos de red; topologías de interconexión; prácticas de negocio; flujo de datos, patrones de tráfico; requerimientos de calidad de servicio. La mejor recomendación es seguir un diseño modular y basado en estándares. Deben evitarse soluciones novedosas basadas en equipos propietarios que no han sido probados lo suficiente, o de proveedores cuya solvencia no esté garantizada. 2.9 Costo-beneficio Es más un requerimiento de negocios que técnico, pero está muy relacionado con las decisiones tomadas para los requerimientos técnicos. Por ejemplo, si la disponibilidad es prioritaria, será necesario invertir en equipos altamente fiables y proporcionar cierto nivel de redundancia en la red. En el capítulo  5 se presentarán algunas de las métricas que se utilizan para evaluar la factibilidad de un proyecto de TI. El objetivo del diseño debe ser transportar la máxima cantidad de información satisfaciendo los requerimientos identificados, a un costo financiero dado. El costo financiero incluye tanto el costo de los equipos como los costos recurrentes de operación (pago de licencias, renta de enlaces, etc.). En muchas ocasiones, el mayor costo operativo de la red ha sido la renta de enlaces WAN con circuitos privados, por lo que los primeros esfuerzos para maximizar el costo/beneficio se concentrarán en esa dirección. Por ejemplo, es posible utilizar ingeniería de tráfico y enrutamiento con restricciones para minimizar el tráfico que circula por estos enlaces. También se pueden combinar servicios de voz y datos en un mismo enlace, implementando mecanismos de QoS si es necesario. Otro costo muy elevado en la operación de la red suele ser la capacitación, entrenamiento y nómina del personal involucrado en su gestión. Estos costos pueden reducirse proporcionando un diseño claro y modular de la red, y simplificando y automatizando las tareas de configuración y administración de los equipos. 2.10 Conflictos entre requerimientos Como se ha mencionado, algunos de los requerimientos técnicos entran en conflicto entre sí. Para resolver estos conflictos, es importante definir con el cliente cuál el requerimiento más relevante y hacerlo un elemento central del diseño. De manera similar, se deben asignar pesos a los otros requerimientos en función de los criterios del cliente. A veces la asignación de prioridades es mucho más compleja pues diferentes áreas dentro de la misma organización pueden tener distintas prioridades; en cualquier caso, es necesario documentarlas y tratar de establecer compromisos entre ellas. 2.11 Otras métricas relevantes Como se ha mencionado, las métricas anteriores permiten los objetivos de la red en requerimientos técnicos específicos y cuantificables. Una vez desplegada la red, algunos de estos requerimientos, en particular los de desempeño, se monitorean constantemente para asegurar que la red opera dentro de los parámetros deseables, o si es necesario hacer un nuevo rediseño de la red. Durante la operación de la red también existen otras métricas sumamente relevantes que están íntimamente relacionadas con una gestión de la red y que tienen un impacto directo en su disponibilidad. El IT Process Institute realizó un estudio junto con varias univresidades de Estados Unidos e identificó estas métricas como las que distinguen a las empresas con un gran desempeño, un desempeño mediocre y un desempeño deficiente en la provisión de servicios de TI. Estas métricas son: Mean Time To Repair. 80% de las fallas en TI son debidas a algún cambio (en configuraciones, parámetros, actualización de software, protocolos, etc.) y el 80% del MTTR en se invierte en detectar qué fue lo que se cambió. Una organización bien administrada anticipa, documenta los cambios y analiza su impacto. Una organización mal administrada, no los documenta y cuando se presenta alguna falla en la red, en vez de analizar primero qué se ha modificado, empiezan por reinicializar servidores y equipos de red. En fallos menores los tres tipos de organización resuelven el problema en tiempos similares, pero cuando el fallo es mayor, las empresas bien administradas tardan minutos en corregir el problema, mientras que las de bajo desempeño, pueden tardar horas y hasta días en resolverlo9. First Fix Rate. Esta métrica mide el porcentaje de incidentes que se resuelven correctamente en el primer intento. Las empresas de alto desempeño resuelven el 90% de los incidentes al primer intento, las de medio, el 80%, y las de bajo desempeño, tan sólo el 50%. El principal problema con estas últimas es que los fallos no se trabajan sistemáticamente y no se documentan en una base de datos que pudiera ser consultada cuando se presenta una falla. En cambio, en las empresas de alto desempeño se ha desarrollado una cultura de causalidad y pueden regresar a operaciones mucho más rápidamente, aumentando así la disponibilidad de la red. Change Success Rate. Relacionada con las dos anteriores, esta métrica indica el porcentaje de cambios que no generan incidencias ni requieren de intervenciones posteriores. En las empresas bien administradas se reporta una tasa de 95%; en las de medio desempeño, de 80% y en las de bajo desempeño, de 70%. Merece la pena resaltar que las empresas de alto desempeño son capaces de realizar diez veces más cambios sin que ésto afecte a la red, que las de medio y bajo desempeño. Server to administrator rate Todo lo anterior conlleva a que una empresa bien administrada, que documenta cambios y sigue las mejores prácticas para gestionar la red, requiere de mucho menos capital humano para administrar la red. En el estudio citado, se reporta que en las empresas de alto desempeño un administrador puede gestionar hasta 125 servidores (y equipos de red), mientras que en las de medio y bajo desempeño, esta cifra se reduce a 25. 2.12 Problemas Problema 2.1 En el dimensionamiento de una red, tradicionalmente se consideraba el principio de localidad que sigue una distribución Pareto: 80% del tráfico generado en un determinado segmento (o subred), se mantiene en ese segmento y sólo el 20% restante debe ser encaminado a otros segmentos (o subredes). ¿Por qué hoy se cuestiona la validez de este principio? Problema 2.2 De acuerdo a la ley de Moore, la capacidad de procesamiento de los equipos electrónicos se duplica cada 18 meses. ¿De qué manera esta ley puede afectar el análisis de requerimientos para diseñar una red de comunicaciones? Problema 2.3 Defina disponibilidad y confiabilidad en términos de MTBF  y MTTR. Problema 2.4 ¿Cuáles son los principales elementos que influyen en determinar un valor de MTTR  para un sistema? Problema 2.5 ¿Cuál es la disponibilidad de un equipo de red que anuncia un MTBF  de \\(6,000\\,hr\\) y se supone que el proveedor garantiza un MTTR de \\(4\\,hr\\)? Problema 2.6 En una red telefónica pública, el objetivo de disponibilidad (sin contar la red de acceso), es de \\(99.999\\%\\) (the five nines). ¿A cuántos minutos de fallos al año corresponde este valor? Para la red de acceso, el objetivo es de \\(99.95\\%\\) y el compromiso es de reparar un fallo en cuatro horas. ¿Cuántos fallos un MTTR de \\(4\\,hr\\)? Problema 2.7 Cierto sistema está compuesto por tres elementos \\(A, B, C\\) dispuestos como se muestra en la parte izquierda de la figura. Sus MTBFson de \\(5,000\\), \\(10,000\\) y \\(15,000\\) horas. Por razones de logística, el MTTR de los tres es de 24 horas. ¿Cuál es la disponibilidad del sistema? Aproxime a seis cifras. ¿Cuál es la disponibilidad si el sistema se modifica con la distribución mostrada en la parte derecha de la figura? Problema 2.8 Cierta empresa ha estimado que un minuto de caída en su red le representa una pérdida de \\(\\$500.00\\). ¿Cuánto dinero pierde al año si: La disponibilidad es de \\(99.9\\%\\)? La disponibilidad es de \\(99.99\\%\\)? ¿Cuál es la disponibilidad que debe tener si no puede perder más de \\(\\$30,000.00\\) al año? Problema 2.9 ¿Qué es una aplicación de misión crítica? ¿Cuál es un requerimiento típico de disponibilidad para estas aplicaciones? Problema 2.10   ¿Qué tipo de fallos se toman en cuenta al estimar la confiabilidad de un PBX? ¿La disponibilidad de 99.999%, se refiere a: \\((i)~\\) El servicio residencial; \\((ii)~\\) El servicio comercial; \\((iii)~\\) El servicio de larga distancia; \\((iv)~\\) Las líneas troncales; \\((v)~\\) El conmutador en la central;\\((vi)~\\) todo? Problema 2.11 Calcule la ocupación promedio del área de almacenamiento temporal de un multiplexor estadístico modelado como una cola M/M/1 para los siguientes casos: Diez terminales conectadas. Cada una genera, en promedio, paquetes con longitud de \\(960\\,bits\\) con distribución exponencial cada \\(8\\,s\\). La línea de salida es de \\(2,400\\,b/s.\\) La generación de paquetes cambia a un paquete cada \\(5\\,s\\) en promedio. Repita el punto (a) conectando 16 terminales. Problema 2.12 Si se aumenta la capacidad de almacenamiento de los equipos de enrutamiento y conmutación, puede aumentarse el throughput de la red. ¿Qué consecuencias tendría este razonamiento? Problema 2.13 Un sistema satelital geoestacionario con una tasa de transferencia de \\(64\\,kb/s\\) se usa para enviar mensajes de 512 bytes. Suponiendo que no hay errores e ignorando encabezados, ¿cuál es el máximo throughput si se utilizan ventas de control de flujo de: 1 paquete 15 paquetes 127 paquetes Problema 2.14 Para un enrutador que es capaz de conmutar paquetes a máxima velocidad (wire-speed) en sus 30 puertos \\(10Base\\,T\\). ¿Cuál es su velocidad de conmutación en paquetes/s si el tamaño de los paquetes es de \\(64\\) bytes? (No olvide considerar el preámbulo 8 bytes y la separación entre tramas 12 bytes) ¿Si los paquetes son de \\(1,500\\) bytes? Problema 2.15 Para un switch FastEthernet, ¿Cuál es el throughput máximo en paquetes/s considerando un tamaño de paquete de \\(1,518\\) bytes? ¿Cuál es la eficiencia del enlace de salida si las tramas son enviadas a wire-speed? Problema 2.16 ¿De qué manera el tamaño del paquete (MSS) afecta la eficiencia de la red? A menor tamaño, más paquetes circulan en la red, por lo que aumenta la eficiencia. A mayor tamaño, aumenta el ancho de banda utilizado, por lo que aumenta la eficiencia. A menor tamaño, menor es la carga útil, por lo que disminuye la eficiencia. A mayor tamaño, mayor inequidad, por lo que disminuye la eficiencia. | Problema 2.17 Mencione dos razones por las que es deseable limitar el tamaño de las colas en los equipos de interconexión en redes TCP/IP. Problema 2.18   Considere una aplicación que transmite voz sobre IP. La frecuencia máxima de la señal se corta a \\(4\\,kHz\\) y es digitalizada utilizando PCM con 8 bits por muestra. Cada paquete contiene \\(30\\,ms\\) de audio y es transmitido con RTP/UDP/IP (= 40 bytes de encabezado). ¿Cuál es la carga útil de los paquetes? ¿Cuál es la eficiencia de la transmisión? ¿Cuál es el ancho de banda requerido? | Si la aplicación utiliza ahora un códec \\(G.723.1\\) (\\(6.4\\,kb/s\\)), ¿Cuál es la carga útil de los paquetes? ¿Cuál es la eficiencia de la transmisión? ¿Cuál es el ancho de banda requerido? Problema 2.19 Al medir en un analizador de protocolos el flujo de una conversación VoIP que utiliza RTP/UDP/IP (40 bytes de encabezado), se observa que consume un ancho de banda de \\(40\\,kb/s\\) y que genera 100 paquetes por segundo. ¿Cuál es la tasa del códec? ¿Cuál es la eficiencia? Problema 2.20 Llene en la siguiente tabla el ancho de banda requerido en cada caso IPv4 IPv4 IPv6 IPv6 25ms 40ms 25ms 40ms G.726 (32kb/s) G.723 (6.4kb/s) Problema 2.21   Encuentre el retardo de ida y vuelta mínimo para la red que se muestra en la figura sabiendo que: La tecnología de red local es FastEthernet en ambos extremos; el enlace WAN es de \\(256\\,kb/s\\) y cubre una distancia de \\(1,000\\,km\\); el retardo de conmutación es de \\(10\\,\\mu s\\); no hay congestión en ninguno de los segmentos indicados, se envía una trama de \\(2\\,kB\\) al destino y éste responde con un acuse de recibo de 64 bytes. ¿Esta red está limitada en ancho de banda o en latencia? Explique. ``` Problema 2.22 ¿Cuáles son los pasos a seguir para analizar la latencia de un enlace? Problema 2.23 Se desea transmitir un archivo de \\(512\\,kB\\) entre dos ciudades separadas \\(1,000\\,km\\) a través de i) un enlace E1 (\\(2.048\\,Mb/s\\)) y ii) un enlace de \\(1.12\\,Gb/s\\). ¿Cuál es el retardo de propagación en cada caso? ¿Cuál es el retardo de transmisión en cada caso? ¿Cuál de las dos redes está limitada en latencia? Explique. Suponga que se tienen cuatro enlaces E1 entre las dos ciudades y que se transmite en paralelo una cuarta parte del archivo por cada enlace. ¿En cuánto tiempo se transmite todo el archivo en este caso? Problema 2.24 Una imagen con resolución de \\(640\\times 480\\) y 3 bytes por píxel debe ser transmitida entre dos puntos separados a \\(250\\,km\\). Antes de su transmisión, la imagen se procesa por un compresor que reduce su tamaño, en promedio, 10:1. Se utiliza UDP/IPv4 (28 bytes) como medio de transporte, en paquetes de \\(1\\,500\\) bytes y se transmiten todos los paquetes uno tras otro (no hay problemas de control de flujo) ¿cuánto tiempo tarda en transmitirse la imagen en: POTS a 56 kb/s Cable a 512 kb/s Un enlace a 2 Mb/s? Problema 2.25 Derive y explique el factor \\(a\\) que relaciona: \\(V\\), la capacidad del enlace; \\(L\\), la distancia recorrida; \\(b\\), el tamaño medio del paquete; y \\(k\\), una constante del tiempo de propagación en un kilómetro. ¿Cuál es el valor del factor en una LAN? ¿En un enlace de \\(1\\,Gb/s\\) de \\(1,000\\,km\\)? Problema 2.26 Se envía información con un protocolo de ventanas deslizantes por un enlace de \\(622\\,Mb/s\\). El tamaño de la ventana de transmisión es de \\(24\\,kB\\) y la distancia entre transmisor y receptor es de \\(1,000\\,km\\). La velocidad de propagación en el medio es de \\(200,000\\,km/s\\). ¿Cuál es el retardo de propagación? ¿Cuál es el retardo de transmisión? ¿Cuál es el throughput maximo (en Mb/s)? ¿Cuál es la eficiencia del enlace? Este no es un buen modelo para representar tráfico de datos, pero sigue siendo popular dada su sencillez. E0=64,000bits/s Más precisamente, \\(299,792,458\\,km/s.\\) Kim, G., IT Service Management Metrics that Matter, Tripwire White Paper, 2007 "],["caracterización-de-la-red-y-del-tráfico-generado-por-las-aplicaciones.html", "Capítulo 3 Caracterización de la red y del tráfico generado por las aplicaciones 3.1 Caracterización de la topología 3.2 Desempeño de la red actual 3.3 Caracterización del flujo 3.4 Problemas", " Capítulo 3 Caracterización de la red y del tráfico generado por las aplicaciones Con mucha frecuencia un proyecto de diseño de redes está orientado a la evolución o crecimiento de una infraestructura ya existente, y rara vez hacia la creación de una red completamente nueva. Por esta razón, es muy importante iniciar el proyecto con un estudio detallado de las características de la red existente y del tráfico que circula por ella. Este estudio permitirá identificar si los objetivos de diseño son realistas, se pueden detectar cuellos de botella existentes o potenciales y se podrá garantizar la interoperabilidad del diseño con la infraestructura actual. Además, dará una referencia de base (baseline) contra la cual sea posible evaluar el desempeño del sistema una vez implementado. A pesar de estas ventajas, la caracterización de la red suele hacerse de manera incompleta o superficial argumentando falta de tiempo o suponiendo que la red es bien conocida. A menos de que la organización que administra la red haya hecho una muy buena labor de caracterización, definición de procedimientos y sea sumamente disciplinada en la documentación de los diversos tipos de cambios que se pueden realizar en dispositivos, topología, servicios, etc., la realidad es que un buen análisis en la fase de planeación del modelo de proceso es indispensable. Habiendo dicho esto, se habrá de reconocer que la necesidad de terminar lo antes posible con el proyecto puede ser la consecuencia de necesidades de negocio reales y justificadas. Un buen administrador del proyecto debe poder negociar un balance de prioridades y empujar la implementación de algunos servicios, localidades o dispositivos para versiones futuras de la red, y definir la forma de trabajo más eficiente posible para acortar tiempos sin perder calidad. Sea cual sea el camino, en la gran mayoría de los proyectos en donde estos pasos se omiten o se recortan demasiado, el resultado es que el tiempo ganado con las omisiones, se perderá con creces en las fases finales del proyecto. La caracterización de la red implica identificar claramente su topología, los repositorios y consumidores de información, los volúmenes de tráfico que son intercambiados y la estructura protocolaria para lograrlo. 3.1 Caracterización de la topología La caracterización de la topología empieza por la obtención de un mapa de la red que describa su configuración física y lógica, pero abarca mucho más que eso: se deben obtener y documentar las políticas de asignación de nombres y direcciones y el esquema de direccionamiento actualmente utilizado. También se habrá de observar el tipo y estado que guardan los esquemas de cableado y si existen restricciones (ambientales, arquitectónicas, legales) para instalar alguna infraestructura de capa física. Mucha de esta información fue recabada en la fase de visión y alcance. Durante la fase de planeación, se recaba la información adicional necesaria para completar la caracterización de la red. La información recabada debe ser examinada y validada tratando de asegurar que no se han hecho cambios importantes no documentados. Partir de suposiciones erróneas es un grave riesgo que puede comprometer seriamente el éxito del proyecto. 3.1.1 Mapa de la red El mapa de la red comienza por un conjunto de esquemas de interconexión con diferentes niveles de abstracción en donde se presenta la organización topológica de la red. Existen diversas herramientas que permiten automatizar la construcción y/o validación de estos esquemas. Al integrar el mapa de la red, se debe crear un documento lo más completo posible en el que se especifique, cuando corresponda: la ubicación física de las instalaciones: ciudad, edificio, piso y, en algunos casos, hasta cubículo donde se encuentren los equipos principales (nodos de conmutación, servidores, etc.); el personal responsable de los diferentes elementos de la red; los enlaces WAN entre ciudades especificando tecnología, capacidad y restricciones; los enlaces CAN y LAN entre edificios especificando igualmente la tecnología utilizada, sus capacidades y restricciones. los puntos de acceso al proveedor de acceso a Internet y los servicios contratados; los servidores de acceso remoto y de VPNs, y las políticas de acceso; las políticas y procedimientos de seguridad; las políticas y procedimientos de administración; la estructura lógica de la red. Caso de estudio: Topología física y topología lógica En una empresa de servicios con cobertura nacional, el servicio de correo enfrentaba serios problemas de rendimiento, pero extrañamente, parecían afectar solamente la comunicación entre algunas ciudades. Por ejemplo, la ciudad \\(F\\) en la figura 3.1 podía tener problemas de comunicación con la ciudades \\(G\\), \\(I\\) y \\(J\\), pero no con las demás. Algunas ciudades no tenían problema alguno. Al estudiar las condiciones de la organización, se encontraron dos elementos interesantes. En primer término, el departamento responsable de administrar el servicio de correo electrónico no era el mismo que se hacía cargo de la administración de los enlaces de comunicación entre las diferentes ciudades, tampoco reportaban al mismo jefe, y en realidad tenían poca comunicación entre sí. En segundo lugar, la topología de la red de correo electrónico (topología lógica) era una estrella simbolizada por las líneas rectas de la figura 3.1: todos los servidores de correo electrónico avanzaban el correo para otras ciudades a las oficinas centrales en la ciudad \\(A\\), y un servidor central ahí lo redistribuía hacia las ciudades destino. Figura 3.1: Topología física y lógica de un servidor de correo Por su parte, los enlaces (topología física), representados por las líneas quebradas en la figura, mostraban la topología de estrellas interconectadas a través del triangulo \\(A\\), \\(E\\), \\(H\\). Al enviar un mensaje de correo electrónico de la ciudad \\(F\\) a la ciudad \\(G\\), el servicio de correo electrónico asumía una topología con una única estrella y lo enviaba a la ciudad \\(A\\), para que de ahí el mensaje fuera enviado a la ciudad \\(G\\). Dada la topología física de los enlaces, el mensaje salía de \\(F\\) hacia \\(E\\), de ahí viajaba a \\(A\\), hasta llegar al servidor distribuidor de correo electrónico, quien entonces lo enviaba de vuelta sobre el mismo enlace entre \\(A\\) y \\(E\\), y de ahí viajaba hasta \\(G\\). El mensaje recorría entonces cuatro segmentos de red, cuando idealmente solo necesitaba recorrer dos, y los dos viajes de sobra se daban sobre un mismo segmento de red. Una vez identificado el problema, se reconfiguraron los servidores de correo locales para ofrecer un servicio distribuido coherente con la arquitectura de la red 3.1.2 Asignación de nombres y direcciones Conocer el esquema de asignación de nombres nos permitirá acotar la solución de diseño de red. El esquema de direccionamiento puede afectar el diseño propuesto para satisfacer los requerimientos técnicos. Por ejemplo, puede ser necesario el uso de traductores de direcciones (NAT, Network Adress Translation) o el renunciar a sumarización de rutas si los protocolos actualmente utilizados no soportan este esquema10. Durante la caracterización de la red es necesario distinguir cuáles son las prácticas comunes para asignar nombres a dispositivos y servicios. También deberá quedar clara la estrategia de asignación de direcciones. Por ejemplo, deberá tenerse una respuesta clara a las siguientes preguntas: ¿Se sigue o promueve un modelo de direccionamiento jerárquico? ¿Se utiliza o puede utilizarse la sumarización de direcciones? ¿Se utiliza o puede utilizarse una estrategia de asignación dinámica de direcciones? ¿Se cuenta con un rango de direcciones libre suficiente para los objetivos de diseño? ¿Se debe negociar un bloque de direcciones? ¿Se utiliza o puede proponerse un esquema de direccionamiento privado? 3.1.3 Caracterización de los medios de transmisión Es imprescindible realizar este estudio para poder satisfacer los requerimientos de escalabilidad y disponibilidad. Al recabar información referente a los medios de transmisión, es decir, a la capa física del modelo de OSI, se deben identificar las tecnologías utilizadas tanto en la red local como en las interconexiones MAN y WAN. También se debe identificar la ubicación y estado de los puntos de conexión: paneles de parcheo, clóset de alambrado, puntos de cruce de cableado vertical y horizontal, etcétera. Para una red CAN, Campus Area Network), debe señalarse claramente cuál es la tecnología de interconexión entre edificios y cuál es la distancia que los separa. La experiencia indica que se es más informal al desplegar una red local, por lo que es ahí donde se sugiere que se ponga mayor énfasis en la caracterización. Al detectar el tipo de cableado y/o de red inalámbrica que se utiliza, se pueden identificar problemas potenciales al diseño propuesto. En lo que concierne al cableado de la red, se deberá detectar si se siguen correctamente las normas de cableado estructurado; si la categoría de cables, rosetas, conectores, etc. es compatible con la velocidad de transmisión deseada; si se respetan las distancias máximas, los códigos de color para los conectores; etc. Se deberá verificar cuántos pares de cable están siendo utilizados y en qué estado se encuentran. Por supuesto, también deberá documentarse la cantidad de pares disponibles y en qué áreas se encuentran. Además, se debe verificar que la ductería tiene espacio suficiente para introducir más cable de ser necesario. Un ducto de par trenzado nunca debe estar ocupado a más del 50% de su capacidad. Si se utilizan redes inalámbricas, se debe verificar que las tarjetas de red y los puntos de acceso están homologados a las normas mexicanas. Así mismo, es necesario verificar que los puntos de acceso están configurados correctamente, que no interfieren entre sí y que el radio de cobertura satisface los nuevos requerimientos. 3.1.4 Restricciones ambientales y arquitectónicas Durante el recorrido de las instalaciones se debe prestar mucha atención al entorno en el que éstas se ubican con el fin de identificar riesgos que pudieran comprometer seriamente la viabilidad del proyecto en etapas posteriores. Por ejemplo, si el edificio se encuentra en una zona con riesgos de inundaciones (alta precipitación pluvial, cercano a un río o laguna), se debe buscar que los nodos de interconexión (y en general, el centro de cómputo) se ubiquen al menos en el primer piso. De hecho, esta es una práctica recomendada para la seguridad física de las instalaciones de TI. Si la instalación se encuentra en una zona de vibraciones anormalmente altas (por las características de la empresa, por encontrarse muy cerca de una vía de ferrocarril, etcétera.), el tipo de conector a utilizar debe ser más robusto. Así mismo, se deben prever revisiones frecuentes de las condiciones del cableado. Es posible que el edificio sea rentado o que sea de interés histórico y esté protegido por leyes especiales. En estos casos, será importante garantizar que se cuenta con los permisos necesarios para instalar la infraestructura de red necesaria (perforaciones para instalar cableado en red local, obra civil para instalar antenas, etcétera.) Para interconectar dos edificios, aún si están relativamente cercanos, se debe contar con permiso de vía. Si se piensa utilizar algún medio inalámbrico (los enlaces láser suelen ser una excelente opción) se debe verificar que se cuenta con línea de vista y que no hay razones para suponer que ésta va a perderse en el mediano plazo. También es conveniente identificar y registrar que se cuenta con las condiciones adecuadas de ventilación, control de temperatura, suministro de energía eléctrica regulada y fuentes de poder no interrumpible (UPS). Se debe prestar una atención particular a ambientes extremos. Por ejemplo, en ciudades con muy altos niveles de humedad y temperatura, equipos convencionales de interconexión pueden no funcionar correctamente si no se cuenta con una instalación ambiental apropiada. De forma similar, en naves industriales con maquinaria eléctrica pesada, las inducciones electromagnéticas pueden afectar severamente las transmisiones en cables no blindados. Caso de estudio: Equipo de aire acondicionado En una empresa financiera, se decidió instalar equipos de aire acondicionado. Para no alterar la arquitectura del edificio, se determinó colocar los equipos en los clósets de cableado, encima de los concentradores y enrutadores de la red. Una tarde de invierno, algún empleado consideró conveniente apagar los equipos de aire acondicionado pues la temperatura no justificaba su utilización. Al condensarse el líquido de estos equipos, éste cayó hacia los equipos de interconexión, los cuales, naturalmente, dejaron de funcionar. 3.2 Desempeño de la red actual Evaluar el desempeño de la red actual es fundamental para establecer una referencia a partir de la cual se puedan comparar las prestaciones del nuevo diseño. Esta evaluación también permite identificar potenciales cuellos de botella y puntos críticos donde habrá que prestar atención especial al diseño. La evaluación del desempeño de una red puede realizarse a través de modelos analíticos, de simulación y mediante mediciones directas. En esta sección se plantea brevemente esta última opción y las técnicas de modelado se presentarán en el capítulo 7. Para colectar información sobre el estado de la red y sus equipos, se medirán variables y parámetros de desempeño de la red, lo cual suele ser un proceso largo y complejo. Hay que decidir lo más pronto posible cuáles son las variables a estudiar, el tipo de herramienta a utilizar, la duración del experimento y sobre qué puntos de la red llevarla a cabo. Para todos estos elementos no hay una respuesta única, pues dependen completamente de los objetivos del estudio. En cuanto a los puntos de evaluación, los primeros candidatos son los segmentos en la red dorsal y aquellos por donde corren los flujos de misión crítica, así como los segmentos que interactuarán con el nuevo diseño. 3.2.1 Herramientas de recolección Existen diversas herramientas que nos permiten obtener distintos parámetros de desempeño, y con distintos niveles de detalle. Es muy importante conocer la utilidad y las características (sus capacidades y nichos de aplicación) de las herramientas a nuestra disposición pues el éxito del estudio dependerá de la selección de la herramienta apropiada. Entre las herramientas típicas para realizar estudios de evaluación de desempeño se encuentran los monitores y analizadores de protocolos, los agentes y protocolos de administración (estudiados en el capítulo 4), las bitácoras y guiones de administración en sistemas operativos y las sondas especializadas tanto activas (que introducen un flujo de evaluación en la red) como pasivas. Hoy en día es posible encontrar herramientas de monitoreo muy sofisticadas, que incorporan agentes inteligentes para apoyar al administrador de la red a detectar posibles problemas en la red y proponerle alternativas de solución. Dicho esto, sigue siendo de primordial importancia el saber interpretar adecuadamente la información que estas herramientas ofrecen. Por ejemplo, al analizar una gráfica de porcentaje de utilización como la que se muestra en la figura 3.2, es importante considerar que los analizadores de protocolos muestran la carga transportada en algún segmento de la red, la cual puede ser distinta a la carga ofrecida a la red. Figura 3.2: Una vista típica de un analizador de protocolos en el que se observa la utilización del segmento, posibles indicadores de congestión, y la distribución algunas de las características de los protocolos observados También se debe tener alguna idea de lo que se está buscando o de lo que se espera observar en el estudio. Por ejemplo, la figura 3.3 muestra otra pantalla del analizador en el que se reporta cómo se distribuye la capacidad del segmento utilizada entre los distintos protocolos detectados, junto con otras estadísticas de utilización (cantidad de bytes y de tramas medidos, número de tramas en difusión, errores detectados, etcétera.). Más adelante en este capítulo se presentan algunas cifras de lo que se considera una red saludable. Figura 3.3: Otra vista del analizador de protocolos que permite conocer la distribución de cómo se está utilizando la red Este tipo de gráfica permite detectar si hay protocolos que no deberían en principio transitar en la red, si existen protocolos que envían demasiadas tramas de difusión, cuáles son las aplicaciones/protocolos más utilizados, etcétera. Los monitores y analizadores de protocolos se instalan en el segmento de red de interés y recaban información de los flujos observados. Esto significa que para tener una idea global de la red, habría que colocar un analizador en cada uno de los segmentos de interés y correr el monitoreo durante el tiempo suficiente. En ciertos casos es necesario hacer el estudio de esta manera, pero la mayoría de las veces, es suficiente incorporar agentes de monitoreo en los mismos dispositivos de red (las sondas RMON) que se incorporan al sistema de administración de red, como se verá en el capítulo 4. 3.2.2 Periodo y frecuencia de recolección En un estudio de evaluación de desempeño, frecuentemente los parámetros de interés son promedios evaluados en una ventana de tiempo. La selección del intervalo, su duración y la frecuencia de captura de los valores son fundamentales para poder tener una interpretación adecuada los resultados obtenidos. Consideremos, por ejemplo, que se desea evaluar la red en condiciones de carga normal, pero el muestreo se hace durante un período atípico (a la hora de entrada, muchos empleados encienden su computadora y se generan muchos mensajes de difusión DHCP; en fin de mes o al cierre del ciclo, cuando hay picos de operación; etcétera.). Entonces, se tendrá una imagen distorsionada del tráfico y se tenderá a sobredimensionar la red. En otras ocasiones, son precisamente los picos de tráfico los eventos de interés y es donde se deberán realizar mediciones especialmente detalladas. Dependiendo del giro de la empresa, se deberá tener una idea de la forma en que la utilización variará. Por ejemplo, es común que el tráfico en la red se incrementa al llegar el fin de mes o el cierre del año o del periodo fiscal. El incremento de tráfico en estos periodos puede ser considerable y es muy importante que la red esté en condiciones de proporcionar un servicio apropiado en estos periodos críticos. Para poder diseñar e interpretar correctamente este tipo de estudios, también es importante conocer las características de operación dentro de la organización. Por ejemplo, se detectarán picos hacia el servidor de correo si en las mañanas los empleados entran más o menos a la misma hora y suelen revisar y responder a sus mensajes. En ciertas organizaciones se detectan picos similares inmediatamente antes del almuerzo y del fin de la jornada pues la política organizacional es tratar de evitar dejar asuntos. Algunas empresas hacen un uso intensivo de su red WAN en horas no hábiles para consolidar bases de datos y distribuir respaldos. En esos casos, es necesario determinar si deben realizarse mediciones detalladas durante este periodo. Con esta información y habiendo identificado claramente el objetivo del estudio, se procede a diseñar el mecanismo de recolección. El periodo deberá ser suficientemente largo para ser significativo; idealmente, deberá cubrir un ciclo completo de operación del comportamiento a evaluar. La evaluación deberá realizarse sobre una población (nodos, enlaces, aplicaciones) representativa. La selección de los segmentos debe comenzar obviamente por aquellos en los que se ubican servidores importantes y los segmentos en donde hay grupos grandes de usuarios, tanto como los segmentos por donde habrá de fluir el tráfico en el camino de un sitio al otro. La frecuencia de recolección, es decir, la intensidad con la que se evalúan las métricas de interés, establece un compromiso entre el nivel de detalle deseado y la cantidad de información a almacenar y procesar. La decisión adecuada se tomará en función del objetivo del estudio: Muestreando en el orden de segundos, se pueden detectar problemas a nivel protocolos de comunicación: retransmisiones por temporizadores mal configurados, tormentas de difusión, enrutadores que publican rutas demasiado frecuentemente, etcétera. Para poder llevar a cabo un análisis de desempeño y obtener una referencia de base sobre el comportamiento general de la red, suelen realizarse mediciones con intervalos de uno a cinco minutos. Para identificar patrones globales de utilización, períodos de picos de operación y gráficas de tendencias, muestreos del orden de 5 a diez minutos suelen ser utilizados. 3.2.3 Algunas métricas de desempeño Dependiendo del tipo de red (LAN, WAN) y de la tecnología utilizada, existen distintos parámetros para evaluar la tasa de error observada y para saber si ésta es aceptable. En todos los casos, es deseable correlacionar la tasa observada contra las métricas de carga y utilización para detectar cuellos de botella o equipo defectuoso en la red. Considerando que ethernet es la tecnología dominante en redes locales, a continuación se presentan algunas de las métricas comunes de error y sus valores recomendables. Número de tramas con CRC incorrecto. La recomendación es que no debe haber más de una trama por cada megabyte de información. Se evita definir esta métrica como un porcentaje del número de tramas para evitar la dependencia con el tamaño de las tramas. Número de colisiones. En una red que trabaja correctamente, las colisiones detectadas no deberán exceder el 0.1% de los paquetes emitidos. A primera instancia esto puede parecer extraño dado que las colisiones son el mecanismo natural del control de acceso en ethernet. Sin embargo, la mayoría de las colisiones se detectan durante el preámbulo y no son tomadas en cuenta como tramas en colisión. Porcentaje de paquetes perdidos. En una red bien dimensionada, el porcentaje de paquetes perdidos debe ser inferior al 1%. Los dispositivos de red y los equipos terminales pueden introducir retardos adicionales o comportamientos que pueden afectar el desempeño y deben ser tomados en esta fase. Por desgracia, son muchos los factores a considerar y se requiere de mucha experiencia para poder identificarlos. A continuación se mencionan algunos de ellos. En TCP/IP, los valores por omisión para los buffers de transmisión y recepción pueden no ser adecuados para la aplicación específica. Por ejemplo, si el espacio reservado para el buffer de recepción es pequeño, el protocolo anunciará una ventana de recepción muy pequeña, que limitará el desempeño de la red. La configuración y la granularidad de los temporizadores también pueden afectar el desempeño: temporizadores mal configurados y que no se adapten dinámicamente a las condiciones de la red pueden ocasionar retransmisiones de información innecesarias. La granularidad de los temporizadores en muchas implementaciones de TCP/IP es de \\(500\\,ms\\), un valor que puede resultar demasiado grande para reaccionar a condiciones de congestión en ciertas implementaciones. La implementación de las pilas de protocolos en muchos sistemas operativos populares realizan copias de información mientras ésta es transferida de una capa a otra. Estas copias de memoria a memoria pueden degradar el desempeño de los equipos involucrados. El mecanismo de atención a interrupciones de entrada-salida puede ser muy ineficiente. Al enviar o recibir tramas por las interfaces de red, los cambios de contexto en los sistemas operativos también pueden introducir retrasos considerables, degradando así el desempeño de las aplicaciones. Debe considerarse que existen varios sistemas complementarios a las aplicaciones de red y que también deben ser tomados en cuenta. Por ejemplo, deberá evaluarse el tiempo de respuesta de los servidores de nombres (DNS) y aunque su efecto es menor de los servidores de configuración. Finalmente, se debe evaluar el desempeño de los nodos de conmutación para identificar si ellos representan un posible cuello de botella. En particular, se debe medir la tasa de ocupación media en los buffers de salida, la cual debe ser muy baja, y el porcentaje de utilización del CPU. De acuerdo a recomendaciones de Cisco, este porcentaje debe ser menor al 75% en intervalos de muestreo de 5 min. Al evaluar los nodos de conmutación, se debe verificar que cuentan con los elementos necesarios para satisfacer los requerimientos de diseño. Por ejemplo, es importante identificar la cantidad de memoria disponible, la versión de sistema operativo y los protocolos de enrutamiento soportados. Podría también ser necesario detectar si el equipo cuenta con los elementos necesarios para dar soporte a los requerimientos de calidad de servicio identificados. Ejemplo 3.1 Si bien es cierto que prácticamente todos los enrutadores actuales soportan el protocolo IPv6, la dominante mayoría lo hace por software en la actualidad. El throughput sería muy inferior al conmutar paquetes IPv6 comparado con el obtenido para paquetes IPv4, que pueden ser conmutados por hardware en muchos equipos. Similarmente, una empresa que desea migrar su red de IPv4 a IPv6 (o permitir la coexistencia de los dos protocolos), debe asegurarse que sus equipos cuentan con la capacidad necesaria para aumentar tanto la memoria RAM, donde se almacenan las tablas de enrutamiento (con direcciones mucho mayores), como del firmware, donde se implementan muchas de las funcionalidades inherentes al nuevo protocolo. 3.2.4 Presentación de resultados La información recolectada durante un cierto intervalo de tiempo debe ser presentada de manera tal que permita sacar conclusiones útiles. Los datos obtenidos pueden ser presentados en un listado, por medio de una gráfica, o bien mediante un resumen estadístico de los mismos. La representación adecuada depende, una vez más, de los objetivos de la prueba. Gráficas de tendencia Una gráfica de tendencia representa la variable de interés contra el tiempo. Es una manera muy cómoda de visualizar su comportamiento y permite identificar rápidamente si la variable presenta comportamientos cíclicos, cuándo hay picos, de qué orden son y cuánto duran, etcétera. Al capturar la información necesaria para producir las gráficas de tendencia, es posible entender con mayor claridad el compromiso entre el período y la frecuencia de recolección en función de los objetivos de estudio, discutidos en los párrafos anteriores. Por ejemplo, las gráficas de las figuras 3.4 y 3.5, muestran la tasa de salida de un enrutador (en bytes por segundo) en un periodo de un día y de una semana. En la primera gráfica se desea tener un mayor nivel de detalle, por lo que la frecuencia de captura debe ser mayor. La gráfica de tendencia semanal (figura 3.5) únicamente se utiliza para tener una idea del comportamiento global de la variable por día. Se puede observar claramente un comportamiento cíclico relacionado con la actividad durante las horas hábiles. El hueco largo sin actividad al centro de la gráfica corresponde a un fin de semana con un día festivo. Figura 3.4: Tasa obtenida (en bytes/s) en la interfaz de salida de un enrutador comercial durante un día Figura 3.5: Tasa obtenida (en bytes/s) en la interfaz de salida de un enrutador comercial durante una semana 3.2.5 Análisis estadístico de redes En general, es imposible determinar con exactitud el valor que tomarán las métricas de desempeño de interés, por lo que se les suele considerar como variables aleatorias (V.A.) a las que se debe aplicar algún análisis estadístico para poder interpretar correctamente los resultados obtenidos. Al considerar las métricas de interés como V.A., se debe obtener un número grande de muestras antes de poder sacar conclusiones sobre ellas. Al agrupar las muestras obtenidas en un histograma que represente la frecuencia de ocurrencia de los valores obtenidos, éste se aproxima a la función de densidad de probabilidad (pdf, probability density function**). La pdf de una variable aleatoria indica qué tan probable es la obtención de cada uno de sus valores y contiene todas sus propiedades estadísticas. Figura 3.6: Histograma que representa la función de densidad de probabilidad de una variable aleatoria discreta En la figura 3.6 se observa una curva con un solo pico o moda. Se trata de una pdf monomodal. Es bastante común que en redes de comunicaciones se encuentren V.A. con varios picos. Por ejemplo, al graficar el tamaño de las tramas en una red local, típicamente se encontrarán dos picos muy notorios en los valores de 64 y 1,500 bytes. Esto se debe principalmente al hecho de que dicho tráfico se compone por lo general de tramas de control (acuses de recibo, solicitud de conexión, etcétera.) y tramas de aplicaciones que intercambian grandes volúmenes de información. Sumarización estadística Si bien la pdf contiene toda la información estadística de la V.A. de interés, puede resultar muy poco práctica para tomar decisiones, sobre todo cuando se desean hacer comparaciones entre varias V.A. Por ejemplo, al evaluar varias opciones de diseño de acuerdo a su incidencia sobre las métricas como retardo, carga y utilización, será difícil hacer una comparación objetiva al contar únicamente con los histogramas obtenidos para cada caso. Es por estas razones, entre otras, que se busca sumarizar el comportamiento de una V.A. en una serie de valores puntuales conocidos como indicadores. Entre los indicadores más utilizados se encuentran los indicadores de tendencia media y los de dispersión. Indicadores de tendencia media Los indicadores de tendencia media son la media aritmética o promedio, que se obtiene al sumar todos los valores obtenidos entre el número de muestras; la moda, que es el valor más observado, es decir, el obtenido un mayor número de veces; y la mediana, que es el valor justo al 50% del área bajo la curva de la pdf de la V.A. Ejemplo 3.2 Para cierta V.A. se han obtenido las siguientes muestras: \\(1,~~3,~~ 3,~~ 3,~~ 4,~~ 8,~~ 12,~~ 15,~~ 30\\) \\(N=9\\qquad \\Sigma \\text{valores} = 79\\) \\(Media = \\frac{79}{9} = 8.\\bar{7}\\qquad Mediana = \\text{valor}[5] = 4\\qquad Moda = 3\\) El promedio es el indicador más popular para sumarizar una V.A., pero muchas veces no es el adecuado. Como se observa en la figura 3.7, en una distribución simétrica, el promedio, mediana y moda caen en el mismo lugar, pero en una distribución asimétrica no necesariamente. En el caso de redes de comunicaciones las distribuciones son típicamente asimétricas. Figura 3.7: Indicadores de tendencia media en distribuciones monomodales simétricas y asimétricas Si los datos son discretos y pueden ser clasificados, es probable que la moda sea el indicador apropiado. Por ejemplo, considere un enrutador con tres interfaces de salida del que se desea conocer cuál es la interfaz más utilizada. En este caso, el promedio no tiene ningún interés. Por regla general, el promedio es relevante cuando el valor total de la métrica puede ser de interés, aunque si la pdf está sesgada, la mediana puede ser más representativa pues con frecuencia lo que nos interesa es el indicador de tendencia central. Ejemplo 3.3 Para cierto servidor de base de datos, se han obtenido los siguientes tiempos de respuesta (valores en milisegundos): \\[20,~~20,~~20,~~30,~~40,~~50,~~60,~~60,~~70,~~80,~~940,~~950.\\] La media es de \\(195\\,ms\\) y la mediana de \\(55\\,ms\\). Claramente la mediana es más representativa de la realidad, pues la distribución está muy sesgada por las dos transacciones \"largas\". De hecho, el 83% de las mediciones está por debajo del promedio. Entre los errores más comunes que se cometen al resumir una variable aleatoria a un indicador de tendencia media, está el emplear los promedios sin tener en cuenta su dispersión. Por ejemplo, muy pocas veces es significativo el calcular el promedio de valores notablemente diferentes. Otro error que se debe evitar al trabajar con promedios es el llamado juego de radios, que se genera al comparar valores divididos con bases distintas, como se muestra en el ejemplo siguiente. Desgraciadamente, esta técnica se encuentra con cierta frecuencia en estudios comparativos y benchmarks de productos comerciales. Ejemplo 3.4 Para tratar de comparar el desempeño de dos tipos de enrutadores, \\(A\\) y \\(B\\), se evalúa el tiempo total de conmutación de cada uno sometido a dos condiciones de carga distintas, \\(L_1\\) y \\(L_2\\), obteniendo los resultados siguientes: Equipo \\(L_1\\) \\(L_2\\) Promedio \\(A\\) \\(10\\,s\\) \\(20\\,s\\) \\(15\\,s\\) \\(B\\) \\(20\\,s\\) \\(10\\,s\\) \\(15\\,s\\) Suponiendo que en condiciones de operación la proporción de \\(L_1\\) es similar a la de \\(L_2\\), con los promedios obtenidos no hay motivos para preferir un enrutador sobre el otro. Considere ahora qué sucede si se desea \"normalizar\" los resultados en relación con el sistema B. La normalización es una práctica común para eliminar las unidades y para restarle importancia al valor absoluto de las variables de estudio. Equipo \\(L_1\\) \\(L_2\\) Promedio \\(A\\) \\(10/20= 0.5\\,s\\) \\(20/10=2\\,s\\) \\(1.25\\,s\\) \\(B\\) \\(20/20=1\\,s\\) \\(10/10=1\\,s\\) \\(1\\,s\\) ¡Ahora parecería ser que el enrutador \\(A\\) es 25% más lento que \\(B\\)! Por supuesto, de haber normalizado con respecto al enrutador A, los resultados serían exactamente los contrarios. Indicadores de dispersión Los indicadores de tendencia media por sí solos pueden dar una información muy limitada sobre el comportamiento de la variable de estudio. Estos indicadores deben estar siempre acompañados de alguno que permita tener una idea sobre la variabilidad que existe entre los valores que puede tomar la variable. Estos son los indicadores de dispersión. Para una distribución unimodal y simétrica, el indicador de dispersión más común es la varianza o su raíz cuadrada, la desviación estándar. También se suele utilizar el coeficiente de varianza, que es la razón entre el promedio y la desviación estándar. Si la distribución no es simétrica no debería utilizarse la varianza. En caso de que ésta esté acotada, se puede especificar el rango, es decir, los valores máximo y mínimo que la variable puede tomar. En otro caso, se deben utilizar los percentiles. Un percentil es el punto en el que el área bajo la curva de la función de distribución acumulativa alcanza un cierto porcentaje. Por ejemplo, el percentil 5% indica que el 5% de todos los valores obtenidos para la distribución son iguales o menores a ese punto. Este valor podría ser equivalente en algunos casos al valor mínimo en una distribución acotada. Los percentiles son de mucha utilidad y comúnmente utilizados pues eliminan los valores que son atípicos (outliers) y que podrían sesgar indebidamente la distribución. Por ejemplo, si se desea conocer qué interfaces de un enrutador mantienen una utilización alta sostenida es recomendable utilizar percentiles 90% o 95%: es casi seguro que todas las interfaces tuvieron una utilización de 100% en algún intervalo en que se emitió una ráfaga de datos. 3.3 Caracterización del flujo Durante la caracterización de la red también es importante obtener un \"mapa\" de los \"ríos\" de información que fluyen por la organización y sus características generales. Esta información es de gran utilidad para determinar qué tan adecuada es la infraestructura de red actual y qué modificaciones podrían hacerse para mejorarla. La caracterización de los flujos implica identificar los repositorios de información, los principales usuarios de dicha información, la simetría y características de los intercambios, los volúmenes de información intercambiados y las trayectorias recorridas. Como se mencionó en la sección 2.1, se debe tener presente que el modelo en el que los usuarios en una organización utilizaban mayoritariamente recursos disponibles y administrados localmente en su área o departamento ha ido desapareciendo gradualmente. Los repositorios de información (data stores) pueden ser servidores, granjas de servidores, mainframes, cintas, lectores de CD, redes de almacenamiento (NAS, SAN), etcétera. Por su parte, los consumidores de información pueden ser redes, subredes o sistemas autónomos. 3.3.1 Tipos de flujo por aplicación Para poder satisfacer los requerimientos de diseño, es importante identificar las características de los flujos generados por las aplicaciones. Se puede empezar por clasificar la simetría, direccionalidad y requerimientos de calidad de servicio de los flujos y posteriormente se tratará de evaluar el volumen del tráfico intercambiado. Como punto de partida, algunos flujos típicos en redes de cómputo tienen las siguientes características: Terminal virtual - servidor. Asimétrico y bidireccional (ejemplo: telnet) Cliente - servidor. Asimétrico y bidireccional (ejemplo: sesiones HTTP) Entre pares. Simétrico y bidireccional (ejemplo: NIS-II, videoconferencia) Servidor - servidor. Bidireccional y generalmente simétrico (ejemplo: cluster de servidores, respaldo de información) Cómputo distribuido. Las características dependen de la aplicación particular (ejemplo: grid computing) Difusión multimedia. Tráfico unidireccional (ejemplo: podcasts) La simetría de los flujos debe considerarse en varias dimensiones como por ejemplo, en el volumen de tráfico intercambiado, en la velocidad de los enlaces en cada dirección, y en los requerimientos de QoS. Algunas tecnologías como ADSL aprovechan las características asimétricas de los flujos cliente-servidor. Sin embargo, se debe tener muy presente que las características de estos flujos pueden variar drásticamente con el diseño de la red. Por ejemplo, los nodos de almacenamiento local de páginas web (cache engines) modifican por completo las caracterísicas de los flujos entre el cliente y el servidor (original). Caso de estudio: Documentación del flujo La documentación necesaria para caracterizar los flujos se empieza a integrar identificando las áreas de la organización, el número de empleados por área, las aplicaciones (fuentes de información) comúnmente utilizadas en esa área, su ubicación física (generalmente ésta se encuentra relacionada de alguna manera con la topología de la red) y otra información que pueda parecer relevante. Esta información puede conjuntarse en una tabla como la siguiente. Área Usuarios Aplicaciones Sist. Op. Ubicación Contabilidad 56 Office; Exchange; SAP W98 Corp. Edif. 2 Ingenieria 200 Web; Exchange; Office; Visio; CAD W2K; Solaris Corp. Edif 2; Mérida Finanzas 25 Web; Exchange; Office; Bloomberg; Infosel W2K Corp. Edif. 2 Pers. admin 33 Web; Office; Exchange W98 Toda la empresa Ejecutivos 20 Web; Office; Exchange; Blomber; Infosel; SAP W2K Corp. Edif. Princ. Operaciones 22 Office; Exchange W98 Mérida Sistemas 15 Web; Office; Exchange; SQL; SAP; Visio; Adm. Red W2K Corp. Edif. 1 Al mismo tiempo, deberán identificarse las principales aplicaciones generadoras de información, los repositorios de información y las características principales de los flujos generados. Esta información también se presenta en una tabla como la siguiente. Repositorio Área Características Sist.Op. Ubicación BD SAP Finanzas RPC Asim BD a Servs. Aplicación HP9000 Corp. Edif. 1 Aplicaciones SAP Finanzas y Ejecutivos RPC Asim. Serv. Aplic a usuarios W2K Corp. Edif. 2 Bloomberg Infosel Piso financiero y Ejecutivos C/S; T. Real Internet Internet/Edif. 1 Serv. Exchange 1 Corporativo Edif. Princ. RPC Asim W2K Corp. Edif. 1 Serv. Exchange 2 Ingeniería RPC Asim W2K Mérida Serv. Exchange 3 Secretarias y Operaciones RPC Asim W2K Mérida Serv. Red 1 Corporativo Edif.. Princ. C/S y Peer W2K Corp. Edif. 1 Serv. Red 2 Mérida C/S y Peer W2K Mérida Serv. Archivos Cada piso Corp. C/S W2K Todos A partir de las tablas anteriores se puede generar una especie de matriz de tráfico que vincula los repositorios y generadores de información con sus usuarios como se muestra en la tabla siguiente. Esa matriz se podrá asociar a la topología física de la red para identificar si los enlaces y equipos involucrados están dimensionados adecuadamente. 3.3.2 Caracterización del volumen de tráfico La caracterización de la carga es obviamente necesaria para poder cumplir con los objetivos de diseño: en general, la capacidad de la red debe poder satisfacer la carga estimada. La manera más fácil de medir un flujo es utilizando un analizador de protocolos o un monitor de red como se ha mencionado en el capítulo 2. Sin embargo, este modelo solamente puede aplicarse y parcialmente a los flujos ya existentes. La estimación de la carga para los nuevos flujos es bastante imprecisa. Existen demasiados factores que influyen en las características del tráfico de red. El objetivo no es hacer una estimación muy precisa, sino evitar cuellos de botella críticos. Para evitar cuellos de botella críticos, deben analizarse los patrones de uso de las aplicaciones, los intervalos entre paquetes y las sesiones, los tamaños de paquete y los patrones característicos introducidos por los protocolos de red. Estimación de la carga Es necesario conocer el tamaño de los objetos que se transmiten en cada aplicación y la sobrecarga introducida por los protocolos que utilizan. De ser posible, se deberán obtener métricas que caracterizan a cada fuente tratando de evaluar el comportamiento y las demandas de servicio de las aplicaciones existentes. Para aplicaciones \"típicas\" se podrá recurrir, con ciertas reservas, a tablas de referencia como las que se mostrarán más adelante. Para cada flujo identificado, debe investigarse el número de usuarios simultáneos, el tamaño de sus ráfagas y la frecuencia de transmisión para calcular la capacidad agregada necesaria por aplicación. Mientras la sesión está activa, con ayuda de un analizador de protocolos es posible medir el intervalo medio entre paquetes (MTBA) y por consiguiente el número medio de paquetes por segundo. También es posible estimar el tamaño medio de los paquetes para así estimar el ancho de banda promedio por sesión y, de esta forma, el ancho de banda requerido para esa aplicación. Con esta información, y dado que ya se conocen las tablas de las comunidades de usuarios y sus rutas, se podrá tener una estimación de la carga por segmento. Con ello se podrá elegir la tecnología más apropiada para el núcleo y para los dispositivos de conmutación. La ecuación siguiente utiliza los parámetros anteriores y algunos elementos de retardo para dar una aproximación del ancho de banda necesario para una aplicación: \\[B_w = \\frac{8\\times (N_A\\times K\\times L)}{K\\times P+T},\\] donde \\(B_w\\) es el ancho de banda estimado, \\(N_A\\) el número medio de sesiones, \\(K\\) el promedio de paquetes por sesión y \\(L\\) el tamaño medio de paquete. \\(P\\) es la latencia de la red en uno solo sentido y \\(T\\) es el \"think time\", es decir, el tiempo estimado que duraría un usuario de la aplicación en procesar o explotar la información recibida antes de solicitar un nuevo mensaje. Por supuesto, aquí se está hablando de valores promedio, lo que permite simplificar enormemente el dimensionamiento pero que no necesariamente corresponderán con los valores observados. Una mejor aproximación es la de representar los flujos por medio de distribuciones aleatorias y utilizar la teoría de colas para estimar el comportamiento de éstos. En el capítulo 7 se presentarán las ventajas y limitaciones de esta técnica. Los patrones de uso están relacionados con el nivel de sesión: ¿Cuánto dura en promedio una sesión? ¿Cuál es el intervalo entre sesiones por usuario? ¿Cuántos usuarios o estaciones hay? Con esto, y un análisis estadístico, se puede establecer cuántas sesiones en promedio se están ejecutando simultáneamente. Si no se cuenta con la información necesaria, a veces será necesario considerar el peor caso: todas las aplicaciones están siendo utilizadas al mismo tiempo y hay tantos usuarios de cada aplicación como usuarios hay en la comunidad de estudio. 3.3.2.0.1 Estimación de volumen por aplicación Es claro que las aplicaciones y los patrones de uso varían demasiado. Sin embargo, es necesario contar con una referencia para poder estimar la carga generada por éstas. La siguiente tabla, hecha alrededor de 1999, da una idea vaga del volumen generado por algunas aplicaciones para hacer estimaciones rápidas. Aplicación \\({\\bf Volumen~(kBytes)}\\) Pantalla de terminal \\(4\\) Mensaje de correo electrónico \\(10\\) Página Web \\(50\\) Hoja de Excel \\(200\\) Documento de Word \\(200\\) Presentación de PowerPoint \\(1,000\\) Video MPEG-4 (30 seg) \\(4,000\\) Imagen de alta resolución \\(50,000\\) Respaldo de una base de datos \\(1,000,000\\) 3.3.2.1 Estimación del volumen por sobrecarga de protocolos Para calcular el volumen total de tráfico transportado por la red, no basta con calcular el tráfico generado por las aplicaciones. También debe considerarse la sobrecarga de los protocolos de transporte y el volumen generado por otros protocolos y aplicaciones que sirven de soporte a la operación de la red. En lo que respecta a los protocolos de transporte, la tabla siguiente muestra la sobrecarga de algunos de los protocolos más comunes. Protocolo \\({\\bf Sobrecarga~(Bytes)}\\) Ethernet \\(18 + 20\\) IEEE802.3, IEEE802.2 y SNAP \\(26 + 20\\) HDLC \\(10\\) IPv4 \\(20\\) IPv6 \\(40\\) TCP \\(20\\) IPX \\(30\\) En el caso de ethernet y de IEEE 802.2, los 20 bytes extra corresponden a 8 de preámbulo (que en realidad es variable) y los 12 de separación entre tramas. Este último, por supuesto, no es tráfico que se genera pero afecta la eficiencia del medio. La actualización de rutas, en particular con protocolos de vector de distancia, puede tener un impacto importante en redes grandes en capacidad de procesamiento de los enrutadores. Su impacto en la capacidad de los enlaces típicamente es muy poca y sólo tiene un impacto importante cuando los enlaces están muy limitados en ancho de banda. Caso de estudio: Actualización tablas de enrutamiento Un ejemplo bien conocido sobre el impacto que los protocolos de enrutamiento pueden tener sobre la red data de principios de los años 90 en que se realizaban los primeros experimentos de transferencia de audio y video sobre internet entre Europa y los Estados Unidos. La calidad de las comunicaciones era muy inferior a lo esperado. Al revisar las trazas de tráfico, se encontró que la latencia de los paquetes sufría degradaciones muy importantes cada dos minutos aproximadamente. Tras muchos estudios, se concluyó que este comportamiento estaba relacionado con el intercambio y la actualización de tablas de ruteo al interior de algunos de los enrutadores en el enlace intercontinental. Varios protocolos comunes en redes locales utilizan tramas de difusión para su operación. Estas tramas también deben ser tomadas en cuenta. Además, un número excesivo de tramas de difusión puede degradar seriamente la eficiencia de la red. Dinámica de los protocolos de transporte Además de la sobrecarga de los encabezados, los protocolos de transporte controlan cómo y cuándo se envía la información, lo cual incide directamente en las características del trafico y en la carga observada. Por ejemplo, si la capa de enlace y la de transporte ofrecen ambas un servicio confiable y los temporizadores de la primera no están bien configurados, habrá retransmisiones innecesarias. En protocolos de ventana deslizante, como TCP, el tamaño de la ventana está asociado a la cantidad de información que puede viajar en la red (\"llenar el tubo\"), la cual es igual al producto ancho de banda por el retraso de ida y vuelta (RTT). Si la ventana es menor a este tamaño (como ocurre en redes satelitales o de fibra óptica de gran distancia), la ventana limitará la eficiencia de la conexión. Dicho esto, una ventana grande puede introducir una ráfaga grande de información a la red, lo que puede acarrear otras consecuencias no deseables, como congestión temporal en los nodos de conmutación y jitter. Para proteger la red ante un exceso de carga, muchos protocolos de transporte utilizan mecanismos de control de congestión que también influyen en las características de los flujos, por lo que se recomienda conocer qué mecanismos de control de congestión se están utilizando: de lazo abierto (token bucket), reactivos por los nodos (ECN, ABR) o de lazo cerrado en los extremos (TCP). Si no hay una forma de reacción a la congestión, la red puede quedar completamente inhabilitada. Influencia de otros componentes Debe tomarse en cuenta el tráfico generado por otros protocolos en los que se basa la operación de la red y que no se utilizan directamente para el transporte de los flujos de las aplicaciones como: La configuración automática con DHCP (que se presenta en el capítulo 4) genera intercmbios de 328 bytes; se considera que un mensaje del protocolo de administración SNMP (capítulo 6) utiliza 128 bytes por variable monitoreada. Dependiendo de las condiciones de la organización y de la configuración de su red, es posible que se detecten ráfagas de mensajes DHCP en ciertos momentos del día. Aunque es poco común, estas ráfagas pueden afectar el desempeño de la red por saturación momentánea de los enlaces, o por falta de capacidad de procesamiento en los servidores. Como se verá más adelante, la granularidad con que deben ser monitoreadas las variables de administración no debe ser muy fina para reducir el tráfico en la red. Copias de tráfico Para ciertas aplicaciones, como la difusión de video en demanda, vuelve a tomar importancia el uso de sistemas que faciliten la difusión restringida (multicast) de la información. En el capítulo 9 se mostrará cómo estos sistemas permiten hacer un uso más eficiente de los recursos de la red al evitar copias innecesarias, como se indica en la figura 3.8. Observe que en el caso de transmisiones unicast, en el enlace de la izquierda se genera un flujo por cada receptor de la información, mientras que en un sistema que soporte multicasting, son los enrutadores los que generan réplicas de la información en caso de ser necesario. Figura 3.8: Flujos de tráfico en aplicaciones unicast y multicast Por supuesto, al establecer la caracterización de los flujos, deberá conocerse si se emplean protocolos de difusión restringida en la organización. Otro elemento que debe tomarse en cuenta, es que si bien se ha tratado de caracterizar los flujos de las fuentes de manera individual, su combinación para estimar el volumen total no es tan sencillo como la suma aritmética que se pretende simbolizar en la figura 3.9. Figura 3.9: La mezcla de fuentes no puede realizarse como una superposición de flujos En realidad éste es un problema bastante complejo. El reto es cómo lograr un modelo que permita mezclar las fuentes para determinar la capacidad que será requerida y así poder estimar los retardos que sufrirán las distintas fuentes. Para redes donde las métricas de desempeño son críticas, el dimensionamiento puede realizarse considerando el peor caso en el que los picos de cada flujo coinciden en el tiempo. Sin embargo, esto genera redes sumamente sub-dimensionadas y costosas. En la mayoría de los casos se utiliza un multiplexaje estadístico basado en alguna técnica de modelado. 3.3.3 Requerimientos de calidad de servicio La calidad de servicio (QoS, Quality of Service) parte del hecho de que no todas las aplicaciones tienen las mismas necesidades y, por lo tanto, no demandan los mismos recursos de la red. Por ello, no basta con caracterizar el tráfico y la carga. También hay que identificar los requerimientos de los distintos flujos que se han identificado. La siguiente tabla muestra algunos requerimientos de QoS para algunas aplicaciones típicas. Los distintos tipos de flujo son más o menos tolerantes al retardo que pueden sufrir en la red. Una transferencia de archivos es relativamente inmune al retardo y a su variabilidad. A este tipo de flujos suele llamársele elásticos. En cambio, un flujo de audio para aplicaciones interactivas es sumamente estricto en sus requerimientos de retardo y jitter. Estas aplicaciones se llaman inelásticas. Existen diversos mecanismos para garantizar la calidad de servicio en la red. Dichos mecanismos son discutidos en forma general en el capítulo 8, pero el concepto central se basa en hacer posible que cada aplicación pueda solicitar de la red una garantía de que los recursos que necesita estarán disponibles. Es importante señalar el hecho de que aún cuando los mecanismos mencionados permiten a las aplicaciones solicitar los recursos necesitados, siempre quedará en manos del administrador de la red el decidir si dichos recursos son autorizados o no. Cada aplicación puede indicar sus requerimientos específicos hacia la red antes de iniciar la transmisión de datos. El \"contrato\" hacia la red (SLA, Service Level Agreement) se negocia especificando típicamente el tipo de tráfico, su variabilidad en la intensidad (burstiness), el ancho de banda, latencia y jitter requeridos y la tasa de pérdida tolerada. La terminología de ATM es útil para poder clasificar las aplicaciones y para poder determinar los parámetros que determinan la calidad de servicio requerida. En ATM hay cinco categorías de servicio: CBR (Constant Bit Rate), rt-VBR (Real-time Variable Bit Rate), nrt-VBR (non real-time Variable Bit Rate), ABR (Available Bit Rate) y UBR (Unspecified Bit Rate). Para cada una de ellas, el forum ATM indica una serie de parámetros que describen el tráfico y los requerimientos de QoS de la red. Ejemplos de estos parámetros son PCR (peak cell rate), SCR (sustainable cell rate), max CTD (cell transfer delay), y MBS (max burst size). Tráfico CBR Esta categoría está pensada para aplicaciones que generan una tráfico con una tasa constante como es el caso de una conversación telefónica y la transmisión de video sin compresión. Este tipo de flujos demanda de la red una capacidad constante en bits por segundo (ver figura 3.10 (a)), un retardo máximo predecible, una variabilidad del retardo y tasa de pérdidas mínimas. Es común que si la red puede ofrecer garantías para el tráfico CBR, este servicio se utilice para otros objetivos, como la interconexión de redes locales. Figura 3.10: Ejemplo de flujos a tasa constante y a tasa variable Tráfico VBR El tráfico VBR es el tipo de tráfico típico en las aplicaciones de red \"tradicionales\" las cuales generan flujos de información en ráfagas seguidas de períodos de silencio, lo que produce una tasa variable de información (figura 3.10 (b)). Algunas aplicaciones de tiempo real, como el video comprimido, también generan un tráfico VBR (por ello la categoría rt-VBR) y demandarán de la red un retardo máximo predecible, aunque normalmente menos rígido que para los flujos CBR. Existen varias definiciones distintas para medir la variabilidad en la intensidad con la que las aplicaciones \"inyectan\" tráfico a la red. Este término es lo que en inglés se llama burstiness. Una medida muy popular de burstiness es la relación entre la tasa de emisión pico (PBR, Peak bit rate) y la tasa promedio (MBR, Mean bit rate). \\[Burstiness = \\frac{PBR}{ MBR}\\] Una aplicación CBR tiene un burstiness muy bajo; una VBR puede tenerlo muy alto. Otras formas de evaluarla son a través de la duración de la ráfaga o de su probabilidad de ocurrencia. Distribución del ancho de banda Para poder satisfacer los requerimientos de calidad de servicio, la infraestructura de la red debe contar con mecanismos que permitan distribuir la capacidad disponible en los enlaces de acuerdo al nivel de importancia de los distintos flujos (o de las clases de servicio, como se verá en el capítulo 8. En los mecanismos llamados de conservación de trabajo, cuando la carga es ligera la capacidad se distribuye entre los distintos flujos, pero conforme la demanda empieza a aumentar rebasando la capacidad de la red, los anchos de banda se asignan en función de prioridad, como aparece en la figura 3.11. Figura 3.11: Distribución del ancho de banda en función de la prioridad de los flujos Algunas aplicaciones, como las que generan tráfico CBR, o algunas aplicaciones de misión crítica, requieren de la asignación de un ancho de banda determinado. Si el administrador está de acuerdo, entonces el ancho de banda de la línea de comunicaciones se divide entre los diferentes tipos de aplicación, y se pueden realizar múltiples sesiones sobre un mismo espacio asignado. 3.4 Problemas Problema 3.1 ¿Cómo se realiza y para qué sirve el baselining de la red en Diseño de Redes? Problema 3.2 Llene la siguiente tabla: Aplicación Direccionalidad Simetría       Burstiness Telnet HTTP Respaldo servidores Video en demanda Audio conferencia Problema 3.3 Caracterice los siguientes flujos en función de su: a) Direccionalidad: uni/bidireccional; b) Simetría: (en relación con los volúmenes de información en cada dirección; c) Tolerancia al retardo: elástica/inelástica; d) Disponibilidad: misión crítica, o no. Justfique brevemente su respuesta Telemetría Video conferencia para empresas Visualizador realidad virtual para síntesis de proteinas Sistema para autorización de tarjetas de crédito en tienda departamental Problema 3.4 ¿Cuáles son los valores que los siguientes parámetros deben tener para considerar que la red es \"sana\"? Porcentaje de utilización de un segmento ethernet Disponibilidad de las aplicaciones de misión crítica Porcentaje de colisiones Porcentaje de paquetes perdidos Porcentaje de utilización de CPU en enrutadores Problema 3.5 ¿Cuáles son los valores típicos de BER en enlaces: de cobre de fibra óptica satelitales? Problema 3.6 Si un proyecto de diseño de redes debe incorporarse a una infraestructura de red ya existente, ¿cómo es posible asegurar que el diseño propuesto será interoperable y que los objetivos de diseño son realistas? Problema 3.7 Describa brevemente y proporcione un ejemplo de mecanismos de control de congestión de: Lazo abierto Reactivos en los nodos de conmutación Lazo cerrado en los extremos. Problema 3.8 Se envía información con un protocolo de ventanas deslizantes por un enlace de \\(155\\,Mb/s\\). La distancia entre transmisor y receptor es de \\(800\\,km\\). La velocidad de propagación en el medio es de \\(200,000\\,km/s\\). ¿Cuál debe ser el tamaño máximo de la ventana para que no se degrade la eficiencia de la comunicación por esta razón? Problema 3.9 ¿Por qué el mecanismo de control de congestión de TCP puede ser ineficiente en redes limitadas en latencia y qué modificaciones se han propuesto para mejorarlo? Problema 3.10 ¿Qué elementos se deben tomar en cuenta para estimar el volumen de los flujos que fluyen por la red? Problema 3.11 Si durante la caracterización de la red se utiliza un analizador de protocolos para monitorear el tráfico, ¿durante cuánto tiempo y con qué frecuencia se debe capturar la información que nos interesa? Problema 3.12 ¿Qué relación hay entre un histograma y una pdf de una métrica de desempeño? ¿Qué propiedades estadísticas tiene la pdf? Problema 3.13 ¿Cómo es la varianza de una distribución Pareto con parámetro de forma \\(\\beta &lt; 1\\)? Problema 3.14 ¿Para qué tipo de variable recomendaría utilizar como medida de dispersión la desviación estándar? ¿Los percentiles 5% y 95%? Problema 3.15 ¿Qué significa \"Burstiness\" y cómo se calcula? ¿Qué significa el término Jitter y cómo se relaciona con la QoS? Problema 3.16 ¿Qué es un proceso de Poisson? ¿Por qué suele utilizarse para modelar tráfico en redes de datos? ¿En qué casos este modelo puede no ser adecuado? Problema 3.17 ¿Por qué es cuestionable modelar el tráfico de aplicaciones \"clásicas\" con procesos de Poisson? ¿Podría modelarse el flujo de VoIP como Poisson? Problema 3.18 Describa brevemente cuáles son las características de los flujos definidos por el foro de ATM y de un ejemplo de una aplicación que genere cada tipo de flujo. Estos temas serán tratados con mayor detalle en el capítulo 4. "],["diseño-lógico-de-la-red.html", "Capítulo 4 Diseño lógico de la red 4.1 Diseño de la topología 4.2 Diseño de la capa de acceso 4.3 Capa de distribución 4.4 Diseño de la red dorsal 4.5 Diseño basado en bloques modulares 4.6 Topologías con redundancia 4.7 Problemas", " Capítulo 4 Diseño lógico de la red El diseño lógico de la red consiste no solamente en definir la topología de interconexión entre los distintos componentes que la conforman. En esta etapa también se determinan las tecnologías para llevar a cabo dicha interconexión. También se establecen las políticas de asignación de direcciones y de nombres, las de seguridad y las de administración de la red. Todos estos elementos serán críticos para que la red cumpla de manera eficiente con los objetivos de diseño establecidos. El diseño de la red se asemeja más a un arte que a una ciencia: No hay absolutos, no hay fórmulas exactas que puedan utilizarse ciegamente en todos los casos. Sin embargo, hay un conjunto de mejores prácticas* a partir de las cuales se podrán tomar decisiones más informadas durante el proceso de diseño.* 4.1 Diseño de la topología En la metodología descendente, el primer paso del diseño lógico es el diseño de la topología de la red. La topología es un mapa en el que se identifican segmentos, puntos de interconexión y comunidades de usuarios. Con esta información se puede tener una primera apreciación de las capacidades de los dispositivos y enlaces pero no se pueden elegir aún los dispositivos específicos con los que se construira la red. En redes de comunicaciones, básicamente es posible identificar tres tipos de topología: Plana.- Topología convencional en la que todos los dispositivos de conmutación tienen la misma funcionalidad. Amorfa.- También conocida como de spaghetti, es una anarquía; la interconexión entre nodos se hace sin orden ni planeación. Es el efecto directo de un crecimiento reactivo y no planeado. Tarde o temprano ocasiona serios problemas para la gestión de la red, el dimensionamiento de enlaces, la implementación de políticas de enrutamiento, etc. Jerárquica.- Agrupamiento ordenado de nodos y enlaces. El tráfico con destinos comunes se va agrupando y fluye por enlaces principales para llegar lo más cerca de su destino y ahí proceder a la desagregación. 4.1.1 Topología plana Algunos ejemplos de topologías planas bien conocidas se muestran en la figura 4.1. Figura 4.1: Ejemplos clásicos de topologías planas de redes Las topologías planas son sencillas de diseñar e implementar. Tambíen son fáciles de administrar en redes pequeñas, por lo que se encuentran comúnmente en redes con pocos dispositivos. Una de las principales limitantes de estas topologías es su falta de escalabilidad. En la topología de anillo, está limitada por el número de saltos que habría que dar para llegar de un extremo a otro, lo que provoca una latencia variable entre dos nodos cualesquiera que deseen comunicarse, y muy grande para la comunicación entre los extremos. En la estrella, también llamada hub and spoke, la escalabilidad queda limitada por el número de puertos en el nodo central. Además, hay un punto único de falla y un potencial cuello de botella de procesamiento. Por otro lado, al tener un punto central donde fluye la información, esta topología es muy útil para gestionar la red y controlar la seguridad. Las topologías de malla parcial o total son sumamente costosas. En la malla total, en particular, es muy difícil agregar un nuevo nodo. Además, el desempeño estará en función del número de vecinos que tiene un nodo enrutador: se debe recordar que la actualización de las tablas de ruteo requiere de la atención de mensajes de difusión, lo cual consume recursos de CPU en la mayoría de los enrutadores. Entre más vecinos enrutadores haya, peor será el desempeño. Por otra parte, es muy complicado establecer el enrutamiento en este tipo de configuración. También se dificulta el mantenimiento y actualización por la falta de modularidad. Como se ha mencionado, algunos de estos problemas también se detectan en las topologías de spaghetti. 4.1.2 Diseño jerárquico El diseño jerárquico proporciona un enfoque estructurado que busca obtener una red más fácil de entender, administrar, planear y escalar. Consiste en dividir la red en capas, cada una responsable de realizar una función específica. En los primeros diseños jerárquicos se definían dos capas: la red de acceso, encargada de ofrecer conectividad a los usuarios finales, y el núcleo, cuyo objetivo central es proporcionar interconexión eficiente entre los distintos sitios. Conforme han evolucionado las redes, se ha propuesto incluir una tercera capa: la de distribución, encargada de ofrecer los servicios del núcleo a la capa de acceso definiendo las políticas necesarias. Por ejemplo, en esta capa se puede llevar a cabo la agregación de rutas, la traducción de direcciones y la implementación y monitoreo de las políticas de seguridad establecidas. La figura 4.2 representa esquemáticamente las tres capas de un diseño jerárquico. En el modelo de la derecha se incluyen enlaces redundantes entre la capa de acceso y la de distribución. Estos enlaces mejoran el desempeño y aumentan la disponibilidad de la red, como se verá en la sección 4.6. Figura 4.2: Diseño jerárquico de tres capas Dependiendo de las características de la red, los nodos en cada capa pueden ser enrutadores, conmutadores, concentradores o puede haber una combinación de dispositivos, como se muestra en la figura 4.2. Por ejemplo, en una LAN, la capa de acceso podría estar formada por concentradores y conmutadores para conectar usuarios finales. En cambio, en una red WAN la capa de acceso podría consistir en los enrutadores de salida de las redes locales. El diseño jerárquico en capas ha adquirido una creciente atención debido a las múltiples ventajas que ofrece, entre las que cabe destacar las siguientes: Permite reducir costos al utilizar equipo especializado en cada nivel. Por ejemplo, los dispositivos en la capa de acceso pueden necesitar una gran densidad de puertos de bajo costo, mientras que los dispositivos en el núcleo tendrán pocos puertos de alta velocidad y su prioridad será una muy alta tasa de conmutación; al elegir los dispositivos apropiados en cada capa, permite aislar los dominios de difusión, mejorando así el desempeño de los enrutadores y estaciones de trabajo; permite una mejor planeación de capacidad, y en consecuencia, un mayor escalamiento; permite una administración sencilla pues se cuenta con una red con una estructura lógica coherente. También simplifica la evolución gradual de la red; simplifica el aislamiento de fallas, lo que facilita un diseño que contemple la continuidad del negocio; simplifica la planeación de agregación de rutas, lo que se traduce en un menor uso de ancho de banda para anunciar rutas y un menor consumo de CPU en los enrutadores. La mayoría de los protocolos de enrutamiento de convergencia rápida en uso actualmente, como OSPF (Open Shortest Path First), IS-IS (Intermediate System to Intermediate System), BGP (Border Gateway Protocol) y EIGRP (Enhanced Interior Gateway Protocol) fueron diseñados para emplearse en redes jerárquicas. Al optar por un diseño jerárquico, hay ciertas recomendaciones que deben seguirse con el fin de explotar al máximo las ventajas de esta metodología, entre las que destacan: Se debe limitar el número de capas (llamado diámetro) para mantener la latencia baja y predecible. Esto también permite estimar las trayectorias de enrutamiento y los flujos de tráfico, para planificar adecuadamente la capacidad de los enlaces. El diseño de la red comienza con la capa de acceso y de ahí se mueve hacia adentro. Empezar en la capa de acceso permite una mejor planeación de la capacidad que se requerirá en las capas superiores. También se empieza a pensar en las posibles tecnologías y optimizaciones que se podrían aplicar a esos niveles tomando en consideración que en cada nivel se debe mantener el diseño lo más modular posible. Se debe mantener un estricto control de la capa de acceso, que es la más vulnerable. A través de un reforzamiento de las políticas de la empresa, se debe evitar que los administradores locales establezcan enlaces directos entre oficinas regionales (llamados cadenas), lo cual en términos prácticos representa la creación de una cuarta capa. También se deben evitar \"puertas traseras\", es decir, enrutadores que conectan entre sí dos redes en una misma oficina regional. Esto introducirá una serie de problemas de ruteo muy difíciles de identificar y corregir. Además, la seguridad de la red está en juego pues las políticas de seguridad están implementadas en la capa de distribución. A veces las cadenas son necesarias, por ejemplo para agregar una nueva ciudad que solo tiene conectividad con otra. Por su parte, se tiende a meter una puerta trasera para aumentar el desempeño o por redundancia. En ambos casos, se puede encontrar generalmente una configuración que no viole el diseño jerárquico. 4.2 Diseño de la capa de acceso La función principal de esta capa es proporcionar acceso a la red de la empresa a grupos de usuarios locales. Una LAN generalmente está conformada por concentradores y conmutadores, pero puede incluir los enrutadores que están en el límite exterior de un campus. En el caso de redes WAN la capa de acceso determina la conectividad de los nodos y usuarios en una misma región geográfica, por ejemplo, una ciudad. En grandes redes, esta capa debe dar acceso a cientos o miles de usuarios, por lo que resulta prioritario encontrar una solución a costo mínimo. El objetivo central de diseño en la capa de acceso es maximizar el desempeño a un costo mínimo cumpliendo los requerimientos fijados. Para reducir los costos, en la capa de acceso se busca típicamente agrupar el tráfico de varios usuarios (también llamados terminales) en nodos concentradores y establecer una topología de interconexión. Así, el problema de diseño en la capa de acceso puede dividirse en tres sub-problemas: Seleccionar los mejores candidatos para concentrar en ellos el tráfico de los usuarios. Seleccionar qué usuarios se conectan a qué concentradores. Definir la topología de interconexión en cada caso. Estos problemas pertenecen a una categoría que se conoce genéricamente como Facility loaction problem. Se ha demostrado que en el caso general estos problemas son NP-Completos11, por lo que se han propuesto diversas heurísticas para resolverlos. En las secciones siguientes se presentan algunas de ellas. Aunque las heurísticas mostradas tienen muchos años de ser conocidas (por ejemplo, el método de Kruskal data de 1956), variantes de estas técnicas tienen muchas aplicaciones en las redes actuales. Por ejemplo, para establecer una primera aproximación a la ubicación de radiobases y puntos de acceso en redes inalámbricas; para ubicar multiplexores en anillos ópticos; para seleccionar puntos de presencia (PoP) de operadores; etc. 4.2.1 Problema de Localización-asignación El diseño de la red de acceso inicia estableciendo cuántos concentradores se necesitan para una determinada población de usuarios (o terminales) y dónde conviene colocarlos. Las localidades donde conviene concentrar el tráfico de los usuarios suelen ser un subconjunto de los sitios donde éstos se encuentran. La selección específica de localidades dependerá del número de puertos disponibles, de la capacidad de los enlaces y del tráfico esperado. Sin embargo, resulta apropiado partir de una primera selección de candidatos, por lo que se presenta en primer término un algoritmo sin restricciones, es decir, se asociará un costo a los enlaces (que puede ser distancia, número de saltos, retraso, etc.) pero no se tomarán en cuenta limitaciones en ancho de banda de los enlaces ni capacidades de los equipos. Algoritmo de Dysart-Georganas El algoritmo de Dysart-Georganas permite identificar los mejores candidatos para ser nodos concentradores utilizando como criterio el grado de vecindad, o número de nodos vecinos cercanos. Utiliza un parámetro \\(K\\) que representa el número de nodos vecinos que un concentrador puede interconectar. Sea \\(N\\) el número de nodos en la red. El algoritmo es el siguiente: Se genera una lista de nodos con sus \\(K\\) vecinos más cercanos. Se obtiene una tabla con la frecuencia \\(j\\) con que aparece cada nodo en la lista de vecinos. Se calcula el número promedio de vecinos a partir de la tabla de frecuencias: \\[\\bar v = \\Big\\lfloor\\frac{\\underset{j=1}{\\overset{F}\\Sigma}% S_j\\times j}{N}\\Big\\rfloor+1\\] Los candidatos idóneos son aquellos nodos con un número de vecinos superior al promedio \\(\\bar v\\). Ejemplo 4.1 Considere la red de la figura 4.3. Las líneas entre los nodos representan enlaces potenciales con el costo indicado en cada una. Se busca elegir a los mejores candidatos para un valor de \\(K=3\\). Figura 4.3: Topología de una red con diez nodos Se construye una tabla de vecindades con los \\(K=3\\) vecinos más cercanos (es decir, con la métrica menor), para cada nodo. Por ejemplo, para el nodo 5 se eligen los tres vecinos con un costo de una unidad. En la tabla de vecindades del ejemplo, la segunda columna muestra los vecinos más cercanos. La columna de frecuencia representa el número de ocurrencias de cada nodo (incluyéndose a sí mismo) en la lista de vecindades. Por ejemplo, el nodo 5 aparece como vecino cercano de 5 nodos (los nodos 1, 2, 3, 4 y 6) más él mismo, lo que da una frecuencia de 6. Tabla 4.1: Tablas de vecindades y de frecuencias Nodo Vecinos Frecuencia 1 2, 5, 6 1 2 3, 4, 5 5 3 2, 4, 5 3 4 2, 3, 5 6 5 2, 4, 6 6 6 4, 5, 7 5 7 6, 8, 10 5 8 4, 6, 7 4 9 7, 8, 10 2 10 7, 8, 9 3 J SJ 1 1 2 1 3 2 4 1 5 3 6 2 De la tabla de vecindades se obtiene una tabla de frecuencias que será utilizada para calcular el promedio ponderado de vecindades. La tabla de frecuencias contiene las frecuencias \\(J\\) observadas en la tabla de vecindades y el número de veces, \\(S_j\\), en que se observó ese valor de frecuencia. El promedio ponderado se calcula directamente a partir de la tabla: \\[\\bar v = \\Bigg\\lfloor\\frac{1\\times 1+2\\times 1+3\\times 2+4\\times % 1+5\\times 3+6\\times 2}{10}\\Bigg\\rfloor +1=5\\] Los candidatos potenciales son aquellos con un número de vecinos mayor o igual a 5, es decir, los nodos 2, 6, 7, 4 y 5. Si se encuentra que algunos concentradores están demasiado cerca o si hay sobrecarga al agregar el análisis de tráfico, a partir de este diseño de base se pueden hacer reconfiguraciones. 4.2.2 Asignación de nodos a concentradores Una vez identificada la localización de los concentradores potenciales, deberá decidirse cómo interconectar los nodos terminales con estos concentradores. Dado que en general se da prioridad a minimizar el costo debido a la potencialmente gran cantidad de usuarios (o nodos) que deben interconectarse, se busca que cada nodo se conecte a uno y solamente un concentrador, ignorando enlaces redundantes. Básicamente, se evalúa la conveniencia de cada concentrador potencial calculando el costo o la reducción que se tiene eliminando cada uno de ellos. Para esto, se han propuesto varias heurísticas, entre las más populares están: Greedy. Cada terminal se conecta a su concentrador más cercano. Si ya no tiene capacidad (en nuestro caso, si ha alcanzado la conectividad \\(K\\)), la terminal se conecta al mejor disponible. Add o de construcción. Todos los nodos se conectan a un solo concentrador. Se van agregando concentradores que prometan ahorros en costo de conectividad y se conectan terminales a ellos hasta que no se justifique agregar más. Drop o de eliminación. Se inicia con cada nodo conectado al concentrador que minimiza el costo de la conexión. Se eliminan concentradores hasta que ninguno pueda eliminarse. 4.2.3 Topología de nodos a concentrador Ya se ha decidido qué concentradores se retienen y qué nodos deben conectarse a cada uno. Solo falta decidir cómo deben conectarse los nodos terminales al concentrador. La topología más sencilla es la estrella, pero puede no ser la configuración más eficiente, por lo que deben investigarse alternativas en las que algunos enlaces pueden compartirse transportando el tráfico de varios nodos. Este tipo de problemas para obtener las trayectorias mínimas entre un conjunto de nodos es bien conocido en redes de comunicaciones y en logística. Sus soluciones consisten en encontrar un árbol de expansión mínimo (minimum spanning tree, MST), es decir, aquél en el que la suma de los brazos es mínima. A continuación se presentarán dos ejemplos de estos algoritmos. Ellos dan una solución mínima cuando se trabaja sin restricciones, es decir, sin considerar las capacidades de los enlaces. Al incluir esta restricción, los métodos pueden proporcionar resultados ligeramente distintos. Con el fin de ejemplificar los dos algoritmos, se considerará una red que tiene ocho nodos, de los cuales el primero es es concentrador. Los costos de conexión entre los distintos nodos, son los que se muestran en la matriz de costos. El costo aquí puede ser cualquier métrica: costo de instalación, longitud de cableado, etc. Las métricas de desempeño y de número de saltos son costos más relevantes en redes WAN. Matriz de costos \\(c_{ij}\\) 1 2 3 4 5 6 7 8 1 0 2 52 13 45 15 58 59 2 2 0 52 14 43 16 58 62 3 52 52 0 60 85 41 23 55 4 13 14 60 0 50 18 72 50 5 45 43 85 50 0 59 81 95 6 15 16 41 18 59 0 55 42 7 58 58 23 72 81 55 0 78 8 59 62 55 50 95 42 78 0 Algoritmo de Esau-Williams El método de Esau-Willimas da muy buenos resultados aún para redes de gran tamaño y ha sido la base de muchas estrategias contemporáneas. Consiste en los pasos: Se inicia con todos los nodos conectados en estrella con el concentrador. Se calcula una matriz de diferencias \\(d_{ij} = c_{ij} - c_{i1}\\), es decir, la diferencia resultante de conectar el nodo \\(i\\) al nodo \\(j\\) en vez de conectarlo al concentrador (nodo 1). Las entradas con valores negativos indican conexiones alternativas más económicas para esos concentradores. Se empieza por seleccionar los valores más negativos y se continúa hasta agotarlos. Ejemplo 4.2 A partir de la matriz de costos se calcula la matriz de diferencias de la siguiente manera: \\[\\begin{aligned} d_{2-3}=c_{2-3}-c_{2-1}=52-2=50;&amp;\\quad d_{2-4}=c_{2-4}-c_{2-1}=14-2=12; \\ldots\\\\ d_{3-2}=c_{3-2}-c_{3-1}=52-52=0;&amp;\\quad d_{3-4}=c_{3-4}-c_{3-1}=60-52=8;\\ldots \\end{aligned}\\] La matriz de diferencias resultante para la configuración de referencia en esta sección es: El proceso inicia conectando todos los nodos al concentrador, como se muestra en el Paso 0 de la figura 4.4. Figura 4.4: Algoritmo Esau-Williams. Pasos 0 a 2 del ejemplo En la matriz de diferencias se busca el enlace con el valor más negativo, es decir, aquél que representa el mayor ahorro. Se trata del enlace \\(7\\leftrightarrow 3\\) con un ahorro de 35. Conectar el nodo 7 al 3 en vez de conectarlo directamente al concentrador genera un ahorro de 35 unidades, por lo que se modifica la topología como aparece en el Paso 1 de la figura 4.4. Se consulta nuevamente la matriz de diferencias. El siguiente número más negativo es el que corresponde al enlace \\(3\\leftrightarrow 7\\) con un valor de 29. Este enlace no se toma en cuenta pues ya están conectados los nodos 7 y 3. Al buscar el siguiente enlace, se selecciona el \\(6\\leftrightarrow 8\\) con un valor de 17, modificando la topología como aparece en el Paso 2 de la figura 4.4. En el paso 3, la matriz de diferencias indica conectar el nodos 3 al 6 y finalmente, el 5 al 2, dejando como resultado la topología que aparece a la derecha de la figura 4.5. Figura 4.5: Algoritmo Esau-Williams. Pasos 3 y 4 del ejemplo El costo de la topología de estrella era de 244 unidades; el costo de la topología final es de 179 unidades. Algoritmo de Kruskal El método de Kruskal es bastante sencillo pero se ha observado que para grandes redes con restricciones, las soluciones a las que se llega suelen estar alejadas de la topología óptima. Este método comienza con todos los nodos desconectados y consiste en: Se ordenan los enlaces de la matriz según su costo. Se seleccionan los enlaces de menor a mayor costo y se van trazando en el diagrama. Si la utilización de un enlace genera un lazo, éste se rechaza. Se continua seleccionando enlaces hasta que todos los nodos estén conectados. Ejemplo 4.3 A partir de la matriz de costos que se presentó en el ejemplo 4.2, la relación de enlaces ordenados por costo es la siguiente: Enlace Costo Enlace Costo \\(1 \\leftrightarrow 2\\) 2 \\(6 \\leftrightarrow 4\\) 18 \\(1 \\leftrightarrow 4\\) 13 \\(3 \\leftrightarrow 7\\) 23 \\(2 \\leftrightarrow 4\\) 14 \\(3 \\leftrightarrow 6\\) 41 \\(1 \\leftrightarrow 6\\) 15 \\(6 \\leftrightarrow 8\\) 42 \\(2 \\leftrightarrow 6\\) 16 \\(2 \\leftrightarrow 5\\) 43 Se selecciona el primer enlace y se conecta el nodo 2 al concentrador. De igual forma, en el siguiente paso se conecta el nodo 4 al concentrador. El siguiente enlace a considerar sería entre los nodos 2 y 4 pero esto generaría un lazo, por lo que se ignora; se toma el enlace conectando el nodo 6 al concentrador como se muestra en la figura 4.6. Figura 4.6: Algoritmo de Kruskal. Pasos 1 a 3 del ejemplo Los enlaces \\(2\\leftrightarrow 6\\), y \\(6\\leftrightarrow 4\\) también formarían un lazo y no son tomados en cuenta. Siguiendo con la tabla, se conectan los enlaces \\(3\\leftrightarrow 7\\), \\(3\\leftrightarrow 6\\), \\(6\\leftrightarrow 8\\) y \\(5\\leftrightarrow 2\\). Con esto se han conectado todos los nodos, como se muestra en la figura (fig:k47), que en esta ocasión coincide con la topología de la figura 4.5. Figura 4.7: Algoritmo de Kruskal. Pasos 4, 5 y 7 del ejemplo Consideraciones de tráfico En los ejemplos de los algoritmos anteriores no se tomaron en cuenta restricciones. En situaciones más reales hay que tomar en cuenta varias restricciones, como el hecho de que no siempre están disponibles las conexiones entre dos nodos cualesquiera. Una restricción más importante consiste en reconocer que no se pueden agregar nodos indefinidamente en un enlace multilínea sin tomar en cuenta la carga que cada nodo irá agregando a la red. Eventualmente la capacidad del enlace se verá rebasada. Si ese fuera el caso, al aplicar las heurísticas de Esau-Williams o de Kruskal, la conexión que violara la restricción de capacidad tendría que ser ignorada y se pasaría al siguiente punto. Ejemplo 4.4 Retomando el ejemplo 4.2 del algoritmo Esau-Williams, se considerará que la capacidad máxima de cualquier enlace es de 19 unidades (paquetes, tramas, kBytes, ) y que cada nodo contribuye con la carga que se indica en la tabla. Al querer agregar el tráfico de los nodos 7 y 3 al nodo 6 (paso 3 en la figura 4.4, la capacidad del enlace \\(6\\leftrightarrow 1\\) se rebasaría, por lo que la conexión \\(3\\leftrightarrow 6\\) no se realiza. La topología resultante se muestra en la figura 4.8. Nodo 2 3 4 5 6 7 8 Tráfico 14 12 13 6 7 6 6 Figura 4.8: Algoritmo con restricciones de tráfico. Configuración resultante 4.3 Capa de distribución La capa de acceso y el núcleo de la red tienen objetivos muy distintos. La primera da conectividad a los equipos terminales de los usuarios al menor costo posible. Por su parte, el núcleo de la red tiene por objeto encaminar los paquetes con la mayor eficiencia posible. La capa de distribución funciona como un punto de demarcación entre estas dos. Su principal tarea es ofrecer los servicios de conectividad del núcleo a la red de acceso, con base en las políticas de la organización. Los dispositivos en esta capa son los mejores candidatos para aplicar las políticas de la organización, pues en ella se interconectan las redes locales, concentrando el tráfico de los usuarios, y se libera a los dispositivos en el núcleo de realizar funciones ajenas a la conmutación eficiente de paquetes. Los requerimientos de disponibilidad en la capa de distribución empiezan a cobrar importancia, pues el fallo de un equipo en esta capa puede aislar una sección muy grande de la red. Frecuentemente se usan equipos redundantes y los nodos de acceso se conectan a ambos como se muestra en la figura 4.3. Las funciones específicas que realiza la capa de distribución dependen, desde luego, del tamaño y complejidad de la red, así como de la estrategia de la organización. La lista que se muestra a continuación ejemplifica algunas de estas funciones, muchas de las cuales serán descritas con mayor detalle en capítulos subsecuentes. Enrutamiento entre VLANs . Si en la empresa se utilizan redes locales virtuales, la capa de distribución es un punto natural de interconexión, y de enrutamiento entre ellas. Servidores de configuración . En redes de tamaño pequeño y mediano, en las que en la capa de acceso hay unas cuantas redes locales, servidores de configuración como DHCP, WINS, LDAP pueden colocarse en esta capa. Adaptación de protocolos de enrutamiento . Frecuentemente los enrutadores en la capa de distribución deben seguir dos esquemas distintos de protocolos de enrutamiento: uno hacia la red de acceso y otro hacia el núcleo. En redes pequeñas, en la red de acceso suele seguirse un enrutamiento estático y en el núcleo uno dinámico interno (por ejemplo, OSPF). En redes medianas y grandes, la red de acceso suele tener enrutamiento dinámico interno y hacia el núcleo puede utilizarse un protocolo de enrutamiento externo (por ejemplo, BGP). Control de desempeño . En redes pequeñas, esta capa rompe los dominios de difusión de las redes locales, limitando el tráfico entre ellas. A través de la configuración de las tablas y políticas de enrutamiento, se controla el flujo de tráfico desde y hacia el núcleo de la red. Además, si la política de direccionamiento lo permite, es en esta capa en la que se puede realizar la sumarización de rutas para disminuir el tamaño de las tablas de enrutamiento en los dispositivos del núcleo. Por otra parte, los dispositivos en esta capa pueden implementar mecanismos diferenciados de asignación de ancho de banda por prioridades y conformado de tráfico (traffic shaping) para cumplir con los acuerdos de servicio y no rebasar las capacidades del núcleo. Seguridad y auditoría . Los dispositvos en la capa de distribución pueden filtrar el tráfico entre las capas de acceso y el núcleo para aplicar las políticas de seguridad de la organización. También es en este nivel el que se puede realizar la traducción de direcciones entre las redes internas (en la capa de acceso) y el núcleo. Así mismo, la capa de distribución es un punto ideal para monitorear, auditar y contabilizar el tráfico que fluye por la red. 4.4 Diseño de la red dorsal La función principal de red dorsal es interconectar eficientemente los sitios (es decir, las distintas redes de acceso) de la organización. A diferencia de la red de acceso, en esta capa todos los nodos (es decir, los sitios) pueden intercambiar tráfico entre sí, por lo que los dos criterios fundamentales de diseño para la red dorsal son la eficiencia y la tolerancia a fallos. Por ello, todas las funciones lógicas relacionadas con las políticas de la organización han sido relegadas a la capa de distribución. Los dispositivos a seleccionar para el núcleo de la red deben tener una muy alta disponibilidad y capacidad de conmutación de paquetes. Un fallo en la red dorsal afecta a una gran parte de los usuarios, por lo que se busca diseñar una topología redundante (ver figura 4.9) capaz de soportar un cierto número de fallos y de adaptarse a los cambios rápidamente. Figura 4.9: Diseño de la red dorsal Se debe tratar limitar el tamaño y mantener la consistencia del núcleo de la red. Esto permitirá predecir el desempeño, detectar rápidamente fallos y en general, simplificar la administración. En un campus, el núcleo de la red interconecta las redes LAN que ya han sido agregadas en la capa de distribución. En una red WAN, esta capa típicamente utiliza los servicios de un proveedor de transporte para interconectar los sitios entre sí. Entre los servicios propuestos por los operadores en la actualidad para diseñar la red dorsal se encuentran: X.25 Frame Relay ATM MPLS Enlaces dedicados Redes virtuales privadas en Internet (VPN) La selección del servicio particular dependerá de su disponibilidad en todas las zonas que deban interconectarse así como de los requerimientos de diseño (desempeño, seguridad, costo, etc.). En la actualidad en México, como en muchas partes del mundo, prácticamente han desaparecido los servicios de X.25 y ATM y han sido sustituidos por Frame Relay (se estima que en 2003, el 80% de los enlaces WAN eran Frame Relay) y más recientemente, por MPLS y por VPNs, que se estudiarán con mayor detalle en capítulos posteriores. Salvo casos muy particulares, los enlaces privados también han perdido popularidad debido a su alto costo. Para redes pequeñas, las topologías de malla, de estrella y combinaciones de éstas se han utilizado con regularidad. Sin embargo, ya se ha mencionado que estas topologías no podrían satisfacer algunos requerimientos críticos para redes grandes. 4.4.1 Diseño de la topología Típicamente, diseñar la topología del núcleo implica encontrar un punto de equilibrio entre los requerimientos de costo, disponibilidad y desempeño de la red. Nuevamente, se ha encontrado que este es un problema de gran complejidad para el que se han propuesto algunas heurísticas iterativas de diseño. Un ejemplo clásico sería el siguiente: Se calcula una matriz de tráfico entre los distintos sitios; se propone una topología inicial (con algún algoritmo); a partir de la matriz de tráfico, se asigna tráfico a los enlaces; se determina la capacidad de los enlaces y se les asigna un costo; se introduce una perturbación que altere la topología y se regresa al punto 3. Cuando se han evaluado todas las posibilidades (o tras un determinado número de iteraciones, se retiene la topología con el costo menor. Topológicamente, el diseño de la red dorsal debe cumplir con los requerimientos de disponibilidad. Esto implica que la topología debe tener \\(k\\) trayectorias disjuntas entre dos nodos cualesquiera si se desea que la red tolere \\(k-1\\) fallos y siga conectada 12. Heurística de Steiglitz-Weiner-Kleitman El problema de encontrar una red k-conectada de costo mínimo es conocido como el problema de diseño de redes sobrevientes o como el problema generalizado de los árboles de Steiner. La heurística de Steiglitz, Weiner y Kleitman permite encontrar una solución local para este problema. La heurística está basada en el teorema de Whitney: Una condición necesaria para que una red sea k-conectada, es que el grado de sus nodos (el número de interfaces en nuestro caso), sea mayor o igual a \\(k\\). Funciona de la siguiente manera: Se enumeran los nodos de manera aleatoria. Asignar identificadores aleatorios permitirá crear fácilmente nuevas topologías al tratar de hallar soluciones con costo menor. Se asigna a todos los nodos un déficit igual al grado \\(k\\) deseado. Este déficit es el número de interfaces que no han sido asignadas a enlaces hacia otros nodos. Se selecciona el nodo con el déficit más alto. Si hay varios candidatos, se selecciona el que tiene el menor identificador. Se enlaza este nodo con el nodo con el mayor déficit entre los no adyacentes. Si hay varios candidatos, se selecciona el más cercano (menor costo). Si hay varios candidatos, se selecciona el que tiene el identificador menor. Al hacer el enlace, se decrementa el déficit en cada uno de estos nodos. Se continúa desde el punto 3 hasta que todos los nodos tengan un déficit menor o igual a cero. Algunos nodos pueden tener un déficit negativo, lo que se ajustará posteriormente. Ejemplo 4.5 En la figura 4.10 se presenta paso a paso la heurística de Stieglitz-Weiner-Kleitman para una red de 5 nodos con una tolerancia a 2 fallos (3-conectada). Los números al interior de los nodos representan su déficit. Los números en el exterior representan su identificador aleatorio. En este caso, se ha supuesto que el costo de los enlaces es el mismo para cualquier par de nodos. Figura 4.10: Algoritmo Stieglitz-Weiner-Kleitman Asignación de capacidad Si bien la asignación de capacidad de los enlaces es una actividad relacionada con el diseño físico de la red, en la red dorsal éste es un proceso complejo e iterativo que influye en la topología final, por lo que en esta sección se introducen los conceptos básicos de asignación de capacidad. El punto de partida para dimensionar los enlaces de la red dorsal consiste en estimar la cantidad de tráfico que cada nodo inyectará hacia el núcleo. Para ello, es necesario identificar qué porcentaje del tráfico generado en las redes de acceso de cada nodo es local y qué porcentaje viaja hacia otros nodos (hacia otras redes de acceso). Esta información permite crear una matriz de tráfico con una aproximación del volumen de tráfico intercambiado entre nodos. Una vez conocidos los volumenes de tráfico, es necesario identificar las trayectorias que recorrerán los flujos en la topología obtenida. En general, estas trayectorias estarán determinadas por las políticas y los protocolos de enrutamiento, y por la dinámica de la red. Si el número de conexiones es relativamente alto, y los enlaces tienen una métrica de costo similar, es posible suponer que las rutas seleccionadas serán las de menor costo. Sin embargo, por razones que serán explicadas en capítulos posteriores, en redes de mediana complejidad la selección de rutas se establece con anterioridad mediante un proceso de Ingeniería de Tráfico en el que se configura una red superpuesta sobre la que se tiene un mejor control del tráfico en el núcleo de la red. Finalmente, debe tomarse en cuenta que, si el criterio central de diseño es la tolerancia a fallas, entonces deberá asignarse un factor de sobrecarga que permita soportar el tráfico excedente en caso de que un enlace (una trayectoria) falle y su carga sea repartida entre los demás. Para soportar una falla, el factor de sobrecarga es: \\[L_f = U -\\frac{U}{N},\\] donde \\(N\\) es el número de enlaces y \\(U\\) es la utilización máxima deseable con la que se dimensionan los enlaces. Ejemplo 4.6 Para una red de grado 4, en la que se desea dejar libre un 20% de la capacidad de los enlaces en el caso de una falla, el dimensionamiento de los flujos no debe rebasar el 60% de utilización: \\[L_f = 80\\%-\\frac{80\\%}{4} = 60\\%\\] En algunas ocasiones se tiene una idea general de los volúmenes de información generados en las redes de acceso pero se desconocen los patrones de tráfico detallados. En estos casos, no queda más remedio que recurrir a generalizaciones y suponer que los volúmenes de tráfico se concentrarán en los repositorios de información, o que se distribuirán uniformemente entre las redes de acceso. Para apoyar el diseño de la red en estas circunstancias, se puede utilizar la siguiente fórmula de equilibrio de tráfico. El tráfico que entra a un nodo del núcleo debe ser igual a la cantidad de tráfico que sale del mismo: \\[\\Sigma_{i=1}^{N_a} v_a^i\\times U_a^i = \\Sigma_{j=1}^{k_b} v_b^j\\times U_b^j,\\] donde \\(N_a\\) es el número de redes de acceso que llegan a un nodo, \\(v_a^i\\) es la capacidad del enlace de la i-ésima red con una utilización media de \\(U_a^i\\), \\(k_b\\) es el grado del nodo en el núcleo y \\(v_b^j\\) la capacidad del j-ésimo enlace con una utilización media de \\(U_b^j\\). Ejemplo 4.7 Considere una red nacional que tiene 1,000 sitios (o redes de acceso). Los usuarios generan en promedio \\(950\\,GB\\) de datos por día hacia los demás sitios. No hay elementos para determinar cómo se distribuye este volumen de tráfico entre las distintas redes de acceso. Lo que sí se ha estimado, es que el 20% de este volumen se genera durante la hora de mayor actividad (la hora pico). Todos los sitios se conectan a nodos en el núcleo por medio de enlaces \\(E1\\). Por políticas de la empresa, los enlaces en el núcleo también son \\(E1\\) y como criterio de diseño, estos enlaces no deben rebasar el 50% de utilización en condiciones normales de operación (es decir, sin tomar en cuenta fallos en la red). Se busca una red dorsal de grado 4. ¿Cuántos nodos en el núcleo deben considerarse? En primer término, hay que determinar cuál es la utilización de los enlaces de acceso: \\[U_a = \\frac{0.2(950\\,GB/dia)}{1,000}\\times \\frac{8\\,b}{3,600\\,s}\\times\\frac{1}{2.048\\,Mb/s} = 20.6\\%\\] Ahora se puede estimar el número de enlaces por nodo: \\[\\begin{aligned} N_a\\times v_a\\times U_a &amp;=k_b\\times v_b\\times U_b\\\\ N_a &amp;= \\frac{4\\times 2.048\\,MB/s\\times 0.5}{2.048\\,Mb/s\\times 0.206}\\\\ &amp;= 9.7 \\Rightarrow 9 \\end{aligned}\\] Por consiguiente, se necesitarán \\(1000/9\\approx 112\\) nodos. Perturbación de la topología La topología obtenida puede no ser la mejor aún si cumple con los criterios de costo y desempeño. Para generar otras topologías, se repite el proceso introduciendo perturbaciones controladas generando nuevos identificadores para los nodos. Más importante aún, la topología inicial fue diseñada respondiendo a criterios de conectividad sin tomar en cuenta el tráfico en la red. Si se tiene un conocimiento general de los flujos, la topología resultante puede modificarse atendiendo a criterios como los siguientes: Nodos que intercambien altos volúmenes de información deben tener enlaces conectados directamente. Enlaces con muy poca utilización pueden ser eliminados y su tráfico asignado a enlaces cercanos. Enlaces con tecnologías muy costosas también pueden ser eliminados. 4.5 Diseño basado en bloques modulares En las secciones anteriores se han presentado los conceptos y los beneficios de contar con un diseño jerárquico de tres capas y se han mostrado algunos algoritmos para satisfacer los requerimientos de diseño en las capas de acceso y dorsal. Otra característica que un buen diseño de redes debe cumplir es su modularidad. Sobre todo en redes medianas y grandes, un diseño modular simplifica las etapas de desarrollo y despliegue, facilita el mantenimiento de la red, reduce la probabilidad de dejar pasar errores no detectados, ofrece un buen rendimiento, y asegura la escalabilidad de la solución. El diseño modular consiste en contar con bloques básicos de módulos (o componentes) típicos en la red de una organización, por ejemplo, bloques de granjas de servidores, de redes SAN, de redes locales, de acceso al núcleo, etc. Sobre esos bloques básicos, se harán pequeñas modificaciones para satisfacer los requerimientos específicos de diseño, y se interconectarán para integrar la red. Dada su gran popularidad, en los siguientes párrafos se presentará el enfoque de diseño modular para una red de campus de tamaño medio. Bloque básico de acceso Excepto en redes locales inalámbricas y en algunos nichos muy específicos, el uso de concentradores en las redes locales ha disminuido dramáticamente. Las ventajas de seguridad y de mayor desempeño, aunado a una gran reducción en el costo por puerto de los conmutadores, han hecho que estos dispositivos sean los más utilizados en la actualidad, como se muestra en la figura 4.11. Figura 4.11: Diseño modular. Bloque básico de acceso Bloque básico de distribución En la figura 4.12 se muestra un bloque genérico de la capa de distribución. Dependiendo de las funcionalidades deseadas, y del tamaño de la red, en el bloque de distribución pueden encontrarse conmutadores, enrutadores o ambos. En la figura mostrada, se observan conmutadores a los que se conectan los conmutadores de la red de acceso. Las funcionalidades de la capa de distribución se ejecutan en los enrutadores. Figura 4.12: Diseño modular. Bloque básico de distribución Bloque básico de red dorsal En un campus, como en una red local grande, el núcleo de la red estará conformado por conmutadores de alto desempeño, como se muestra en la figura 4.13. En este caso particular, ni siquiera las funciones de enrutamiento se efectúan en el núcleo. Estas fueron delegadas a la capa de distribución. Figura 4.13: Diseño modular. Bloque básico de la red dorsal Con el diseño modular, construir una solución para una red consiste en interconectar los bloques básicos. Por ejemplo, en la figura 4.14 se muestra del lado izquierdo una solución para una red de campus genérica. Para satisfacer los requerimientos de disponibilidad, esta misma red puede robustecerse como se muestra en el diagrama de la derecha. La siguiente sección presenta algunos conceptos de topologías redundantes. Figura 4.14: Red genérica modular sin y con enlaces redundantes 4.6 Topologías con redundancia Con el fin de satisfacer los requerimientos de disponibilidad, el diseño de la red debe contar un cierto número de componentes redundantes que permitan asegurar, al menos, la continuidad de las operaciones de misión crítica de la organización. En las secciones anteriores ya se han introducido enlaces redundantes para tolerar fallos sobre todo en el núcleo de la red. Sin embargo, para que la infraestructura continúe operando, el diseño de la red también debe incluir redundancia en servidores, en enrutadores y nodos de conmutación, en los accesos a internet, y hasta en los sistemas de alimentación de energía eléctrica. La redundancia en equipos y enlaces incide directamente en el costo de la infraestructura; además, genera una red mucho más compleja de administrar, sobre todo en la configuración de políticas de enrutamiento y en la gestión y asignación de direcciones. El nivel de redundancia deseado debe elegirse con cuidado poniendo énfasis en el soporte a operaciones de misión crítica. Por otra parte, una duplicación cuidadosa de componentes en la infraestructura de red en general permite realizar un balanceo de cargas aumentando así el desempeño total de la red. Si los dispositivos redundantes no forman parte de la operación cotidiana de la red, resulta primordial garantizar que: está definido y funciona apropiadamente el mecanismo para conmutar a los equipos de respaldo; el tiempo de conmutación (llamado también tiempo de convergencia) a los equipos de respaldo está dentro de los parámetros aceptables para evitar caídas de las aplicaciones y servicios; la capacidad de operación en el respaldo es suficiente para soportar los servicios principales. En este caso, se debe contar con mecanismos que filtren el tráfico para dar prioridad a los flujos de misión crítica; los equipos y enlaces de respaldo son, efectivamente, independientes de la red en operación; la red de respaldo es probada periódicamente para asegurar su funcionamiento. Se recomienda que por lo menos dos veces al año se realicen simulacros de fallos en los que se activen los dispositivos de respaldo. Caso de estudio: Enlaces POTS de respaldo Como muchas organizaciones, una empresa del sector financiero contaba con enlaces de microondas para interconectar sus sucursales con el centro de cómputo en la oficina matriz. Como respaldo, cada sucursal tenía una línea telefónica con un módem de 14.4 a 33kb/s. Esta configuración funcionaba adecuadamente cuando los sistemas de la empresa tenían un modelo centralizado en el que las sucursales sólo ejecutaban aplicaciones de terminal virtual y a través de los enlaces se intercambiaban pantallas de texto únicamente. En un momento determinado, el área informática, la cual estaba completamente desvinculada del área de telecomunicaciones, decidió actualizar sus sistemas y migrar a un modelo de varias capas. Ahora las aplicaciones en las sucursales ejecutaban clientes robustos con interfaces gráficas y contenidos más complejos. Con el cambio, el volumen de tráfico entre el centro de datos y las sucursales aumentó sustancialmente. Este cambio sí fue notificado al área de telecomunicaciones y se aumentó la capacidad de los enlaces de microondas. En cambio, jamás se consideró la actualización en los enlaces de respaldo. El primer incidente posterior a la migración resultó caótico, pues el respaldo telefónico era totalmente insuficiente hasta para soportar las aplicaciones más esenciales. Fue necesario activar un plan de emergencia adquiriendo enlaces de banda ancha o enlaces privados que no estaban contemplados en el presupuesto original y hacer profundas adecuaciones a la infraestructura de red para soportar la nueva topología. Servidores y nodos Existen algunos servicios, como el Servidor de Nombres de Dominio (DNS), diseñados específicamente para trabajar con servidores redundantes. Desgraciadamente ésta es la excepción, y en general, el balanceo de cargas no es una tarea trivial: en los servidores se requiere de reglas especiales y de un cierto nivel de sofisticación para llevarlo a cabo exitosamente. Si la duplicación de servidores de aplicaciones, de archivos, de bases de datos, etc. resulta muy costosa, al menos se debe tratar de que estos servidores cuenten con discos RAID (Redundant Array of Inexpensive Disks) con el nivel de redundancia apropiado. En los nodos de conmutación, uno de los componentes que más fallos presenta es la fuente de alimentación, muchas veces debido a problemas en el sistema de suministro. Por ello, es común que los conmutadores y enrutadores de alto desempeño cuenten con fuentes de alimentación redundantes, las cuales deben estar conectadas a una línea de alimentación distinta. Enlaces Aunque los enrutadores conozcan varias trayectorias hacia un mismo destino, normalmente no distribuyen el tráfico entre ellas a menos que todas las trayectorias cuenten con la misma métrica. De no ser así, los enrutadores deben configurarse específicamente para permitir el balanceo de cargas. En las redes locales, el mecanismo de spanning tree en los conmutadores bloquea el balanceo de cargas al inhibir la existencia de varias trayectorias entre dos dispositivos. Gateway por omisión Cuando un dispositivo desea establecer una comunicación fuera de su red local, manda sus paquetes a un enrutador quien los redirige hacia la trayectoria que los conducirá al destino final. Este enrutador se conoce como el gateway por omisión y, típicamente, su dirección está configurada en las computadoras de la red local. Este gateway es un punto vulnerable: si falla, todos los dispositivos en la red local pierden conexión con el exterior. Si se agrega un segundo enrutador como respaldo, en caso de detectar una falla todos los equipos en la red local deberán reconfigurarse con la dirección del enrutador de respaldo, lo cual es inaceptable en redes de mediano tamaño. Se han propuesto varias soluciones a este problema. En primer lugar, los dispositivos podrían ejecutar un protocolo de enrutamiento interno (como RIP u OSPF) y recibir así los anuncios del gateway por omisión y del respaldo. En este caso, el protocolo en las estaciones debe ejecutarse en modo pasivo, es decir, atendiendo únicamente a los anuncios recibidos pero sin publicar sus tablas de ruteo para reducir el tráfico en la red. Desgraciadamente esta solución presenta varios problemas: aumenta la complejidad para administrar los dispositivos; los protocolos de ruteo consumen recursos; el tiempo para reconfigurar un dispositivo depende de la frecuencia con la que se anuncien las tablas en la red, el cual depende del protocolo utilizado. Este tiempo puede ser lo bastante grande como para no pasar desapercibido; se presta a ataques de seguridad pues un intruso o una máquina comprometida puede anunciarse como enrutador por omisión. Router Discovery Protocol, RDP, es otra solución basada en la difusión periódica de mensajes ICMP especiales por parte de los enrutadores. Si un dispositivo detecta que un mensaje no ha sido recibido, supone que el gateway ha fallado y puede enviar inmediatamente otro mensaje ICMP solicitando que un (posiblemente nuevo) enrutador se anuncie. Esta solución reduce algunos de los problemas anteriores, pero sigue siendo vulnerable a los ataques de seguridad, por lo que ha sido muy poco implementada. De hecho, hoy se recomienda fuertemente ignorar los mensajes ICMP relacionados con este protocolo. La solución más recomendada en la actualidad para ofrecer redundancia en el gateway por omisión es el protocolo VRRP (Virtual Router Redundancy Protocol), también conocido como enrutador fantasma, o la variante de Cisco: HSRP (Hot Standby Router Protocol). Figura 4.15: Configuración de enrutador fantasma Observe la figura 4.15. Se define un enrutador virtual con una dirección MAC y una dirección IP determinadas. El gateway por omisión responde a los mensajes enviados a estas direcciones virtuales y también envía al enrutador de respaldo mensajes periódicamente indicando que se encuentra activo. Si el enrutador de respaldo detecta que estos mensajes han dejado de enviarse, inmediatamente toma el papel del enrutador virtual, sin que los dispositivos en la red detecten el cambio. El único problema con esta solución es que el enrutador de respaldo no puede ser utilizado para balancear la carga en la red local, aunque hay protocolos propietarios que lo permiten. Salida a internet Al definir trayectorias redundantes, hay que poner especial atención al enlace entre la empresa y el punto de presencia (PoP) del proveedor de acceso (ISP). Esta liga es normalmente la más débil de la red. Dada la creciente importancia que han adquirido los accesos a Internet, una organización puede optar por alguna de las opciones que se muestran en la figura 4.16. Figura 4.16: Configuraciones redundantes para acceso a Internet Los principales elementos a considerar en estas configuraciones son la seguridad adicional de contar con más de un proveedor de acceso contra la complejidad que esto implica pues en general no es trivial definir, negociar y verificar un contrato de servicio para redes de tamaño medio. En las primeras dos opciones se tiene la ventaja de trabajar con un solo proveedor, con lo que se podrían obtener, además, tarifas preferentes. Sin embargo, se establece una relación de dependencia con la infraestructura del único ISP. La primera opción supone que el ISP cuenta con dos PoP relativamente cercanos entre sí, lo cual no siempre es el caso, sobre todo en ciudades pequeñas. Las opciones 2 y 4 se recomiendan para redes geográficamente muy dispersas, por ejemplo redes continentales o intercontinentales. Con las opciones 3 y 4 se consigue, en principio, redundancia del proveedor de acceso, pero ésto debe tratar de verificarse con los ISPs pues con frecuencia no existe realmente independencia de circuitos. Los grandes ISPs suelen tener contratos entre ellos o con el proveedor de transporte dominante, para compartir circuitos, por lo que si éstos fallan, los dos ISPs dejarían de operar. En todas las opciones, pero principalmente en las últimas dos, se deben definir e implmentar políticas especiales de enrutamiento para evitar que la red de la organización se vuelva una red de tránsito por el que los ISP intercambian tráfico entre ellos. 4.7 Problemas Problema 4.1 ¿De qué manera la metodología de diseño jerárquico mejora el desempeño, la disponibilidad y la escalabilidad de la red? Problema 4.2 ¿En dónde (red de acceso, distribución, núcleo) colocaría: Un firewall un switch que permita configurar VLANs un mecanismo de despacho de colas para ofrecer QoS? Problema 4.3 ¿Qué tipo de interfaces (100BaseT en par trenzado, serial E1, fibra óptica alta velocidad, ) esperaría encontrar en los enrutadores de acceso, de distribución y de núcleo? ¿Cuántas? Problema 4.4 Discuta brevemente qué tipo de topología (malla total, malla parcial, hub and spoke) utilizaría para interconectar: Un núcleo con 5 nodos; un núcleo con 20 nodos; una red de acceso para 5 nodos; una red de acceso para 20 nodos. Problema 4.5 A partir de la siguiente matriz de costos, y considerando un valor de \\(K=3\\), obtenga los mejores candidatos para poner los concentradores de acuerdo al algoritmo de Dysart-Georganas. 2 3 4 5 6 7 8 9 10 1 3 5 5 3 4 7 7.5 12 11.5 2 2 2 1 2.5 7 5 9 11 3 2 2 2 3.5 7 5 9 11 4 2 2 1 2.5 5 3 7 9 5 1 2 1 1.5 4.5 4 8 10 6 2.5 3.5 2.5 1.5 3 3.5 7.5 7.5 7 7 7 5 4.5 3 1 5 45 8 5 5 3 4 3.5 1 4 6 9 9 9 7 8 7.5 5 4 2 10 11 11 9 10 7.5 4.5 6 2 Problema 4.6 Considere la distribución de nodos en la figura y el tráfico introducido en cada nodo. Los valores entre nodos representan distancias en km. El tamaño de los paquetes es de \\(6,000\\, bits\\). Considerando que los enlaces entre ciudades son E0, Obtenga mediante el algoritmo de Kruskal la topología de árbol mínimo. Obtenga la topología de menor costo considerando que el retraso por segundo es de \\(\\$1,000.00\\). Suponga que el nodo inferior derecho es elconcentrador y que el costo de los enlaces es de \\(\\$40.00/km\\). Problema 4.7 Se desea diseñar una red para interconectar las Alcaldías de la Ciudad de Mëxico con las siguientes consideraciones: Dado que las Alcaldías Milpa Alta (MA), Xochimilco (XO) y Tláhuac (TL) están muy alejadas de las demás, éstas se conectarán entre sí en un anillo doble. La Alcaldía XO servirá de conexión entre MA y TL con las demás Alcaldías. Tendrá dos conexiones a la red de Alcaldías (es decir, su grado total será K=4). Las Alcaldías Miguel Hidalgo (MH), Cuauhtémoc (CU), Benito Juárez (BJ), Álvaro Obregón (AO) y Coyoacán (CO) tendrán tres enlaces redundantes (K=3). Las demás Alcaldías tendrán dos enlaces (K=2). Son Azcapotzalco (AZ), Cuajimalpa (CJ), Gustavo A. Madero (GM), Iztacalpo (IC), Iztapalapa (IP), Magdalena Contreras (MC), Tlalpan (TP) y Venustiano Carranza (VC). La tabla de distancias (equivalente al costo) se muestra a continuación, junto con el identificador de cada Alcaldía y el grado inicial de los dispositivos de interconexión. Muestre el diagrama de la red enumerando los enlaces conforme los va definiendo. Id K AO AZ BJ CO CJ CU GM IZ 4 AO 3 10.56 4.40 5.50 11.55 7.32 13.06 10.17 9 AZ 2 10.56 12.90 15.08 18.54 5.86 7.55 12.10 8 BJ 3 4.40 12.90 2.37 14.94 7.88 12.80 6.85 1 CO 3 5.50 15.08 2.37 14.43 10.20 15.11 8.41 13 CJ 2 11.55 18.54 14.94 14.43 18.06 23.70 21.55 2 CU 3 7.32 5.86 7.88 10.20 18.06 5.77 7.62 10 GM 2 13.06 7.55 12.80 15.11 23.70 5.77 9.28 11 IZ 2 10.17 12.10 6.85 8.41 21.55 7.62 9.28 15 IP 2 11.30 16.96 7.03 7.44 21.79 11.11 13.38 4.10 3 MC 2 10.63 20.85 11.46 9.74 8.49 17.88 23.52 18.13 14 MH 3 1.81 8.85 4.91 6.64 12.79 5.61 11.36 9.50 16 MP 2 29.89 37.77 25.78 24.38 36.30 31.93 33.89 24.82 5 TL 2 23.96 30.38 19.59 18.79 32.45 24.53 25.73 17.04 6 TP 2 11.61 21.83 9.21 6.89 15.85 17.08 21.82 13.96 7 VC 2 7.60 10.39 7.12 9.22 19.55 4.75 6.52 3.08 12 XO 2 16.41 26.47 13.65 11.77 22.93 20.99 24.55 15.43 Id K IP MC MH MA TL TP VC X0 4 AO 3 11.30 10.63 1.81 29.89 23.96 11.61 7.60 16.41 9 AZ 2 16.96 20.85 8.85 37.77 30.38 21.83 10.39 26.47 8 BJ 3 7.03 11.46 4.91 25.78 19.59 9.21 7.12 13.65 1 CO 3 7.44 9.74 6.64 24.38 18.79 6.89 9.22 11.77 13 CJ 2 21.79 8.49 12.79 36.30 32.45 15.85 19.55 22.93 2 CU 3 11.11 17.88 5.61 31.93 24.53 17.08 4.75 20.99 10 GM 2 13.38 23.52 11.36 33.89 25.73 21.82 6.52 24.55 11 IZ 2 4.10 18.13 9.50 24.82 17.04 13.96 3.08 15.43 15 IP 2 16.82 11.28 20.89 13.48 11.21 7.04 11.48 3 MC 2 16.82 12.43 28.11 25.15 7.97 18.52 14.89 14 MH 3 11.28 12.43 30.69 24.37 13.07 8.01 18.37 16 MP 2 20.89 28.11 30.69 8.75 20.44 27.87 13.37 5 TL 2 13.48 25.15 24.37 8.75 17.22 20.11 11.04 6 TP 2 11.21 7.97 13.07 20.44 17.22 15.60 7.08 7 VC 2 7.04 18.52 8.01 27.87 20.11 15.60 18.03 12 XO 2 11.48 14.89 18.37 13.37 11.04 7.08 18.03 Problema 4.8 Mediante el método de Stieglitz-Weiner-Kleitman, interconecte los nodos siguientes con un nivel de redundancia = 2. Considere que no está permitida la conexión entre los nodos 1 y 5. Enumere los nodos conforme los vaya definiendo. Problema 4.9 Diseñe la topología de costo mínimo con el método de Esau-Williams para una red cuya matriz de costos es la siguiente. 2 3 4 5 6 7 1 1 4 3 2 7 9 2 2 6 9 3 5 3 4 7 1 3 4 9 6 2 5 3 3 6 7 7 Estime el costo inicial y final. Problema 4.10 Para la siguiente matriz de costos, utilice el método de Kruskal para obtener la topología óptima: 1 2 3 4 5 1  6 3 3 5 2 6 - 3 5 1 3 3 3 - 4 5 4 3 5 4 - 3 5 5 1 5 3 - Problema 4.11 Diseñe la topología del núcleo de red que se muestra en la figura mediante el método de Stieglitz-Weiner-Kleitman. Se desea que la red pueda subsistir a dos fallos por lo menos. Los enlaces que se muestran en la figura ya están establecidos y no pueden eliminarse. Las líneas punteadas en la figura sirven únicamente como referencia. Problema 4.12 Explique brevemente para qué se utiliza la siguiente fórmula y qué signifca cada uno de sus términos. \\[\\bar v = \\Big\\lfloor\\frac{\\underset{j=1}{\\overset{F}\\Sigma} S_j\\times j}{N}\\Big\\rfloor+1\\] Problema 4.13 La siguiente es una matriz de tráfico en paquetes por segundo en la hora pico para la red de la figura. Los enlaces deben dimensionarse con una capacidad tal que la utilización durante la hora pico sea de 80%. A B C D A \\(11,000\\) \\(900\\) \\(750\\) \\(10\\,500\\) B \\(14,000\\) \\(10,000\\) \\(2,000\\) \\(1\\,300\\) C \\(9\\,500\\) \\(1\\,800\\) \\(4\\,200\\) 0 D \\(18\\,700\\) \\(550\\) 0 \\(3\\,150\\) Dimensione todos los enlaces. Considere que \\(A-C\\) y \\(A-D\\) deben repartirse equitativamente la carga de \\(A-B\\) si este enlace falla. ¿Con qué capacidad deben dimensionarse estos enlaces? Problema 4.14 Un concentrador hacia el núcleo recibe 25 enlaces como se muestra en la tabla. El núcleo está diseñado con una redundancia de K=3 y los enlaces (las troncales) no deben exceder 50% de utilización. ¿De qué capacidad deben ser estos enlaces? No. enlaces Capacidad Utilización 5 E1 37% 10 1Mb/s 57% 10 E0 75% Problema 4.15 De acuerdo al método de diseño con bloques funcionales, dibuje un bloque básico de red de acceso para una LAN. Problema 4.16 Mencione algunas de las consideraciones principales a tomar en cuenta cuando se decide contratar accesos a internet a través de dos proveedores de servicio distintos. Para un problema NP-Completo no se tienen algoritmos que proporcionen soluciones en tiempo polinómico, es decir, el tiempo esperado para resolverlo es el que tardaría una búsqueda exhaustiva de todas las posibilidades. Una red está conectada si existe una trayectoria entre cualquier par de nodos. Se dice que la red es de grado k o está k-conectada si existen k trayectorias disjuntas entre cualquier par de nodos, donde dos trayectorias son disjuntas si no tienen ningún enlace o nodo en común. "],["administración-de-redes.html", "Capítulo 5 Administración de redes 5.1 Evolución de administración de sistemas 5.2 Protocolos de administración 5.3 RMON 5.4 Administración de sistemas con SNMP 5.5 Problemas", " Capítulo 5 Administración de redes La administración de redes es una parte fundamental de los sistemas integrados de gestión de sistemas de información. Con el enorme crecimiento en la variedad y número de equipos y redes como el ambiente mostrado en la figura 5.1, una administración centralizada resulta impensable. La integración de equipos heterogéneos impide la utilización de sistemas propietarios de bajo nivel. La administración de redes representa el conjunto de funciones que permiten una adecuada explotación, mantenimiento, seguridad y seguimiento en la operación de la red. Figura 5.1: Una red heterogénea Para poder garantizar el acceso ubicuo a la información y servicios en las redes heterogéneas tendrá que haber una inversión considerable en tecnologías de gestión y monitoreo de redes y sistemas (NSM, network and systems management). Una mala estrategia de NSM es la razón típica por la que falla un esfuerzo de downsizing, así como por la que se perciben bajos incrementos en la productividad del personal no técnico. En el viejo modelo de cómputo centralizado, los administradores debían preocuparse únicamente por el equipo central y unas cuantas terminales tontas. En la actualidad, el modelo está basado en estaciones de trabajo inteligentes, capaces de realizar muchas más tareas pero que al mismo tiempo necesitan más dedicación y tiempo para su instalación, configuración, evaluación y mantenimiento. Estudios recientes (figura 5.2) sobre los costos incurridos en redes en Estados Unidos, muestran que el costo anual de administración de sistemas excede los costos de adquisición tanto de hardware como de software. Figura 5.2: Retos en la gestión de TI por su evolución 5.1 Evolución de administración de sistemas La evolución de los sistemas administrativos comienza con la administración tradicional del Mainframe y sus equipos asociados. A este ambiente de administración se le llamaba de invernadero (Glass house). Durante más de treinta años, los responsables de los sistemas informáticos debían gestionar todos sus sistemas en el centro de cómputo. En grandes centros, esto implicaba decenas de herramientas distintas, todas ellas especializadas en cada una de las plataformas disponibles. Conforme fue evolucionando el ambiente de cómputo, lo fue haciendo su gestión, transitando hacia un modelo distribuido donde se debía considerar la administración de: Minicomputadoras Estaciones de trabajo Computadoras personales departamentales A estos sistemas de cómputo hoy deben agregarse equipos portátiles como laptops, tabletas y hasta teléfonos inteligentes. Además de los equipos terminales, la gestión debe incluir, por supuesto, los equipos de interconexión, que es el tema central de este capítulo. De acuerdo al marco de referencia OSI, los componentes básicos de administración de redes se conforman por cinco subsistemas: Gestión de fallas (Fault Management) Gestión de configuración (Configuration Management) Gestión de seguridad (Security Management) Gestión de rendimiento (Performance Management) Contabilidad de recursos (Accounting Management) En el modelo OSI, estos subsistemas ofrecen un conjunto de servicios: Common Management Information Services, CMIS, con ayuda del protocolo de nivel de aplicación Common Management Information Protocol, CMIP. 5.1.1 Gestión de fallas La gestión de fallas debe ser preferentemente proactiva, es decir, se debe tratar de identificar tempranamente una condición potencial de falla antes de que ésta se manifieste. Se sigue un modelo de gestión activa en el que un mecanismo de sondeo solicita información a los dispositivos administrados. Debe haber un compromiso entre la precisión de la información adquirida y la cantidad de tráfico inyectado; también deben contemplarse canales alternos para recabar información de los dispositivos en caso de fallos en la red. También debe definirse con claridad, como se mencionó al presentar el modelo de administración de riesgos, que es importante definir qué fallas se desean gestionar y cuáles no. Debe considerarse que hay muchos tipos de fallos que ocurren raramente, pero sobre todo tienen un impacto bajo en el desempeño de la red, por lo que quizás no merece la pena incluirlas en el modelo (automatizado) de gestión de fallas. En el proceso de localizar y corregir problemas en la red, los tres pasos básicos son: Identificar (pasiva o activamente) un comportamiento anormal de la red. Aislar el problema; minimizar su impacto en el resto de la red. Tratar de reproducirlo para poder analizarlo. Corregir el problema. 5.1.2 Gestión de configuración La gestión de configuración tiene por objeto alinear la configuración de equipos a las políticas de operación definidas, simplificar su despliegue y minimizar errores durante este proceso. Para ello, es muy recomendable definir perfiles de usuarios con sus respectivos permisos para acceso a equipos y servicios de red. Las gestión de configuración debe tomar en cuenta tanto el nivel físico como el nivel lógico de la red. En operación, este subsistema obtiene datos e información de la red y los utiliza para gestionar la configuración de los diferentes dispositivos. Para ello se debe: Obtener información sobre la configuración actual de la red, incluyendo dispositivos instalados por el usuario (autodiscovery); Utilizar dicha información y las herramientas (automatizadas) para modificar los dispositivos según se desee; Almacenar información, mantener y actualizar el inventario y producir reportes. Este inventario debe incluir elementos como direcciones asignadas, hardware y software instalado, números de serie, localización física, capacidad, etcétera. 5.1.3 Gestión de seguridad La gestión de seguridad no se limita a los mecanismos de seguridad (protocolos, mecanismos de encripción) sino a toda la política de seguridad que debe ser implementada en la organización, como la administración de contraseñas, responsabilidades de los usuarios, seguridad de acceso físico, entre muchos otros. En capítulos posteriores se tratará con más detalle este tema. La protección de información importante se logra mediante la limitación en el acceso de los usuarios a hosts y dispositivos de red y mediante la notificación al administrador de red de intentos y violaciones de seguridad. Para realizar estos objetivos tenemos que: Definir e identificar la información que será protegida. Localizar los puntos de acceso a dicha información. Asegurar dichos puntos de acceso mediante los mecanismos apropiados (encripción, filtrado de paquetes, Identificación de hosts e Identificación de usuarios). Incluir seguridad física (control de acceso) de los dispositivos. 5.1.4 Gestión de rendimiento El objetivo de la gestión de rendimiento es el garantizar que la red está dentro de los parámetros de operación definidos en la etapa de diseño, mediante el monitoreo de los dispositivos de red y sus enlaces asociados para determinar su utilización, niveles de error, etcétera. El monitoreo continuo permite una gestión proactiva de la red y ayuda a anticipar las extensiones y cambios necesarios cuando la infraestructura de comunicaciones empieza a rebasar sus condiciones óptimas de operación. La gestión de rendimiento puede ser extremo a extremo y por componente. Deben identificarse las métricas a utilizar para evaluar el rendimiento. Para lograr los objetivos de la gestión de rendimiento es recomendable: Reunir información de la utilización actual de dispositivos y enlaces, como tiempo de respuesta, ocupación media de las colas, disponibilidad (MTBF), etcétera. Analizar la información relevante par discernir si hay altos niveles de utilización. Fijar umbrales de utilización. Valerse de herramientas de simulación para determinar cómo la red puede ser alterada para maximizar su rendimiento. 5.1.5 Contabilidad de recursos La gestión contable o auditoría de recursos almacena y procesa datos referentes al consumo de los recursos de la red. Esta información puede ser utilizada para fines de tarificación y también como apoyo para planear la capacidad y/o detectar fallas de la red. En esencia, la gestión contable implica: Medir la utilización de los recursos de la red para determinar su correcta distribución. Definir cuotas de uso utilizando métricas adecuadas. Determinar y reportar costos y utilización, para cobrar a los usuarios por el servicio. 5.2 Protocolos de administración Existe un conjunto amplio de protocolos y herramientas propietarias para la gestión de redes y sistemas informáticos, pero la admistración de redes se concentra en dos grandes categorías: el enfoque de administración de OSI y el de IETF. 5.2.1 Modelo de administración OSI En el modelo de administración OSI cada capa cuenta con una \"entidad de administración de capa\" (LME, layer management entity) que se comunica con la \"entidad de aplicación de administración del sistema\" (SMAE, system management application entity). Las SMAE se comunican entre sí a través de CMIP como se muestra en la figura 5.3. Figura 5.3: Modelo de gestión OSI Las primitivas del modelo definen los servicios ofrecidos (CMIS): Set (manipular información de administración) Action (ejecutar un comando, p.e., reinicio) Get (leer información de administración) Create (crear una nueva instancia de un objeto) Delete (eliminar una instancia de un objeto) Event-report (reportar eventos anormales) CMIS está basado en un modelo orientado a conexión. Todos los servicios se ofrecen con confirmación, aunque Set, Action e Event-report también pueden ofrecerse sin confirmación. Observe que en este modelo, para que pueda haber intercambio de información, toda la pila de protocolos debe estar funcionando. 5.2.2 Modelo de gestión IETF A los inicios del desarrollo de Internet, se implementó el protocolo ICMP (Internet Control Message Protocol) para depuración, control y monitoreo de errores del protocolo IP. Una de sus aplicaciones más conocidas es la herramienta PING que permite verificar si un dispositivo determinado es \"alcanzable\". Claramente, este tipo de mecanismos es insuficiente para la administración de redes cada vez más complejas. A mediados de los años 80 se reconoció la necesidad de incorporar un mecanismo de administración de red. Se consideraba que las propuestas de OSI para gestión debían ser incorporadas a Internet, pero OSI avanzaba muy lentamente, por lo que se optó en 1987 por seguir dos estrategias paralelas: A corto plazo se desarrollaría un protocolo sencillo basado en SGMP (Simple Gateway Monitoring Protocol), un protocolo utilizado para depurar la operación de enruteadores. Este protocolo es SNMP (Simple Network Monitoring Protocol). La idea de base es: el impacto de añadir administración de red debe tener un efecto mínimo en los nodos administrados A largo plazo se debía soportar CMIP sobre TCP/IP: CMOT Como se consideraba que las dos estrategias eventualmente deberían converger y, de hecho, se esperaba que la dominante fuera CMOT, se decidió definir un marco de referencia común inspirado en las ideas y las mejores prácticas de OSI. El marco de referencia común consistió en la definición de una Estructura de Información Común (SMI, Structure of Management Information) y un conjunto de elementos de administración: la base de información de administración (MIB, Management Information Base). En otras palabras, el modelo de administración en IETF se divide en dos partes: El formato de los mensajes (SMI) y el protocolo de transferencia entre agentes y administrador: SNMP La información que se administra: MIB En general, los dispositivos tienen agentes encargados de colectar la información que les corresponde (las variables MIB) y el administrador contacta a los agentes para recabar esta información. Ver figura 5.5. Siguiendo la idea de no sobrecargar los nodos, los agentes son entidades simplificadas y la inteligencia es desplazada a la consola de administración. Figura 5.4: Modelo de gestión IETF 5.2.3 Simple Network Management Protocol Especifica cómo debe ser la comunicación entre la estación de administración y los agentes para intercambiar información sobre las variables MIB en cuestión. En su primera versión (SNMPv1) se definen únicamente cinco comandos: Get-request La consola solicita el valor de una variable Get-next-request Solicita el valor de la siguiente variable. Se utiliza para recorrer tablas Get-response El agente devuelve el valor solicitado Set-request La consola establece el valor de una variable Trap El agente reporta alguna anormalidad La primera versión trabaja sobre UDP; en las últimas versiones, el protocolo de transporte puede ser TCP o UDP. Los comandos get, get-next y set esperan contactar al agente en el puerto 161; el comando trap espera contactar al administrador en el puerto 162. Las anormalidades reportadas con el comando trap están claramente definidas en SNMP aunque pueden extenderse. Como ejemplos de las anomalías reportadas tenemos: Reinicio del sistema. Enlace caído / restablecido. Autentificación fallida. Pérdida de vecino EGP. Para los administradores de redes, SNMP se mantiene oculto detrás de paquetes de software conocidos como consolas de administración. La consola manda comandos y recibe respuestas de los agentes que se encuentran en los dispositivos administrados. Como se muestra en la figura 5.5, los agentes se encargan de recabar información sobre objetos determinados, los cuales son un subconjunto de la Base MIB. Figura 5.5: Elementos de SNMP Para que un administrador pueda interactuar con un agente, deben pertenecer a la misma comunidad. Este concepto permite que en redes con muchos dispositivos la carga de la gestión se pueda distribuir entre varios administradores. En la figura 5.6 se aprecian dos comunidades, public y public2. En su empeño por mantener los agentes simples, SNMPv1 ignora el problema de seguridad de acceso. El identificador de comunidad es un campo en el paquete SNMP que viaja sin encriptar por la red. Figura 5.6: Comunidades SNMP 5.2.4 Base de datos de información de administración (MIB) Se trata de una estructura jerárquica en la que se definen los identificadores de los objetos (llamados las variables MIB) que pueden administrados a través de SNMP. Las variables MIB están organizadas en una estructura arborescente basada en el árbol de identificadores de objetos (OID, Object Identifier definido en conjunto por OSI y por la ITU. En la figura 5.7 se muestran las diez categorías de variables definidas en el RFC 1213, que corresponden a la segunda versión de variables, las variables MIB-II, definida cuando se separan, en 1989, los grupos CMOT y SNMP. Figura 5.7: Variables MIB-II en el árbol de identificadores de objetos Un objeto o variable MIB-II tiene un identificador único recorriendo el árbol desde la raíz hasta la hoja que lo representa. El primer nivel del árbol tiene tres ramas: los objetos definidos por ISO (1), los definidos por ITU -anteriormente CCITT- (2) y los definidos conjuntamente por ISO e ITU. Abajo de ISO encontramos la rama que corresponde a las organizaciones (org, 3) y dejado de ésta, hay una rama para el Departamento de Defensa de Estados Unidos (dod, 6). Así se sigue recorriendo el árbol hasta llegar al objeto deseado. Por ejemplo, el identificador 1.3.6.1.2.1.1.1 corresponde a la variable iso.org.dod.internet.mgmt.MIB-II.system.sysDescr. Una instancia de esa variable, es decir, el valor actual de la variable, es gestionado por el agente del dispositivo y se puede acceder a él agregando un 0 al OID de la variable, en este caso, 1.3.6.1.2.1.1.1.0. De manera similar, el OID 1.3.6.1.2.1.4.3.0 hace referencia a la instancia de la variable IpInReceives bajo la rama IP, que lleva el conteo de datagramas IP recibidos por el dispositivo. Los valores para la mayor parte de las características listadas pueden almacenarse en un solo entero. Sin embargo, MIB también define estructuras más complejas. Por ejemplo, la variable IpRoutingTable se refiere a la tabla de ruteo del ruteador. Dado que la administración de la red involucra muchos equipos heterogéneos, los responsables del protocolo establecieron normas muy específicas sobre cómo definir, identificar y representar las variables. El conjunto de estas normas es lo que se conoce como la estructura de la información de administración (SMI, Structure of Management Information). SMI indica que los objetos deben ser identificados en el árbol OID y deben ser definidos utilizando un subconjunto de la notación ASN.1 (Abstract Syntax Notation v1). ASN.1 es un metalengauje que permite representar de manera universal una información (tipos básicos y estructuras de datos complejas) y establece la forma en que debe ser codificada esta información para el intecambio de datos, es decir, la sintaxis de los objetos. Para SNMP, se eligió BER (Basic Encoding Rules) como el formato de codificación. Como se muestra en la figura 5.8, la codificación BER tiene tres campos: El identificador del tipo de objeto, la longitud del objeto y su valor. Figura 5.8: Reglas de codificación BER Como se muestra en la figura 5.8, los primeros dos bits indican si el objeto es un tipo de datos \"universal\", es decir, definido en ASN.1, si depende de la aplicación, si está definido en un contexto determinado (por ejemplo, en el contexto de la definición de SNMP) o si es un objeto definido por el usuario. El tercer bit indica si el objeto es un tipo básico, como un entero, o uno complejo, como una estructura de datos. Los cinco bits restantes de la etiqueta indican de qué objeto se trata dentro del dominio definido (universal, aplicación, etc.). Si la longitud del objeto es menor a 127 bytes, ésta ocupa un solo campo (el segundo octeto de la codificación); si es mayor, el bit más significativo es \"1\" y los demás bits indican el número de octetos subsecuentes que representan la longitud del objeto. En la tabla 5.1 se muestran algunos de los tipos de datos universales definidos en ASN.1 y se resaltan en negritas aquellos utilizados en la definición de SNMP. Tabla 5.1: Ejemplo de tipos de datos universales en ASN.1 Clase Tipo Descripción 1 BOOLEAN Valores cierto o falso 2 INTEGER Números enteros positivos o negativos 3 BIT STRING Serie de bits sin representación específica 4 OCTET STRING Cadena de caracteres 5 NULL Entrada sin valor 6 OBJECT IDENTIFIER Identificador de un objeto en el árbol OID 7 OBJECT DESCRIPTOR Cadena que describe el objeto 8 EXTERNAL Tipo definido en otro módulo 9 REAL Número en punto flotante 10 ENUMERATED Lista de enteros 16 SEQUENCE OF Conjunto de elementos 17 SET; SET OF Lista no ordenada de elementos Por su parte, la tabla 5.2 los objetos definidos en el contexto de SNMPv1 y que corresponden a los PDU del protocolo. Tabla 5.2: Tipos de datos ASN.1 en el contexto de SNMPv1 Clase Tipo.de.Dato 0 GetRequest 1 GetNextRequest 2 GetResponse 3 SetRequest 4 Trap 5.2.4.1 Formato de mensajes SNMP (v1) En la definición SMI el formato de los mensajes SNMPv1 tiene la siguiente estructura: El protocolo está definido en el RFC 1157. Una sección de la definición se muestra a continuación: De esta manera, un mensaje SNMP versión 1 está formado por una secuencia con cuatro campos: versión (tiene el valor 1), comunidad y cualquiera de cinco opciones para el PDU. El formato de los PDU para GetRequest (0), GetNextRequest (1), SetRequest (2) y GetResponse (3), es el mismo; lo único que cambia es el identificador de tipo de PDU con los valores indicados en paréntesis. En la figura 5.9 se muestra codificado un mensaje GetRequest de la variable sysDescr. El primer octeto es 0x30 hexadecimal (0011 0000 binario). Los dos primeros bits indican que es un tipo de dato universal, el tercero que es un tipo complejo y los últimos cinco (con valor 10000 binario, es decir, 16) nos dice que se trata de un SEQUENCE según lo indica la tabla 5.1. Esto es consistente con el formato del mensaje definido en el RFC 1157. Como el mensaje está codificado con reglas BER, el segundo octeto, 0x29 (41 decimal) muestra la longitud de esa estructura y los campos subsecuentes indican su valor. Figura 5.9: Mensaje SNMP, PDU GetRequest con codificación BER Como se trata de una solicitud, los campos errorStatus y errorIndex tienen un valor de cero. Para el campo OID hay un tratamiento especial: dado que el primer dígito sólo puede ser 0,1 ó 2 y el segundo es menor a 39, estos dos se combinan en un solo octeto siguiendo la fórmula \\(40*A + B\\), donde A es el primer dígito y B es el segundo. 5.2.4.2 SNMPv2 y v3 SNMPv1 (RFC 1157) no toma en cuenta la seguridad. Además, el acceso a las variables mediante los PDU GetRequest y GetNextRequest es muy ineficiente si se desea recabar mucha información. La segunda versión introduce mejoras en las áreas de: Rendimiento, Se agregan los PDU Get-bulk, Inform y se definen contadores con un tamaño mayor a 64 bits, entre otras). Seguridad. Desgraciadamente, los mecanismos para implementar seguridad en la segunda versión podían ser incompatibles entre sí, por lo que al final del día se tuvo que abandonar. Comunicaciones administrador-administrador. La tercera versión, SNMPv3 (RFC 2570-2576), tiene la categoría de Proposed Standard. es una profunda revisión del protocolo en la que se retienen las mejores propuestas de la versión 2 y se aclaran las confusiones para asegurar los mensajes mediante algoritmos de cifrado y autenticación. También se da flexibilidad para que el protocolo de transporte pueda ser UDP o TCP. 5.3 RMON Si cada dispositivo que es administrado con SNMP está conectado a una red, entonces puede contribuir al monitoreo activo de sus segmentos de red local como si se tratara de un analizador de protocolos. Eso es lo que se busca con RMON (Remote monitoring), una extensión a las variables MIB definida en el RFC 1757. Como se muestra en la figura 5.10, las funciones de monitoreo se dividen en diez grupos y permiten el monitoreo de topologías Ethernet y Token Ring. El agente se instala en sondas (probes). La segunda versión, RMON2, agrega objetos para el monitoreo de tráfico de red por encima de la capa de MAC. Figura 5.10: Árbol OID para variables RMON 5.4 Administración de sistemas con SNMP Como se comentó al inicio de este capítulo, SNMP puede ser utilizado para gestionar dispositivos y equipos terminales que estén conectados a la red aunque no formen parte de su operación. Para ello, sólo es necesario que se definan las variables MIB correspondientes en el árbol OID, típicamente debajo de la rama para enterprises. Por supuesto, los dispositivos deben tener los agentes dedicados a monitorear y actualizar los contadores relacionados con esas variables. Por ejemplo, con las extensiones MIB privadas, la estación de administración puede consultar al agente SNMP de una impresora y detectar el nivel de tóner o de hojas en la bandeja de impresión. De la misma forma, podría consultar un agente en un servidor para conocer la ocupación media de memoria principal, el espacio disponible en disco, el número de procesos activos, entre muchos otros parámetros. 5.5 Problemas Problema 5.1 De acuerdo al modelo de OSI, la gestión de la red se divide en cinco componentes. Descríbalos brevemente. Problema 5.2 Seleccione las respuestas correctas SNMP define [_____] que se enviarán del administrador al agente y viceversa el formato de los paquetes la codificación de los paquetes el número de paquetes ninguno de los anteriores Un agente es una computadora en la que se ejecuta el proceso [_____] de SNMP cliente servidor cliente y servidor ninguno de los anteriores SMI enfatiza tres atributos para manipular un objeto: [_____] nombre; tipo de dato; tamaño nombre; tamaño; método de codificación nombre; tipo de dato; método de codificación ninguno de los anteriores El OID de todos los objetos administrados por SNMP comienza por: [_____] iso.org.dod.internet.management.mib. iso.org.dod.internet.management.mib-II. iso-itu.std.dod.internet.management.mib-II. ninguna de las anteriores Para definir sus tipos de datos, SMI utiliza y extiende las definiciones de objetos establecidas en [_____] ASN.1 BER SNMP ninguna de las anteriores SMI se basa en el estándar [_____] para codificar la información que será transmitida por la red MIB ASN.1 BER ninguna de las anteriores El PDU GetReques se envía del [_____] para obtener el valor de una variable o conjunto de variables cliente al servidor servidor al cliente servidor a la red ninguna de las anteriores Problema 5.3 ¿Qué valor tiene el entero codificado en BER 02 01 08? Problema 5.4 Describa brevemente las operaciones Get, Get Next, Trap e Inform de SNMP Problema 5.5 Mencione los principales cambios propuestos en SNMPv3 respecto de SNMPv1 Problema 5.6 Codifique el siguiente segmento utilizando reglas BER. Suponga que los identificadores de los tipos de datos son: (1) Boolean, (2) integer, (9) real, (16) sequence, (28) character string. Suponga también que los enteros son de longitud variable y que los números de punto flotante son siempre de 8 bytes. "],["tecnologías-de-acceso.html", "Capítulo 6 Tecnologías de acceso 6.1 Cobertura de Internet 6.2 Tecnologías de acceso 6.3 Tecnologías de acceso inalámbricas 6.4 Problemas", " Capítulo 6 Tecnologías de acceso En este capítulo se presentan algunas de las tecnologías más populares para el despliegue de redes, tanto para la red de acceso como para el núcleo. Por su relevancia en la sociedad contemporánea, antes de presentar las tecnologías de acceso, iniciamos esta parte con algunas estadísticas sobre la penetración de internet. Esta información nos será de mucha utilidad al analizar la factibilidad de garantizar la cobertura de Internet a toda la población13. 6.1 Cobertura de Internet Internet se ha consolidado como una herramienta muy poderosa que ha afectado prácticamente todas las esferas en las que nos desarrollamos como sociedad. Desde su creación, la cobertura de Internet ha crecido muy rápidamente. Como se observa en la figura 6.1, mientras en 1995 el número de usuarios llegaba a 16 millones, lo que representaba un 0.2% de la población mundial total, en diciembre de 2018 el número de usuarios alcanzó los 4,313 millones, aproximadamente 56.5% de la población. Figura 6.1: Usuarios de Internet por año En marzo de 2019 esta cifra alcanzó un total de 4,346 millones los cuales se distribuían geográficamente como se muestra en la figura6.2. Sin embargo, al analizar la tasa de penetración por región, se observa una enorme desigualdad, la cual puede estar ligada a factores socioeconómicos en términos de acceso a servicios de Internet, pues mientras que en Norteamérica y Europa la penetración rebasa el 85%, tanto Asia (51.7%) como África (35.9%) se encuentran por debajo del promedio global de 56.3%. Figura 6.2: Usuarios de Internet (en el eje y porcentaje en la barra) y tasa de penetración. Datos a marzo de 2019 6.1.1 Red de acceso Una red de acceso es la parte de una red de comunicaciones que conecta a los suscriptores con su proveedor de servicios inmediato. Un ejemplo de red de acceso es el par trenzado en el bucle local del operador telefónico, también llamado última milla, que se refiere a la porción de la red que alcanza físicamente las premisas del usuario final. La infraestructura de las redes de acceso puede llegar a representar entre el 70% y 80% de los recursos físicos para los incumbentes. Las redes de acceso representan un mercado muy competido y con muchos retos para los proveedores, sin embargo, también es un mercado con grandes tendencias de crecimiento. En la década anterior representaba del 16% al 20% de los ingresos globales de las empresas de telecomunicaciones y prácticamente todos los operadores tradicionales. Se observan dos tendencias en la oferta de los proveedores de acceso a Internet: Las Redes de Nueva Generación (NGN, Next Generation Network), que ofrecen una amplia gama de servicios de valor agregado en la última milla (independientemente de la tecnología de acceso). Su modelo de negocios está basado en los servicios ofrecidos. La provisión de acceso, que ofrece infraestructura con muy alta capacidad y un suministro de bajo costo (dumb pipes). Los servicios ofrecidos son de bajo valor agregado, por lo cual su modelo de negocio está basado en la administración de la infraestructura. Actualmente, la mayoría de los operadores busca migrar hacia las NGN debido a los incentivos que ofrecen, entre los que se encuentran maximizar los ingresos a través de la oferta de nuevos servicios de Internet (correo electrónico, compartir archivos, mensajería instantánea, comunicaciones unificadas, navegación, Web 2.0, etc.) y la conformación de paquetes de triple y cuádruple play (voz, banda ancha y televisión, y acceso móvil). En la figura6.3 se observa cómo en seis años cambió drásticamente la conformación del tipo de tráfico cursado por los operadores móviles. El tráfico de voz se ha mantenido relativamente estable, pero el de datos ha crecido más que exponencialmente. Figura 6.3: Tráfico por tipo La figura6.4 muestra cómo durante el mismo periodo el crecimiento en los ingresos de los operadoresse ha mantenido más o menos estable (0.3% de aumento). El incremento mayor en ingresos viene de la venta de equipos móviles. Figura 6.4: Ingresos de los operadores La tendencia hacia mayores servicios a través de Internet explica el crecimiento exponencial en el tráfico cursado. Tan sólo de 2010 a 2017, el volumen de datos se ha incrementado 40 veces. Esto hace necesario un despliegue de infraestructura, creando así el círculo virtuoso de la economía digital (figura6.5) en el que una mayor oferta de servicios y contenidos produce un aumento en la demanda de los mismos, lo cual hace necesario un nuevo despliegue de redes. Redes más poderas permiten la creación de contenido y servicios de más calidad y con mayores demandas de capacidad... y así sucesivamente. Figura 6.5: Círculo virtuos de la economía digital Los mayores obstáculos que enfrenta este círculo, es la demanda excesiva por el crecimiento de flujos de video, como lo muestran los datos de Cisco VNI presentados en la figura6.4. En el 2017, el 59% del tráfico de datos móviles era de video y se estima que para 2022 será del 79%. Figura 6.6: Tráfico de datos móviles estimado (en 2017) por tipo 6.1.2 Contexto de Internet y servicios de Banda Ancha en México En los últimos años la cantidad de usuarios de Internet en México ha crecido considerablemente, alcanzando 71.3 millones en el 2017, lo que representa más del doble de los usuarios en 2010, como se muestra en la figura 6.7. Figura 6.7: Usuarios de Internet en México Sin embargo, recordemos que es necesario considerar el aumento en la oferta de este servicio no sólo en términos de cantidad de usuarios, sino la tasa a la que se da esta penetración con relación a otras economías, y el porcentaje de penetración dentro de las distintas regiones del país14. Comparando la penetración de Internet en México con otras economías, hacia el año 2018 la figura6.8 muestra que en 2018, la cobertura en México se encuentra por encima del promedio en Latinoamérica con un 65% de penetración, aunque un poco lejos de Argentina, Chile y Costa Rica. Figura 6.8: Penetración de Internet en América Latina (2018) Si ahora vemos la situación de México con respecto a la OCDE, el panorama cambia drásticamente pues el país se encuentra en las últimas posiciones en servicios de banda ancha tanto fija (penúltimo lugar, figura6.9) como móvil (ante penúltimo lugar, figura6.10). Cabe destacar que en el servicio móvil las suscripciones ofrecidas son prácticamente en su totalidad de voz y datos, en vez de ofrecer también suscripciones de sólo datos, como prácticmaente todos los países de la OCDE. Figura 6.9: Suscripciones de banda ancha fija (OCDE) Figura 6.10: **Suscripciones de banda ancha móvil (OCDE)* 6.1.3 Banda Ancha Hemos estado hablando de banda ancha. Se trata de un término particularmente elusivo al tratar de definirla. La banda ancha puede verse como un conjunto de tecnologías de red avanzadas o como el motor de una radical y gran transformación que revitaliza la entrega de los servicios existentes y da pie a la aparición de nuevos e innovadores servicios. La banda ancha se ha convertido en una infraestructura fundamental que determina la competitividad nacional de los países en la economía digital mundial. En términos técnicos, la banda ancha ha tratado de definirse en función de las velocidades de transmisión mínimas, del tipo de tecnología (por ejemplo, IMT-Avanzadas móviles o las llamadas tecnologías 4G), y de una serie de conceptos funcionales entre los que se encuentran conexión permanente y alta capacidad. El debate para tratar de definirla no se ha detenido, y a manera de conciliación, suele definirse de manera informal e imprecisa, a la banda ancha como las tecnologías que permiten la entrega fiable con con calidad de servicios convergentes de voz, datos y video. La banda ancha ha demostrado ser un elemento esencial para el desarrollo económico, a tal punto que en 2010 Finlandia la declaró como un derecho ciudadano, al mismo nivel que la alimentación, la salud y la educación, pues promueve la creación de nuevos servicios digitales, mayor eficiencia y productividad, estimula la competitividad, habilita ventajas de la globalización y promueve el acceso a redes de innovación. En México, si bien no se especifica con servicios de banda ancha, el acceso a Internet se convirtió en un derecho ciudadano plasmado en la Constitución, con la Reforma en Telecomunicaciones de 2013. La figura6.11 muesra el nivel de penetración de banda ancha fija en los países de la OCDE en 2018, así como su ingreso per cápita en dólares PPP15. Hay una clara relación entre penetración banda ancha y nivel de riqueza, pero es difícil demostrar cuál es la dirección de la causalidad. Figura 6.11: Penetración de banda ancha vs GDP (OCDE) Prácticamente todos los países desarrollados y en vías de desarrollo disponen de banda ancha. Hoy en día la principal preocupación es evitar la creación de brechas digitales en términos de velocidad o calidad de acceso. Grupos multipartitas como la Comisión de la Banda Ancha para el Desarrollo Digital de las Naciones Unidas están fomentando que todos los países en sus planes de desarrollo den prioridad al desarrollo de redes fijas y móviles de alta velocidad a fin de cimentar sus previsiones de crecimiento económico a largo plazo y de competitividad en la era de la información. Parece que en México todavía hay mucho por hacer en banda ancha fija pues tenemos un gran rezago en términos de velocidades y de suscripciones, como lo muestra la figura6.12. Podemos ver que el país apenas llega a un nivel de alrededor de 15 suscripciones por cada 100 habitantes, y de éstas, la gran mayoría son de una velocidad de entre 10 y 25 Mbps. Esto se encuentra muy lejos de objetivos como los fijados en Europa, que establecen una penetración del 100% al menos a 30 Mbps y del 50% al menos a 100 Mbps y hacia 2018 se encuentran cerca de ser alcanzados, según el reporte DESI (Digital Economy and Society Index) de la Comisión Europea de 2018. Figura 6.12: Banda ancha fija. Penetración y velocidades de acceso (OCDE) Con relación a los costos a usuarios finales, México presenta un rango de precios muy grande en comparación con otros países de la OCDE, con costos que van de aproximadamente 30 dólares PPP para usuarios de bajo nivel (20 GB/mes, 0.250 Mbps) a los 65 dólares PPP para usuarios de alto nivel (200 GB/mes, 25 Mbps). Este comportamiento se debe principalmente a que si bien los precios a usuarios de bajo nivel se encuentran en el promedio de la OCDE, cuando vemos los precios ofertados a usuarios de alto nivel, México tiene los niveles más elevados como se observa en la figura6.13. Aún con precios ajustados PPP, el acceso a banda ancha fija sigue siendo muy costoso para los deciles más bajos de la población nacional; justamente los grupos de población que se encuentran fuera de los servicios de Internet. Figura 6.13: Comparativo de costos (USD, PPP) en países de la OCDE a junio de 2017. (a) Costos usuarios de bajo nivel; (b) Cosos a usuarios de alto nivel; (c) Rangos de costos (USD, PPP) 6.2 Tecnologías de acceso Las expectativas de tráfico para los próximos años alcanzan niveles difíciles de asimilar. Se estima que para 2022, el tráfico IP anual será de 4.8 zettabytes16, lo cual, para dimensionar la magnitud, es igual a 11 veces el tráfico generado en 2012. 82% de ese tráfico será de aplicaciones de video y 71% será por medio de tecnologías inalámbricas. Para cumplir con estas expectativas, las tecnologías de acceso deben estar en constante evolución de manera que la provisión de contenidos y servicios innovadores. Las tecnologías de acceso pueden clasificarse en dos categorías: Tecnologías por línea, como lo son: xDSL Cable Módem PLC Fibra + cable Tecnologías inalámbricas, tales como: WiFi WiMax Celular Satélite, HAP Radio cognitivo 6.2.1 Tecnologías de acceso cableadas xDSL xDSL (Digital Subscriber Line, Línea de Abonado Digital) es una familia de tecnologías que proporcionan acceso a Internet mediante la transmisión de datos a través del par trenzado de hilos de cobre convencionales de la red telefónica convencional. Emplea los rangos de frecuencia que no son utilizados para el transporte de voz, maximizando así el ancho de banda de la red de acceso (llamada la red de última milla) de los operadores telefónicos. En el equipo que se coloca en las instalaciones del usuario17 hay un filtro (splitter) el canal de frecuencias bajas, dedicado a los servicios de voz, del resto de frecuencias, dedicadas a la transferencia de datos. De forma similar, en la central telefónica las tarjetas DSLAM (Digital Subscriber Line Access Multiplexer) separan las frecuencias bajas (que dirigen a la red telefónica) de las altas, donde viaja el tráfico que debe ser dirigido a Internet, como se muestra en la figura6.11, que se refiere al tecnología ADSL(Asymmetric DSL), que es la tecnología xDSL más popular. Figura 6.14: Tecnología ADSL ADSL se denomina asimétrica porque las capacidades de descarga o de bajada (de la red hacia el usuario) y de subida (en sentido inverso) de datos no coinciden. La tecnología ADSL está diseñada para que la capacidad de bajada sea mayor que la de subida, ideal para servicios de red cliente-servidor en los que el cliente (el usuario) solicita un servicio, por ejemplo la descarga de una página web y el servidor, por ejemplo el servidor Web, la envía. La consulta requiere de mucho menos capacidad que la transferencia del contenido. En ADSL, el ancho de banda dedicado a la transferencia de datos se divide en hasta 256 subportadoras (las espigas rectangulares de la figura). Típicamente cada una es un canal de 4 kHz con modulación QAM. En principio, cada una puede transportar hasta 60 kbps (4000 baudios, con 15 bits por baudio). Si una subportadora tiene mucho ruido, ésta deja de utilizarse (las espigas blancas de la figura), lo que reduce la velocidad de transmisión del medio. Como se ha mencionado, ADSL es la más popular de las tecnologías xDSL, pero existen muchas otras. La siguiente tabla muestra las características de velocidad teóricas de algunas de las más populares. ADSL HDSL ADSL2+ VDSL Asymmetric High Bit Rate Asymmetric Very High Speed DSL DSL DSL DSL De la red 256 kbps 1,168 kbps 25 Mbps 13, 42, 200 Mbps al usuario Del usuario 64 kbps Simétrico 1 Mbps 1, 5, 6 Mbps a la red 1.5 Mbps Distancia 2.5 km Hasta 4 km 1 km 52 Mbps 750 m Dentro de las ventajas de esta tecnología se encuentran la recuperación del costo de despliegue del par de abonado, la retención del ARPU (Average Revenue per User, ingreso medio por suscriptor), su bajo costo y su ubicuidad. Además, ofrece la posibilidad de hablar por teléfono al mismo tiempo que se navega por Internet. Un gran inconveniente de ADSL es que la velocidad del servicio está limitada por varios factores, como la calidad del cable y la distancia hasta la central telefónica, así como por el número de pares que viajan juntos en el ducto. Además, en muchos países el marco regulatorio puede limitar la desagregación del par18, lo que representa una barrera de entrada a la competencia. Otro inconveniente de ADSL es que los enlaces asimétricos pueden ser inadecuados para las características de los usuarios contemporáneos, como lo muestra la figura@ref[fig:upstream) obtenida de tráfico en un servidor de Twitter. En un entorno más familiar, jamás se debería poner un servidor local a través de un enlace asimétrico. Figura 6.15: Tráfico simétrico en Internet Cable módem El cable módem es un tipo especial de módem diseñado para modular y demodular la señal de datos sobre una infraestructura de televisión por cable. Se utiliza principalmente para distribuir el acceso a Internet de banda ancha, aprovechando el ancho de banda que no se utiliza en la red de televisión por cable. (#fig:cable_modem)Cable módem Esta tecnología presenta las ventajas de que el cable es de mayor calidad que el par trenzado. Bajo la norma DOCSIS 3.1, se pueden alcanzar velocidades de 10 Gbps en el canal descendente y 1 Gbps en el ascendente, en condiciones ideales. La principal desventaja es que los abonados de un mismo vecindario comparten el ancho de banda proporcionado por una única línea de cable coaxial. Por lo tanto, la velocidad de conexión puede variar dependiendo de cuántos equipos están utilizando el servicio al mismo tiempo. Otras desventajas son las inversiones necesarias para modificar la infraestructura para servicios digitales bidireccionales, y que el unbundling (la desagregación de servicios) puede ser legalmente complicado pues frecuentemente estas redes se despliegan con los propios recursos de los operadores (lo que no necesariamente fue cierto al desplegar las redes telefónicas a principios del siglo XX). PLC (Power Line Communications) Se refiere a un conjunto de tecnologías para ofrecer acceso a través de los cables de energía eléctrica. El servicio se ofrece a través de la red eléctrica de baja tensión (110-380V) por medio de unidades acondicionadoras que filtran y separan las señales eléctrica y de datos. Como red de acceso, esta tecnología, también llamada BPL (Broadband over Power Lines), prometía ser una alternativa a las redes de DSL y de cable módem aprovechando que la cobertura de la red eléctrica es mayor que la de las redes telefónicas y de cable. Desgraciadamente, las señales de datos, al ser transmitidas en un medio no blindado, pueden causar interferencia a otros sistemas de radio-comunicaciones, lo que ha limitado severamente su despliegue en varios países, aunque en los últimos años se observa un interés creciente en aplicaciones emergentes de Internet de las cosas (IoT) que no requieren de transferencias de datos a alta velocidad. En cambio, HomePlug (HP) es una variante utilizada para desplegar redes locales dentro de los hogares ha logrado una gran aceptación en el mercado. Su última versión, AV2 puede alcanzar hasta 500 Mbps, más que suficiente para transportar flujos de video de alta definición dentro de los hogares. HomePlug es desarrollada por CEPCA (Consumer Electronics Powerline Communications Alliance). Por su parte, ITU desarrolla un nuevo estándar G.9960 conocido como G.hn. Pretende utilizar cualquier medio de cobre en el hogar (cable telefóncio, cable coaxial de TV y las líneas eléctricas de corriente alterna) para transmitir datos a tasas de hasta 1 Gbps. Figura 6.16: Esquema PLC Redes de fibra e híbridas Una red híbrida HFC (Hybrid Fiber Copper) incorpora fibra óptica y cable coaxial para crear una red de banda ancha. Esta tecnología se implementa típicamente como evolución de las redes de televisión por cable para soportar la demanda creciente dde transferencia de datos y más canales de video de alta definición. Este tipo de red busca aprovechar las ventajas de cada tecnología que la conforman. Los hilos de fibra óptica permiten la cobertura de largas distancias con un mínimo de amplificación y regeneración de la señal, sin embargo, debido al costo y dimensiones de los multiplexores y demultiplexores ópticos, no se suele conectar directamente a los nodos de clientes; la fibra es conectada a un gateway el cual contiene al menos un transformador óptico que permite la transición de la señal a la red de cable coaxial. El cable coaxial permite que la señal llegue a los equipos terminales. Las limitaciones de estos sistemas son que la señal puede necesitar ser amplificada y el sistema puede ser susceptible a interferencias externas. (#fig:red_HFC)Diagrama de una red HFC Redes FTTx La fibra hasta el punto x (Fiber To The x) se refiere a un conjunto de tecnologías de telecomunicaciones que se basan en la utilización de hilos de fibra óptica y sistemas de distribución ópticos para ofrecer servicios avanzados a hogares y negocios. Este tipo de tecnología presenta características muy deseables, como: Alta inmunidad a la interferencia electromagnética Enorme ancho de banda para grandes distancias El costo de la fibra es del mismo orden que el cobre, aunque los despliegues, interfaces y OAM (Operación, Administración y Mantenimiento) son más costosos Debido a estas ventajas, los despliegues de fibra han crecido enormemente en los últimos años. La figura6.17 muestra que las tecnologías que mayor crecimeinto tuvieron de 2017 a 2018 son FTTH (23.2%) y otros despliegues de fibra (5.3%), esto en detrimento, sobre todo, de los despliegues en par trenzado, que tuvieron una caída de -7.1%. Figura 6.17: Crecimiento de suscriptores por tecnología Para finales de 2018, la región dominante en despliegues de fibra óptica son los países asiáticos donde la cobertura se acerca al 90% de hogares y edificios (figura6.18). Figura 6.18: Número total de suscriptores a FTTx en el mundo Este fenómeno está ocurriendo en casi todos los países desarrollados y la mayoría ya han entrado a la etapa de crecimiento acelerado de las características curvas S de absorción tecnológica (que retomaremos en el capítulo7). La figura6.19 muestra el crecimiento de suscriptores en España de 2007 a 2017 y la figura6.20 la de Estados Unidos de 2001 a 2010. Llama la atención tanto el parecido de las curvas como los números absolutos en ambos países. Figura 6.19: Penetración de FTTH en España Figura 6.20: Penetración FTTH en EUA. (a) Hogares visitados; (b) Hogares antendidos Cabe mencionar que los Estados Unidos se vieron beneficiados por agresivas políticas públicas como el USA Recovery and Reinvestment Act, que destinó más de 7 mil millones de dólares para fomentar el despliegue de fibra óptica durante la administración de Barak Obama. Este tipo de iniciativas permitió que una gran cantidad de hogares tuvieran la posibilidad de contratar accesos en fibra aunque menos de la tercera parte lo haya hecho, como se muestra en la figura6.20. 6.3 Tecnologías de acceso inalámbricas Las tecnologías inalámbricas utilizan una señal radioeléctrica (una portadora) para transmitir información modificando algunas de sus propiedades (frecuencia, fase o amplitud). Como redes de acceso a Internet, las tecnologías inalámbricastienen la gran ventaja de que es mucho más rápido y económico levantar una torre y colocar antenas de comunicaciones, que hacer tendidos de cable en postes o ductos en ciudades y en zonas rurales. Esta flexibilidad ayuda a explicar porqué las tecnologías inalámbricas han tenido un avance sorprendente en los últimos años. De hecho, si se extendieran las curvas mostradas en la figura6.21, las velocidades ofrecidas por las tecnologías cableadas e inalámbricas convergerían hacia el año 2030. Figura 6.21: Velocidades de tecnologías de acceso La realidad es que es difícil creer que esto sucederá, pues las tecnologías inalámbricas se enfrentan a muchos retos, como la relativa escasez de espectro radioeléctrico y la gran variabilidad de las capacidades de estas tecnologías, en función de la frecuencia que utilicen para su transmisión. Por ello, es claro que no se tendrá una gran tecnología dominante sino una serie de soluciones tecnológicas que atienden diferentes nichos con distintas necesidades. La figura6.22 muestra una panorámica de las tendencias tecnológicas en función de dos criterios: movilidad y velocidad de transmisión. Figura 6.22: Evolución de tecnologías inalámbricas Tratando de presentar de manera sencilla conceptos que técnicamente son relativamente complejos, siempre encontramos un compromiso entre la cobertura (qué tan lejos puede propagarse) y la capacidad (qué tasa de transferencia ofrece) de una red. Por ejemplo, en la figura6.23 ubicamos algunas de las tecnologías inalámbricas más populares en función de su tasa de transmisión y su cobertura. Figura 6.23: Sistemas inalámbricos en cobertura vs capacidad La curva envolvente de la figura anterior es llamada Equi-cost/Equi-power porque un elemento clave del alcance y de la calidad de la señal (y por tanto, de la tasa de transmisión), es la potencia de transmisión la cual puede estar limitada por el costo (a mayor potencia, mayor costo) o por aspectos regulatorios para evitar daños a la salud o interferencias a otros servicios. Dos factores que afectan la propagación de una señal radioeléctrica son la frecuencia de la señal y la distancia entre el emisor y el receptor. La fórmula simplificada de Friis (figura6.24) muestra cómo es esta relación en términos de la potencia recibida: Es directamente proporcional a la potencia transmitida e inversamente proporcional al cuadrado de la distancia y de la frecuencia. \\[P_{rx} = P_{tx}\\{\\frac{1}{f\\times d}\\}^2\\] Figura 6.24: Fórmula simpificada de Friis En las frecuencias más altas, la longitud de onda es del orden de las moléculas de agua en la atmósfera y la energía de la señal es parcialmente absorbida pór éstas (y por otros objetos); en cambio, portadoras en frecuencias más bajas, como las bandas de 600 y 700 MHz, hasta pueden atravesar paredes sin sufrir una atenuación tan alta. En la figura6.25 se muestra cómo este efecto tiene un impacto en la cobertura de una radio base transmitiendo con la misma potencia en distintas frecuencias, en una zona urbana. Mientras que a 900 MHz se cubre con una calidad aceptable un área con un radio de 1.5 km, a 3.5 GHz esta cae a menos de 500 metros. Figura 6.25: Efecto de la frecuencia en el área cubierta por una radio base Como la potencia de recepción disminuye con la distancia, la relación señal a ruido (SNR, Signal-Noise-Ratio) disminuye drásticamente. Por ello, informalmente, la energía que debe tener un bit en un símbolo debe ser mayor; más formalmente, la eficiencia espectral disminuye con la distancia, como se muestra en la figura6.26. La figura muestra cómo debe utilizarse un modulador con menor densidad conforme aumenta la distancia. Las distintas curvas son para diferentes tipos de receptor en las instalaciones del usuario (CPE, Customer Premises Equipment). Figura 6.26: Densidad del modulador en función de la distancia Figura 6.27: Tasa de transmisión vs distancia El hecho de que se utilice un modulador con menor eficiencia espectral es lo que explica que la tasa de transmisión disminuya conforme nos alejamos del AP en las redes WiFi o de la radio base en las redes celulares, como se muestra en la figura6.27. Resumiendo, la tasa efectiva estará afectada por la potencia del transmisor, la distancia del receptor y la frecuencia de la portadora. Es claro que también se verá afectada por objetos que obstruyan la trayectoria entre transmisor y receptor, la ganancia de la antena del receptor (que depende de su tamaño, entre otros factores) y, de manera muy importante, de la cantidad de espectro (el tamaño del bloque) que el regulador del espectro radioeléctrico en un país (en nuestro caso, el Instituto Federal de Telecomunicaciones), otorgue para el servicio de comunicación inalámbrica de que se trate. La siguiente tabla muestra características de equipos receptores CPE (Customer Premises Equipment) para cierta tecnología inalámbrica fija, por ejemplo, WiMAX. Con un CPE situado en el exterior (por ejemplo, en la azotea de una casa), es de esperar que se pueda tener un enlace sin obstrucciones (llamado línea de vista) entre emisor y receptor. Además, la antena del receptor puede ser de tamaño relativamente grande, con una ganancia sustancial. En cambio, un AP en el interior recibe una señal atenuada por paredes y otros obstáculos. Lo mismo ocurre con un receptor USB el cual, además, tiene una antena muy pequeña y con una ganancia muy pobre. Tipo CPE Rango de alcance % cobertura Exterior 20-25 km 100% Interior 10.6 km 53% USB 2.8 km 14% En la figura6.28 ejemplifica cómo los factores anteriores tienen un impacto profundo al desplegar un sistema de comunicaciones en distintos entornos: En función de la frecuencia, el área de cobertura, el tamaño del bloque y las características del entorno, el número de radiobases requerido para desplegar el sistema varía drásticamente. Como se explicará más adelante, en una zona urbana densa, no merece la pena tener frecuencias bajas con bloques pequeños, pues el factor determinante es la densidad de usuarios. Una radio base con un bloque pequeño rápidamente se saturará por la demanda de los usuarios, por lo que habrá que desplegar muchas más radio bases, reduciendo su potencia de transmisión para que no se genere interferencia entre ellas. En cambio, en unza zona rural, hay muy pocos usuarios, y se tenderá a privilegiar el uso de frecuencias que cubran la máxima distancia posible. Figura 6.28: Despliegue de estaciones base en área metropolitana A continuación se presentan brevemente algunas de las tecnologías de acceso inalámbricas más populares en la actualidad. Acceso satelital La idea de tener una estación de relevo para telecomunicaciones (un espejo) en el espacio fue propuesta por el científico y escritor Arthur C. Clarke y por Vahid K. Sanadi en los años 40. Unos años más tarde, la Marina de Estados Unidos realizó varias pruebas de concepto en proyectos de espionaje utilizando a la luna, nuestro satélite natural, como espejo para captar las señales emitidas por los radares soviéticos. El primer satélite artificial lanzado exitosamente fue el satélite ruso Sputnik I, en 1957. No se utilizó para sistemas de telecomunicaciones pero permitió validar la factibilidad técnica de esta tecnología. Un año más tarde la NASA manda fabricar el primer satélite diseñado como relevo de telecomunicaciones dentro del proyecto SCORE. Los satélites para telecomunicaciones más comunes se encuentran en la llamada órbita de Clark en honor a Arthur Clark, a 35,784 km (\\(\\approx 36,000 km\\)) sobre el nivel del mar (snm) en el ecuador. A esa altura, las fuerzas centrífuga y centrípeta están en equilibrio y el satélite tiene la misma velocidad angular que la rotación de la tierra, por lo que parecen fijos en el espacio para un observador terrestre. Se les llama satélites geo-estacionarios o GEO (Geo-stationary earth orbit). Todos los satélites dedicados a difusión de radio y televisión y muchos de los utilizados para acceso a Internet son GEO, pues entre sus ventajas está el hecho de que una vez orientada la antena hacia el satélite, ya no tiene que ajustarse. Los satélites GEO poseen otras ventajas, como el hecho de que, en principio, con sólo tres satélites se podría cubrir casi toda la superficie terrestre, como se muestra en la figura6.29 (a). Los satélties GEO tienen varias limitantes. En primer lugar, es que es muy costoso y complejo colocar un satélite a esa altitud. Además, se requiere de antenas relativamente grandes y de una potencia de transmisión sustancial para que la comunicación pueda llevarse a cabo. Por ello, el uso de satélites GEO para comunicaciones en smartphones, es sencillamente imposible. Por último, la latencia imposibilita comunicaciones bi-direccionales en tiempo real. Los satélites MEO (Medium-earth Orbit) operan órbitas entre 5,000 y 12,000 km snm. Su diseño es más simple y su puesta en órbita mucho menos costosa. Se utilizan para aplicaciones como monitoreo y fotografiado terrestre, monitoreo atmosférico y para aplicaciones militares. Se han llegado a utilizar como sistemas de comunicaciones, pero ello implica el uso de antenas especiales que van siguiendo la órbita de un satélite, y del relevo de la comunicación entre algunos de ellos, que forman una constelación. Figura 6.29: Sistemas satelitales (a) geo-estacionarios y (b) de órbita baja Los satélites LEO (Low-earth orbit) operan a distancias de 500 a 1,500 km snm. A esa distancia, la latencia es bastante reducida; además, se pueden utilizar antenas de baja potencia (alrededor de 1 Watt). Sin embargo, su cobertura es muy limitada, por lo que se deben desplegar constelaciones de alta densidad (decenas de satélites, como se muestra en la figura6.29 (b)) y el relevo entre ellos es muy complejo. Su tiempo de vida es muy corto (5 a 8 años). Si una constelación tiene 50 satélites, se tendría que estar renovando un satélite cada dos meses, lo que hace que estos sistemas tengan un costo de operación muy alto. Como tecnologías de acceso, los satélites GEO de los años 90 operaban en la banda de frecuencias C (4 a 6 GHz) con anchos de banda de 36 a 72 MHz y ofrecían velocidades de acceso de 128 kbps a 2 Mbps. En la última década se ha hecho popular el uso de la banda Ku (11 a 14 GHz) con anchos de banda más granades. Junto con sofisticadas tecnologías de compresión y codificación, estos satélites permiten velocidades de bajada de cientos de Mbps. Aunque el servicio de acceso a Internet es sustancialmente más costoso que con las otras tecnologías de acceso, los satélites artificiales garantizan conectividad en zonas donde ninguna otra tecnología es factible, como en aviones, océanos, montañas o zonas desérticas. Para reducir los costos de los equipos terminales en enlaces satelitales GEO, se han popularizado los sistemas con antenas VSAT (Very small apperture terminal). En éstos, las antenas de los equipos terminales son comparativamente muy pequeñas (70 cm a 1.5 mt). Dado que estas antenas tienen una ganancia muy baja, la comunicación entre dos usuarios pasa a través de un nodo central (un hub, figura6.30) con una antena mucho más grande (4 a 10 metros) que permite una gran amplificación de la señal. Desgraciadamente, esto hace que se duplique la latencia, pues el mensaje va del emisor al satélite, de éste al hub, nuevamente al satélite y finalmente al destinatario. Figura 6.30: Sistema VSAT A pesar de que la gran mayoría de los proyectos de constelaciones satelitales LEO de los años 90 fueron un gran fracaso comercial, en los últimos 5 años ha resurgido el interés por estos sistemas y empresas como SpaceX, Amazon y OneWeb están invirtiendo miles de millones de dólares para desplegar constelaciones con cientos de satélites intercomunicados entre sí a través de enlaces láser. HAP (High Altitude Platform) Las estaciones HAP consisten en vehículos típicamente no tripulados a una altitud de 20 a 50 km en un punto específico relativo a la tierra. Tienen muchos usos en aplicaciones militares y de monitoreo remoto. Para telecomunicaciones, se trata de estaciones de relevo que ofrecen una excelente alternativas para regiones donde no hay servicio terrestre o satelital. También pueden ser desplegados rápidamente para dar cobertura en áreas que han sido afectadas por desastres naturales. Las tecnologías HAP se empezaron a probar a principios de los años 90, principalmente para aplicaciones militares. A finales de los años 90 el interés por estas tecnologías fue tal, que la Unión Internacional de Telecomunicaciones asignó bandas de frecuencia específicas para servicios HAP: 2 GHz en la banda 47/48 GHz y 6 GHz en la banda 27/31 GHz. Potencialmente, las HAP ofrecen muchas ventajas: Mayor cobertura y menor tiempo de despliegue que un sistema basado en radio-bases, y por supuesto, con menor interferencia. Con relación a los sistemas satelitales, su costo es mucho menor así como la latencia. Además, se pueden regresar fácilmente a tierra para su reparación y actualización. Por estas razones, se esperaba que las HAP fueran una atractiva alternativa para tecnologías de acceso a Internet. En la década pasada, hubo muchos proyectos para evaluar su factibilidad en Japón, Corea del Sur, Brasil, la Unión Europea y Estados Unidos. Sin embargo, de las decenas de proyectos documentados, sólo continuaron tres: Los proyectos LOON de Google (actualmente en suspensión), Aquila de Facebook (que se ha aliado con Airbus) y Zephyr de Airbus (figura6.31). Figura 6.31: Plataforma no tripulada Zephyr de Airbus Algunas de las razones por las que estas tecnologías no han sido desplegadas son el hecho de que, a pesar de que tienen un costo sustancialmente menor que los satélites, los componentes de los HAPs son sofisticados, pues deben soportar condiciones de operación muy adversas y tener una alta tolerancia a fallos. En zonas urbanas otras alternativas de acceso son más atractivas y en zonas aisladas, el modelo de negocio los hace inviables. Por otra parte, varias de las pruebas de concepto se cancelaron por fallos en los vehículos no tripulados, lo que representa un serio riesgo de seguridad en zonas pobladas. Radios cognitivos Tradicionalmente se ha considerado que el espectro radioeléctrico es un recurso escaso que debe ser regulado. La forma en que esto suele hacerse, es concesionando bloques de espectro para usos específicos. Por ejemplo, el rango de frecuencias de 87.5 MHz a 108 MHz, está contemplado para concesionarios de radiodifusión en FM, mientras que la banda de 1.9 GHz es una de las frecuencias utilizadas por concesionarios de telefonía celular. Sin enmbargo, el espectro es un recurso particular pues no se desgasta con su uso. Además, mientras las frecuencias para unos servicios pueden estar saturadas (por ejemplo, telefonía celular) otras bandas pueden estar seriamente subutilizadas (por ejemplo, bandas para radio aficionados, difusión de TV en ultra alta frecuencia y frecuencias para uso militar). Con el fin de aprovechar mejor el espectro y dejar atrás la percepción de que se trata de un recurso escaso, nace la idea de utilizar radios cognitivos (CR, cognitive radio). Se trata de dispositivos que pueden ser configurados dinámicamente para utilizar las bandas de frecuencia disponibles en su entorno y si se detecta que éstas empiezan a ser utilizadas (por otros CR o por los concesionarios de la banda), el radio puede brincar a otras frecuencias libres. De esta manera, se consigue lo que se conoce como gestión dinámica del espectro. Las primeras propuestas de CR eran un subconjunto de los radios definidos por software. El dispositivo sensa su entorno; si encuentra una banda que aparentemente esté libre, calcula cuánta energía generaría su transmisión y si ésta no rebasa un umbral llamado temperatura de interferencia (figura6.32), transmite en esa banda; de lo contrario, busca otro canal. Figura 6.32: Temperatura de interferencia Se ha encontrado que es sumamente complicado implementar dispositivos basados en la idea de sensar el entorno y calcular la temperatura de interferencia para establecer una red de comunicaciones confiable. Se requiere de nuevos protocolos y algoritmos para estimar de manera confiable qué bandas podrían ser utilizadas sin generar interferencia. Una alternativa, surgida en el Reino Unido y ampliamente aceptada, sobre todo para aprovechar los bloques de espectro asignados a difusión de televisión abierta, es la conocida como espacios blancos (white spaces). La idea básica es que el regulador sabe qué frecuencias ha asignado en qué regiones, y por lo tanto, cuáles quedan libres en esa región (figura6.33). El dispositivo tiene un módulo de geolocalización y cuando desea establecer una comunicación, determina su ubicación, consulta la base de datos del regulador y se auto-configura para utilizar alguana de las bandas que están libres en su entorno. Figura 6.33: Radio cognitivo El grupo de trabajo IEEE 802.22 ha definido estándares para desplegar redes de área regional (hasta 100 km con baja densidad de población) con base en la tecnología de radios cognitivos con espacios blancos. En Estados Unidos, la base de datos del órgano regulador que consultan estos radios es administrada por Google. La IEEE también ha definido el estándar IEEE 802.11af para desplegar redes locales inalámbricas con tecnología de espacios blancos. Se le conoce como White-Fi o Super Wi-Fi. 6.3.1 Telefonía celular Como se ha mostrado al inicio de este capítulo, la penetración de Internet con tecnologías inalámbricas ha tenido un crecimiento exponencial en todo el planeta. El principal medio de acceso inalámbrico a Internet es la telefonía celular o móvil. En México, el crecimiento de líneas móviles por cada 100 habitantes ha rebasado el 90% como se muestra en la figura6.34. La penetración de la telefonía móvil ha sido tal que en algunos países ha logrado desplazar hasta el 50% de las líneas de telefonía fija. Figura 6.34: Evolución de la teledensidad de líneas de telefonía móvil en México Como se muestra en la tabla6.1, desde la segunda generación de telefonía celular se han contemplado tecnologías para facilitar la transferencia de datos en las redes móviles, y, eventualmente, proveer acceso a Internet. Tabla 6.1: Evolución de generaciones de telefonía celular Generación Tecnología Velocidad.típica GSM 14.4 kbps 2G HSCSD 36.6 kbps PDC; CDMA 64 kbps 2.5G GPRS 115 kbps 2.75G EDGE 384 kbps 3G UMTS 2 Mbps Figura 6.35: Aumento de demanda de tasas de transferencia Las primeras generaciones de telefonía celular respondían razonablemente bien a las necesidades de teléfonos con pantallas sumamente pequeñas y capacidad de procesamiento muy limitada. Con la llegada de los teléfonos inteligentes, y en especial con la introducción de la familia de dispositivos móviles de Apple, el panorama cambió radicalmente, como se muestra en la figura6.35. Estos dispositivos en los que toda la superficie es una pantalla, basados en el uso de aplicaciones móviles (Apps) y que requieren de conexión constante (a veces, continua) a Internet rebasaron por mucho las capacidades de las redes celulares. Ello llevó a los fabricantes y operadores a acelerar sus hojas de ruta y se dio un rápido despliegue de subgeneraciones (3.5G, 3.75G) que ofrecían mayores velocidades de transferencia, hasta llegar a las actuales redes 4G (LTE, Long Term Evolution) cuya principal característica es que son redes basadas en los principios de transferencia de datos (conmutación de paquetes), en las que la telefonía es un servicio más. Para zonas donde las redes celulares están altamente congestionadas o la cobertura al interior de edificios es un problema, se han implementado alternativas ingeniosas que complementan el acceso a Internet a través de teléfonos inteligentes. Dos de ellas son las femto celdas y UMA que aparecen en la figura6.36. Figura 6.36: Alternativas pra desfogar carga en redes celulares: (a) Femto celdas; (b) Unlicensed Mobile Access FemtoCeldas Se trata de una pequeña estación base que proporciona tecnología celular dentro del hogar o la oficina. Se enlaza a la red del operador a través de cualquier tecnología de acceso disponible (típicamente una tecnología alambrada, como FTTH o ADSL). En esa red se establece una VPN con los equipos del operador para fines de administración, tarificación, etcétera. Los puntos de acceso utilizan las mismas frecuencias que las macro celdas, pero operan a una potencia mucho menor para evitar interferencia. Algunas femto celdas permiten el relevo con las macro celdas (handover) sin perder la conexión, exactamente como ocurre con la itinerancia entre radio bases. Con técnicas similares a las empleadas para planear el despliegue de redes WiFi, se eligen los puntos óptimos para la instalación de estos puntos de acceso, lo que permite incrementar la capacidad a bajo costo y mejorar la cobertura en interiores. Unlicensed Mobile Access Es el nombre comercial de una tecnología llamada Generic Access Network (GAN). También se le llama Wi-Fi Calling, VoWiFi. Dado que prácticamente todos los teléfonos móviles en la actualidad cuentan con la posibilidad de conectarse a redes WiFi, esta tecnología permite que los usuarios utilicen los recursos de la red local cuando se encuentren dentro de su cobertura para acceder a Internet pero también para establecer llamadas telefónicas. Si el usuario sale del área de cobertura de la red WiFi, la red celular se ocupará de hcer la transición a la radio base de manera transparente. La principal diferencia entre las femto celdas y UMA/GAN, es que en este último caso, el relevo se hace transitando de una pila de protocolos (WiFi) a otra (GSM, UMTS, LTE) además de la transición del AP a la radio base. A esto se le conoce como relevo vertical (vertical handover) y requiere de dispositivos móviles que cuenten con esta funcionalidad. WiMAX - IEEE 802.16 Worldwide Ineroperability for Microwave Access es una norma de transmisión de datos que pertenece a las tecnologías de última milla, utiliza las ondas radioeléctricas en las frecuencias 2,5 a 5,8 GHz y puede llegar a proveer una cobertura de hasta 70 km. En las implementaciones para cobertura móvil, WiMAX permite que los usuarios se desplacen de manera similar que en las redes móviles convencionales (UMTS). También, las características de WiMAX lo hacen adecuado para aplicaciones potenciales como acceso a Internet, backhaul o triple play. Una de sus mayores ventajas es que permite proveer servicios de banda ancha a zonas con baja densidad poblacional que presentan altos costos por usuario. Una de las últimas implenetaciones de WiMAX (WiMAX2-IEEE 802.16m) tiene como objetivo alcanzar una velocidad de descarga de 100 Mbit/s, esto la da potencial para el despliegue de tecnologías de cuarta generación. Figura 6.37: Esquema de comunicación WiMAX 6.4 Problemas Problema 6.1 Además de ADSL, identifique otras tres tecnologías de acceso, resaltando su principal ventaja y grado de madurez en México Problema 6.2 ¿Por qué en un sistema de VSAT se debe recorrer el segmento terrestre-satélite 4 veces? Problema 6.3 ¿Aproximadamente cuál es la latencia de fuente a destino para una comunicación en los globos de Google? (Tip: un globo vuela más o menos a la altura de un HAP) \\(\\approx 60 \\mu\\,s\\) \\(\\approx 130 \\mu\\,s\\) \\(\\approx 120 ms\\) \\(\\approx 240 ms\\) Problema 6.4 El perfil de Don Lencho en Internet es principalmente el de un consumidor de contenidos: Ve regularmente series y películas de Netflix y algunos videos de youtube. En su localidad, solo tiene dos opciones: Contratar un enlace ADSL de 5 Mbps con una renta mensual de $500.00, o un FTTH de 10 Mbps con una renta mensual de $800.00. ¿Qué le recomendarías? Justifica muy brevemente tu respuesta Agradecemos la colaboración de Rodrigo Calderón Serafín y Diego Gutiérrez Romero para actualizar este material. En este curso no ahondaremos en las tasas de penetración y las inequidades de cobertura de Internet en México, pero debemos tenerlo presente. El costo del dólar llevado a Paridad de Poder Adquisitivo (Parity Purchasing Power) para eliminar las diferencias entre el valor de las distintas economías. 1 zettabyte = \\(10^{21}\\) bytes CPE, Customer Premises Equipment, se trata del modem que instala el operador Desagregación del bucle local, o del par trenzado, se refiere a un lineamiento que permite que distintos operadores puedan ofrecer sus propios servicios (voz, datos, video) por el par trenzado a pesar de no haber sido ellos quienes lo desplegaron. "],["análisis-tecno-económico.html", "Capítulo 7 Análisis tecno-económico 7.1 Introducción 7.2 Métricas financieras 7.3 Análisis tecno-económico", " Capítulo 7 Análisis tecno-económico 7.1 Introducción Los proyectos de TI en general, y de infraestructura de redes en particular, deben ser coherentes con los objetivos de negocio y poder justificarse en términos financieros o estratégicos. La empresa tiene objetivos tácticos o duros, que son cuantificables (objetivos SMART), tales como reducir costos, aumentar la productividad, o reducir el tiempo de lanzamiento al mercado. También tiene objetivos estratégicos o suaves, los cuales son subjetivos y más difíciles de medir, como incrementar la eficiencia, obtener ventajas competitivas sostenibles y facilitar una reingeniería de procesos de negocio. En cualquier caso, al final del día se busca que el dinero empleado para el proyecto (y que se obtiene de un préstamo, de las utilidades, o de aportaciones de los inversionistas), se utilice con el fin de maximizar el retorno de la inversión para los accionistas. En este capítulo se hace una muy breve introducción a las métricas financieras básicas utilizadas para analizar y justificar proyectos en las organizaciones, utilizando ejemplos de proyectos de TI. Posteriormente se muestran los elementos a considerar al hacer un análisis tecno-económico de un proyecto de redes. 7.2 Métricas financieras Las métricas financieras básicas para analizar inversiones en proyectos son las siguientes: Costo total de propiedad (TCO, Total Cost of Ownership) Periodo de recuperación (PBP, Pay Back Period) Retorno de Inversión (ROI, Return On Investment) Valor presente neto (NPV, Net Present Value) Para proyectos específicos de TI algunas consultoras han propuesto métricas más especializadas, como Rapid Economic Justification (REJ), Total Value of Opportunity (TVO) y Total Economic Impact (TEI). Estas métricas rebasan el alcance del curso. 7.2.1 Costo total de propiedad El costo total de propiedad (TCO) tiene por objeto considerar de manera explícita los costos incurridos durante TODO el ciclo de vida de la solución. Cuando se tiene poca experiencia es común tomar en cuenta únicamente los costos de adquisición de las tecnologías involucradas (por ejemplo, la compra de equipo e infraestructura), pero el proyecto tiene costos a lo largo de toda su vida útil. Al menos se deben tomar en cuenta los costos de las fases que se muestran en la figura 7.1: Figura 7.1: Fases en el ciclo de vida de un proyecto Los costos de adquisición se incluyen en el indicador conocido como CAPEX (Capital Expenditures); los de operación, administración y mantenimiento (OA&amp;M), en el OPEX Operational Expenditures). A manera de ejemplo, podemos imaginar el costo total de poseer un automóvil. Además del costo de adquisición del auto (el CAPEX), debemos tomar en cuenta los costos de tenencia, mantenimiento, consumo de gasolina, seguros, estacionamiento, etcétera. En en un horizonte de tres años, estos costos pueden ser lo bastante onerosos como para no tomarlos en consideración. En algunos proyectos el OPEX puede ser el factor dominante, al grado que en ocasiones TCO se interpreta como Total Cost of Operation. En otro tipo de proyectos, el factor dominante puede ser el CAPEX; para ellos a veces la métrica que se utiliza es TCA, Total Cost of Acquisition. En proyectos de TI, como la adquisición de un ERP o un manejador de base de datos, el CAPEX suele representar entre 20% y 30% del costo total de operación en un horizonte de 3 a 5 años. En la actualidad, con la gran penetración del cómputo en la nube (cloud computing) estos términos se han puesto de moda, pues con la provisión de servicios de TI en la nube se reduce drásticamente el CAPEX (se dejan de comprar servidores, infraestructura de soporte) y se aumenta el OPEX (se paga regularmente el arrendamiento de los servidores virtuales). Dado que en el despliegue de grandes redes de comunicaciones los costos de implementación iniciales pueden ser muy grandes, en este tipo de proyectos suelen especificarse de forma aislada como IMPEX, Implementation Expenditures. Aquí se incluyen costos como la adquisición del terreno, obra civil para instalaciones y levantamiento de la torre, el equipo de la estación base y antenas, etcétera). Para calcular el TCO se deben incluir todos los elementos que puedan identificarse, como: Hardware (servidores, instalación, configuración, planeación, modificaciones a la infraestructura existente, ...) Software (adquisición, licencias, configuración, mantenimiento, adaptaciones, costos de estabilización, ...) Capital humano (nuevo personal, capacitación, apoyo para instalación, gestión del cambio, ...) Indirectos (arrendamiento del local y de los equipos, luz, probabilidad e impacto de fallos, ...) No es extraño que se aumente un margen (entre 10% y 30%) al TCO para incluir costos adicionales que no han sido claramente identificados. Ejemplo 7.1 19 Se tienen tres alternativas para desplegar una red local: una red cableada (LAN); una red inalámbrica convencional basada en puntos de acceso (AP, Access Point) robustos distribuidos en las instalaciones (WLAN) y una red inalámbrica basada en un conmutador inteligente y puntos de acceso muy simples (repetidores) distribuidos en las instalaciones (Sw-WLAN). El conmutador en la última opción, es muy poderoso e incorpora, de forma centralizada, muchas de las funcionalidades que se espera encontrar en un AP, como control de acceso, configuración de VLANs, asiganción dinámica de IPs, gestión de potencia de portadoras, etc. Sin embargo, es un equipo muy costoso; en cambio, los APs para esta red son muy sencillos y económicos. El ambiente en el que se desplegará la red incluye 100 puestos de trabajo (100 computadoras) y es muy dinámico; se ha estimado que durante un año, alrededor del 30% de los puestos de trabajo deben re-ubicarse. Si durante esta reubicacion se pierde conectividad con la red, ese puesto de trabajo tendrá una pérdida de productividad estimada en $50 USD por año 20. Las computadoras en los puestos de trabajo incluyen una tarjeta de red cableada; si se desea desplegar una red inalámbrica, se deben adquirir nuevas tarjetas de red. Las siguientes tablas muestra los costos que se toman en cuenta para este ejemplo: Red Alambrada Computadoras 100 Tarjeta de red $0 Costo del conmutador por puerto $20 Instalación por puerto $400 Reinstalación por puerto $200 Porcentaje de reubicación por año 30% Pérdida de productividad $50 Herramientas de administración $4,000 OA&amp;M y licencias por año $200 WLAN Sw-WLAN APs 20 20 Costo AP $300 $100 Instalación AP $250 $250 Tarjeta de red $75 $75 Conmutador $0 $10,000 Herramientas de administración $4,000 $2,000 Herramientas Ctl. acceso $5,000 $2,500 OA&amp;M y licencias por AP por año $250 $150 Gestión de radio frecuencia por AP por año $200 $50 Los costos de adquisición de las tres alternativas son los siguientes: \\[\\begin{aligned} \\text{LAN} : &amp; (100)(\\$20)+ (100)(\\$400) + \\$4,000 = \\$46,000\\\\ \\text{WLAN}: &amp; (20)(\\$300)+(20)(\\$250)+(100)(\\$75)+\\$0+\\$4,000+\\$5,000=\\$27,500\\\\ \\text{Sw-WLAN}: &amp; (20)(\\$100)+(20)(\\$250)+(100)(\\$75)+\\$10,000+\\$2,000+\\$2,500=\\$29,000 \\end{aligned}\\] Considerando el CAPEX, parecería que la opción de la red local inalámbrica convencional es la más atractiva, y es que el costo del conmutador en la Sw-WLAN es muy elevado. Los gastos de instalación en la red cableada son muy altos, pues suponen el tendido de canaletas y cables a lo largo de la empresa. En un edificio con cableado estructurado, estos costos disminuirían considerablemente. Veamos ahora los costos de operación, administración y mantenimiento (OA&amp;M) por año: \\[\\begin{aligned} \\text{LAN} : &amp; (0.3)(100)(\\$200)+ (0.3)(100)(\\$50) + (100)(\\$200) = \\$27,500\\\\ \\text{WLAN}:&amp; (0.3)(100)(\\$0) +(20)(\\$250)+(20)(\\$200) = \\$9,000\\\\ \\text{Sw-WLAN}:&amp;(0.3)(100)(\\$0)+(20)(\\$150)+(20)(\\$50) = \\$4,000\\\\ \\end{aligned}\\] El OPEX anual de la red local con conmutador inteligente es menos de la mitad que el de la red inalámbrica convencional; las funcionalidades del conmutador empiezan a rendir frutos. Los dos son mucho menores a los de la red cableada porque en la reconfiguración de puestos no se requiere de reinstalaciones y no hay pérdida de productividad. El costo total de operación a tres años, es mucho más favorable para la red inalámbrica basada en conmutador inteligente: \\[\\begin{aligned} \\text{LAN} : TCO =&amp; \\$46,000+3(\\$ 9,000) = \\$128,500\\\\ \\text{WLAN}: TCO = &amp;\\$27,500 + 3(\\$9,000) = \\$54,500\\\\ \\text{Sw-WLAN}:TCO =&amp;\\$29,000 + 3(\\$4,000) = \\$41,000\\\\ \\end{aligned}\\] Una de las mayores dificultades para calcular el TCO en el despliegue de redes de telecomunicaciones, es que los costos pueden variar enormemente de una región a otra, y de un año a otro. Son mercados sumamente dinámicos. Las siguientes cifras se presentan únicamente como referencia para tener una idea muy somera de los costos de despliegue de este tipo de redes: Despliegues de redes WiFi municipales en Estados Unidos. Si la red contempla únicamente servicios no públicos (servicios municipales) se estimaba que el OPEX era de 15% del CAPEX por AP por año. Si la red ofrecía servicios públicos el OPEX se duplicaba pues se deben incluir costos de servicio a cliente, tarificación y marketing, entre otros. En algunas redes municipales el OPEX total fue 10 veces superior al CAPEX en un horizonte de 5 años. El arrendamiento de luminarias para instalar los APs variaba enormemente de un municipio a otro: En Louisiana costaba $86 USD por poste por año, mientras que en California el costo era de $36. Los AP con calidad comercial para despliegues a la intemperie con un solo radio, gastaban $20 USD de energía eléctrica por año; los AP con dos radios (ideales para despliegues de mallas WiFi municipales) gastan cinco veces más: $100 USD por año. Para despliegues de fibra al hogar (FTTH) en Canadá, se estimó un OPEX de 5% del CAPEX por nodo. La figura 7.2 muestran los porcentajes de los rubros más importantes en CAPEX y OPEX para el despliegue de una estación base de telefonía celular en Estados Unidos a principios de este milenio. Figura 7.2: Elementos que conforman el CAPEX y OPEX para el despliegue de una radio base Recordemos que estas cifras son únicamente un referente y que hay grandes variaciones dependiendo del contexto. Por ejemplo, en un país grande, el equipo de la red dorsal representa 30% del CAPEX, mientras que en uno pequeño, es sólo el 10%. Sin embargo, la adaptación de los sitios en el primer caso cubren el 30% del CAPEX, pero en los países pequeños puede ascender hasta 50%. Es interesante observar que los costos relacionados con los equipos de telecomunicaciones no son dominantes ni en CAPEX ni en OPEX, y, de hecho, la tendencia es que estos costos disminuyan con el teimpo. En México, en áreas rurales, el costo de interconexión era en promedio el doble que la figura anterior (18%), pero en algunas regiones podía alcanzar hasta el 70%, debido a la enorme variación en los costos de los enlaces dedicados: Un enlace E1 podía costar de $15 a $15,000 USD mensuales. Estas variaciones explican buena parte de la gran variación en cobertura celular que tenía México, donde todavía hay un porcentaje sustancial de comunidades no atendidas y subatendidas. Para tener una idea general de los costos de implementación, figura 7.3 muestra la distribución de costos para despliegues de redes LTE en un país nórdico en 2012. Figura 7.3: Distribución de CAPEX, OPEX, IMPEX para redes LTE en un país nórdico Sorprende la gran diferencia en TCO entre despliegues basados en macro-celdas (120,000) y micro-celdas (22,000). En el despliegue de micro-celdas, el componente más importante del OPEX es la interconexión entre celdas (backhaul) porque se deben desplegar muchas más celdas para la misma zona. Terminamos esta sección resaltando algunas características del TCO: Es muy conocido desde que la consultora Gartner lo empezó a utilizar en la industria de TI a finales de los años 80. Es el punto de partida de casi todos los estudios de rentabilidad Es muy útil para comparar proyectos alternativos equiparables. Sin embargo, no debemos olvidar que el objetivo de un proyecto es maximizar la rentabilidad de una inversión, no minimizar los costos. El TCO no toma en cuenta el costo del capital. Esto es un riesgo financiero importante para proyectos de alto costo y tiempo. 7.2.2 Retorno de inversión El Retorno de inversión (ROI) es una técnica muy popular para estimar las consecuencias financieras al hacer una inversión o implementar un proyecto. En su forma más simple, el ROI es el resultado de dividir los beneficios netos entre el costo de la inversión, expresado en porcentaje. \\[\\text{ROI} = \\frac{(\\text{Beneficios}-\\text{Costos}}{\\text{Costos}}\\times 100 %\\] Es una métrica muy popular que permite comparar la tasa de retorno esperada de un proyecto, contra otro tipo de inversión de capital, como puede ser un portafolio de inversión. Esta métrica debe considerar un horizonte de tiempo. Para proyectos de TI, este horizonte suele ser de 3 a 5 años. Con frecuencia se utiliza para comparar la tasa de retorno del proyecto contra otro tipo de inversión de capital; por ejemplo, decidir adquirir un nuevo servidor, o invertir el dinero en un instrumento financiero. Para calcular el ROI se deben tratar de identificar todos los beneficios y costos del proyecto. Para el cálculo de costos, se deben incorporar las reflexiones presentadas en el análisis del TCO. La estimación de los beneficios se complica porque existen distintos tipos de beneficios, como tangibles, estratégicos y algunos, como los financieros, pueden cambiar en función de las políticas económicas de un país. Un buen punto de partida (y un gran reto en muchas empresas), es tratar de identificar los llamados KPI,Key Performance Indicators. Estos son algunos ejemplos de beneficios a considerar cuando se calcula el ROI: Beneficios cuantificables (hard) : Reducción en el ancho de banda en los accesos a Internet; consolidación de servidores físicos; reducción en los tiempos de procesamiento y en los tiempos de lanzamiento al mercado de una nueva aplicación; Beneficios cualitativos (soft) : Mejora la productividad y eficiencia de los empleados; mejora el ambiente laboral; aumenta la fidelización de los clientes; mejora la reputación de la marca Beneficios en ingresos : Aumento de la producción; mayor participación de mercado; Incremento en el ingreso medio por cliente (ARPU, Average Revenue Per User) Los beneficios cualitativos se les llama soft porque no pueden convertirse directamente en un valor económico. Por ejemplo, el aumento en la productividad de un empleado no necesariamente implica una aumento en la producción ni una reducción en el número de empleados. En general, se debe recurrir a profesionales de otras áreas (por ejemplo, al director de RH, de marketing, de operaciones) para que ayuden a convertir estos beneficios en términos cuantitativos. Al estimar el horizonte de tiempo para el cálculo del ROI también deben tomarse en consideración los cambios (realistas) esperados durante ese tiempo, como pueden ser el incremento en ingresos (por ejemplo, por una mayor captación de clientes) y en gastos (por ejemplo, por un aumento en los recursos asignados a los centros de atención a clientes). Por ello, aunque se recomiendan horizontes de tiempo de tres a cinco años para proyectos de TI, en ocasiones el ROI se calcula para dos o tres años. Una excepción notable es el cálculo de ROI para redes de comunicaciones. Las inversiones iniciales suelen ser tan grandes, que los proyectos no son rentables antes de 7 o 10 años; en estos casos, los cálculos consideran horizontes de tiempo de 10, 15 o 20 años. Ejemplo 7.2 Una empresa está considerando implementar un CRM con el que espera tener una interacción mucho más fluida con sus clientes. A través de esta interacción estima que tendrá una gran fidelización (una tasa de abandono, CHURN, menor) y la oportunidad de lanzar más y mejorses servicios al mercado en menos tiempo. Al analizar el proyecto con las distintas unidades de negocio, se encontraron los siguientes beneficios. Observe que casi todos están expresados como una reducción en costos y que se está haciendo una estimación de mejoras a lo largo del tiempo gracias a la implementación del CRM. Beneficios (Millones USD) Año 1 Año 2 Año 3 Reduce costos de transacción $ 2.50 $ 3.00 $ 3.20 Reduce costos de operación $ 0.80 $ 1.00 $ 1.10 Reduce costos de TI  $ 1.50 $ 1.50 Reduce CHURN $ 3.50 $ 4.00 $ 5.00 Reduce time to market  $ 2.50 $ 2.50 TOTAL: $ 6.80 $ 12.00 $ 13.30 La empresa espera un beneficio total \\(\\$ 6.80 + \\$ 12.00 + \\$ 13.30 = \\textbf{\\$ 32.10}\\) en los tres años calculados. En la siguiente tabla se presenta la estimación de los principales gastos incurridos al implementar el CRM. Observe que el gasto más importante se da en el primer año, que es el más intensivo en el desarrollo del producto. En los años subsecuentes, los desarrollos están limitados a actualizaciones y aumento de funcionalidades. Costos (Millones USD) Año 1 Año 2 Año 3 Licencias $ 1.00 $ 1.00 $ 1.00 Desarrollo y TQM $ 2.50 $ 0.20 $ 0.20 Mantenimiento $ 0.70 $ 0.20 $ 0.20 TOTAL: $ 4.20 $ 1.40 $ 1.40 Los costos totales para el proyecto durante los tres años, se estiman en \\(\\$ 4.20 + \\$ 1.40 + \\$ 1.40 = \\textbf{\\$ 7.00}\\). Con una inversión de $ 7 MUSD se espera un beneficio de $ 32.10. Los retornos de inversión para el primer año, para el tiempo de vida del proyecto, y el anual estimado, son los siguientes: \\[\\begin{aligned} \\text{ROI primer año} &amp;= \\frac{6.8 - 4.2}{4.2}\\times 100\\% = 62\\%\\\\ \\text{ROI tres años} &amp;= \\frac{32.1 - 7}{7}\\times 100\\% = 358\\%\\\\ \\text{ROI anualizado} &amp;= (1+3.58)^{1/3} - 1 = 66\\%\\\\ \\end{aligned}\\] El Periodo de recuperación (PBP) es el tiempo en que se recupera la inversión. Con mucha frecuencia se suele considerar únicamente la inversión inicial (el CAPEX), pero debe tomarse en cuenta que se hacen inversiones a lo largo del tiempo de vida del proyecto, por lo que el cálculo del PBP debe considerarse en ese horizonte de tiempo. Para el ejemplo anterior, el periodo de recuperación es: \\[PBP = \\frac{\\text{costo total}}{\\text{beneficio en el tiempo}} = \\frac{7}{\\frac{32.1}{36}} \\approx 7.8\\,\\text{meses}\\] Como se ha comentado, en el despliegue de redes de comunicaciones, las inversiones iniciales pueden ser muy considerables, por lo que no es de extrañar que el PBP sea muy grande, mayor a siete años. Regresando al ROI, una de sus complicaciones es determinar si la erogación que se hace es un gasto o una inversión, y, de hecho, en ocasiones ésto se depende de las políticas fiscales del país. En el ejemplo anterior, los costos que se tomaron en cuenta son costos de operación y se consideran un gasto. En el siguiente ejemplo, el costo que se tomará en cuenta es el adquisición de un equipo, que en estricto sentido, debe depreciarse anualmente. Sin embargo, para enfatizar la complejidad en el cálculo del ROI, se considera que este equipo es un activo (como la compra de un edificio, o una inversión bancaria), por lo que su \"valor\" puede ser recuperado con la reventa del equipo. Ejemplo 7.3 Una empresa está considerando adquirir un dispositivo SD-WAN (Software defined WAN) que le permitirá optimizar sus enlaces WAN al consolidar el tráfico de voz y datos y redistribuir el tráfico entre distintos enlaces para optimizar el balanceo de cargas. Este ejemplo tiene enfatiza dos características frecuentes en el cálculo del ROI: (1) Los beneficios se derivan al comparar el modo actual de operación (PMO, Present Mode of Operation), y (2) casos en que los \"gastos\" pueden ser considerados inversiones en activos. Los costos de la red WAN en el modo actual de operación se presentan en la siguiente tabla: Costos (Miles USD) Año 1 Año 2 Año 3 Enlaces WAN $ 1,000 $ 1,100 $ 1,250 Recursos humanos $ 200 $ 200 $ 250 TOTAL: $ 1,200 $ 1,300 $ 1,500 Total acumulado: $ 1,200 $ 2,500 $ 4,000 Los costos de la red WAN con el equipo SD-WAN son los siguientes: Costos (Miles USD) Año 1 Año 2 Año 3 Enlaces WAN $ 750 $ 775 $ 825 Recursos humanos $ 200 $ 200 $ 250 Equipo SD-WAN $ 500 TOTAL: $ 1,450 $ 975 $ 1,075 Total acumulado: $ 1,450 $ 2,425 $ 3,500 Estamos ahorrando \\(\\$ 4,000-\\$ 3,500 = \\$ 500\\). Para ello invertimos (y aún tenemos) \\(\\$ 500\\), por lo que el retorno es: \\[\\begin{aligned} \\text{ROI tres años} &amp;= \\frac{(500+500) - 500}{500}\\times 100\\% = 100\\%\\\\ \\text{ROI anualizado} &amp;= (1+1)^{1/3} - 1 = 26\\%\\\\[1ex] \\text{PBP} &amp; = \\frac{500}{\\frac{1000}{36}} = 18\\,\\text{meses} \\end{aligned}\\] Estas son algunas recomendaciones básicas relacionadas con el ROI: Se debe crear lista de métricas (KPI) relacionadas con la estrategia del negocio, como atención a clientes; productividad y competitividad; eficiencia operativa. Se debe evaluar cómo el proyecto impacta estas métricas, y eso requiere de expertos (no sesgados y no afectados por el proyecto) en las demás unidades de negocio. Se debe desarrollar la metodología en términos financieros y con apoyo del área de finanzas. Un análisis de ROI adecuado difícilmente uede salir del área de TI y de telecomunicaciones. Se deben establecer beneficios que puedan ser claramente medibles (SMART). Los beneficios soft deben verse como deseables, o bien, deben ser cuantificables (de forma convincente) por las áreas de negocio correspondientes Se deben privilegiar proyectos en los que los beneficios se reflejen lo más pronto posible (con PBP corto); de lo contrario, se debe tomar en cuenta los gastos financieros del dinero apalancado (los gastos de tesorería). A pesar de su gran popularidad, el ROI tiene algunas limitaciones que deben tomarse en cuenta; entre las más importantes están: No se toma en cuenta el costo del capital, lo cual puede ser muy delicado en proyectos con un PBP muy grande. Frecuentemente se calcula ROI ajustando a valor presente neto. A esto se le conoce como RA-ROI (Risk adjusted ROI). Al reportarse en porcentaje, no considera que los beneficios netos podrían ser muy bajos para justificar la inversión. Por ejemplo, una inversión de $100,000 que genera un beneficio de 5,000 tiene un ROI de 5%, mientras que una inversión con un ROI de 20% puede ser una inversión $ 10 que genera un beneficio de $ 2. De forma similar, el ROI oculta los flujos de capital requeridos. Específicamente, para grandes proyectos, los costos de inversión iniciales pueden ser tan altos, que hagan al proyecto inviable aún si el ROI parece atractivo. 7.2.3 Valor Presente Neto El valor presente neto, NPV, es una medida del beneficio que genera una inversión durante su vida útil considerando el valor del dinero. Se define como el valor presente de los ingresos futuros menos el valor presente del flujo de costos futuros. En términos simples, podemos entender \"valor presente\" considerando que un peso hoy tiene y se percibe como más valioso que un peso en el futuro. Entre muchos otros factores, además de la pérdida de valor por inflación, se deben tomar en cuenta factores como el costo de oportunidad, es decir, la incapacidad de tomar otras decisiones de inversión si ese peso no se tiene disponible. Para calcular el valor presente, se utiliza una tasa de descuento \\(r\\) que busca ser un indicador del riesgo financiero que la empresa atribuye a los factores anteriores. La fórmula de NPV es la siguiente: \\[NPV=\\sum\\limits_{t=0}^T\\frac{C_t}{(1+r)^t},\\] donde \\(t\\) es el periodo en años, \\(r\\) es la tasa de descuento y \\(C_t\\) es el ingreso neto (es decir, ingresos menos egresos) en el año \\(t\\). Ejemplo 7.4 En la siguiente tabla se muestran dos opciones para invertir $ 1,000,000. La primera es para un proyecto a cinco años con ingresos netos de $500,000 cada año. La segunda es para un proyecto a tres años con ingresos netos variables. Opción 1 Opción 2 Año Ingreso neto Ajustado Ingreso neto Ajustado 0 ($ 1,000,000) ($ 1,000,000) ($ 1,000,000) ($ 1,000,000) 1 $ 500,000 $ 454,500 $ 1,000,000 $ 909,000 2 $ 500,000 $ 413,000 $ 750,000 $ 619,500 3 $ 500,000 $ 375,500 $ 500,000 $ 375,500 4 $ 500,000 $ 341,500 5 $ 500,000 $ 310,500 Total: $ 1,500,000 $ 895,000 $ 1,250,000 $ 904,000 En las columnas 2 y 4 se presentan los resultados netos de las dos opciones. Aparentemente la primer opción es más atractiva pues reporta un beneficio neto $250,000 mayor al de la segunda. Sin embargo, al hacer el ajuste a valor presente con una tasa de descuento de 10%, la segunda opción es la más rentable. Para poder determinar los ingresos netos anuales, se deben estimar los flujos de capital. Para proyectos con fuertes inversiones iniciales como el despliegue de una red de comunicaciones, la curva de flujos de capital sería similar a la de la figura @ref(fig:cashflow9: Figura 7.4: Ejemplo de una curva de flujo de capital En términos generales, los proyectos con \\(NPV &lt; 0\\) deben rechazarse y aquellos con \\(NPV \\ge 0\\) deben analizarse más detenidamente. Por otra parte, como debió quedar claro en el ejemplo, los resultados de NPV dependen de la tasa de descuento utilizada. Es muy importante elegir un valor con objetividad y justificarlo. No es raro encontrar tomadores de decisiones que estarán inclinados a definir una tasa de descuento \"conveniente\". Finalmente, todos los proyectos de largo plazo deben incluir un factor de riesgo adicional para tomar en consideración la manifestación de eventos ajenos al proyecto que pueden tener un gran impacto en el mismo. Por ejemplo, la aparición de nuevos jugadores disruptores, factores macro-económicos, cambios en las prioridades del Estado y otros factores externos, pueden parecer improbables en el corto plazo, pero factibles en un escenario de 15 años. 7.3 Análisis tecno-económico En otras secciones del curso se ha hablado sobre cientos de proyectos de redes WiFi municipales desplegadas los Estados Unidos y en otros países en los últimos años. Cuando estas redes se pensaron para ofrecer, además de servicios municipales, servicios públicos de acceso a Internet, la gran mayoría de estos proyectos fracasó, pero estas experiencias dejaron muchas lecciones que han contribuido a fortalecer las metodologías de diseño de redes. Un ejemplo de estas lecciones es el marco propuesto por Mandviwalla (2008) para el despliegue de redes inalámbricas municipales (WMN, Wireless Municipal Networks). Se trata de un marco compuesto por tres fases; si en alguna de ellas los elementos no están claramente definidos o si cuestiona la viabilidad de la red, el proyecto debería abandonarse. El marco propuesto es el siguiente. Observe la gran semejanza de este marco con la metodología de diseño descendente que hemos seguido a lo largo del curso. Fase 1 Objetivos Los objetivos de la red deben ser claramente identificados. Para redes WSN éstos pueden ser disminuir la brecha digital, ofrecer mejores servicios municipales, reducir los costos de operación de redes actuales, incrementar la atractividad de la región, empoderar a los ciudadanos, etcétera. Actores clave Los objetivos deben estar asociados a cubrir las necesidades de actores clave como ciudadanos, turistas, empleados de gobierno. Se debe considerar también quiénes se verían perjudicados (por ejemplo, competidores comerciales, proyectos a los cuales se les recortaría presupuesto para financiar la red). Políticas y regulaciones Es muy importante tomar en consideración las restricciones de política pública y regulatorias en el diseño de estas redes. En algunos casos, estas redes pueden ser vistas como competencia desleal. Para ello, la Unión Europea ha definido criterios en los que se fomenta el despliegue de redes públicas municipales (las llamadas zonas blancas) o en los que éstas se prohíben (las zonas negras). En esta fase también se analizan las implicaciones legales sobre seguridad (si ésta es comprometida), niveles de servicio, atención a clientes, entre otros. Fase 2 Servicios y aplicaciones Con los resultados de la primera fase, se pueden definir los servicios y aplicaciones que ofrecerá la red. Para ello deben priorizarse los objetivos identificados,en función de los actores clave y de las restricciones detectadas. Selección de tecnología Ya se cuenta con todos los elementos necesarios para proceder a un primer diseño, similar al diseño conceptual en la metodología de diseño descendente. En esta etapa no se trata de la selección de tecnologías específicas (lo que llamamos diseño físico) sino de consideraciones más generales, como bandas de frecuencia para los servicios WiFi y para el backhaul, gateways para conexión a la red dorsal, infraestructura municipal disponible para desplegar la red, entre otros. Finanzas y gestión Esta etapa es crítica. Se debe tener un sólido estudio de factibilidad económica no sólo para desplegar la red (el CAPEX) sino para garantizar su operación (el OPEX) de forma sustentable. Se debe si los servicios ofrecidos son gratuitos (todos ellos, o sólo algunos), si la red puede ser financiada con modelos publicitarios, o si los ahorros por el uso de nuevas tecnologías son suficientes para desplegar la red. En este capítulo conoceremos los conceptos básicos necesarios para realizar este tipo de análisis financiero. Fase 3 Si las etapas anteriores dan viabilidad al proyecto, se puede proceder al diseño detallado (diseño lógico y físico) y al eventual despliegue de la red. 7.3.1 Análisis de rentabilidad Para evaluar la viabilidad financiera del proyecto, se debe hacer un análisis de rentabilidad. La Unión Europea ha financiado varios proyectos marco (Titan, TONIC, EcoSys) de donde se derivan las principales líneas de esta sección. Para contextualizar el análisis, utilizaremos ejemplos del entorno mexicano. Un análisis de rentabilidad tiene los siguientes pasos: Se define el periodo de tiempo en el que el proyecto (la red a desplegar) estará vigente Se realiza el análisis del mercado y la definición de los servicios a ofrecer. Estos dos pasos permiten hacer una estimación de la demanda Se analizan los aspectos relacionados con el despliegue y operación de la red (la estimación de la oferta), tales como: Características tecnológicas de la red Estimación de costos: De adquisición, operación, mantenimiento, licenciamiento, etcétera Se determinan los parámetros financieros del entorno en el que se desplegará la red, tales como tasas de interés, tasa de descuento, políticas fiscales para depreciación y valoración de activos, impuestos a pagar, estímulos fiscales, etcétera  Se hace el análisis de los resultados financieros, como los análisis de sensibilidad y de riesgo financiero Consideraciones de Riesgos Como se ha mencionado en múltiples ocasiones, los proyectos de despliegue de redes de comunicaciones requieren de grandes inversiones y se espera que duren muchos años. En ambos casos, se entra en zonas de incertidumbre no despreciable para elementos clave del proyecto. En ejemplo, es la capacidad de estimar la demanda de servicios y de anchos de banda requeridos en el corto, mediano y largo plazo. A principios del siglo XXI, arrastrados por la burbuja de las startups \"dot com\", muchos de los grandes operadores de telecomunicaciones tuvieron pérdidas millonarias al ser excesivamente optimistas en la demanda esperada de servicios y desplegar redes sobre-dimensionadas, con capacidades que sencillamente excedían por mucho las necesidades de sus clientes. En cambio, con la aparición de las tabletas y los teléfonos inteligentes, muchas redes celulares se vieron en la necesidad de hacer inversiones no planeadas, para poder crecer la capacidad de sus redes. En proyectos de largo plazo tampoco es posible estimar con precisión las dinámicas de competencia entre operadores, la aparición de nuevos jugadores y modelos de negocio, como tampoco se puede estimar cómo evolucionará la tecnología y los costos asociados a ella. Para protegerse en cierta medida de estas fuentes de incertidumbre, es común agregar al análisis de valor presente neto, un factor de riesgo o risk penalty que va de cero (para organizaciones aversas al riesgo) a uno (para organizaciones que son tomadoras de riesgo. En el análisis de riesgos se suele considerar distintos escenarios, que se interpretan como posibles rutas de evolución de aspectos relevantes del proyecto. Éstos se presentan frecuentemente como tres rutas: El escenario tendencial, el cual considera que las condiciones actuales no cambiarán sustancialmente; el pesimista, en el que varios de los riesgos se materializan (por ejemplo, que en las comunidades rurales se acentúen los fenómenos de migración); y el optimista, en el que los factores clave del proyecto (como la penetración de mercado) evolucionan favorablemente. El diseño de escenarios deberá incluir al menos los cuatro elementos que se muestran a continuación: Regulatorio Entorno que favorezca las condiciones de competencia, de fomento a la competencia y de protección a inversionistas: Número de competidores en los mercados de redes y servicios; participación de mercado de cada uno (índice HHI). Ambiente Densidad de clientes potenciales en el área de cobertura; nivel socio-económico; porcentaje de ingresos dedicado a telecomunicaciones; espacios disponibles para despliegue de infraestructura; costos de arrendamiento, trámite de permisos, obra civil Servicios Tipo de servicios demandados y potencialemnte demandados; tasas de penetración; niveles de alfabetización digital; tarifas de suscripción; modelos de negocio Tecnologías Tecnologías disponibles; rutas esperadas de evolución tecnológica; costo de equipos de telecomunicaciones; de soporte y de usuario final; costos OA&amp;M De mercado Un elemento esencial en los estudios de rentabilidad. Por supuesto, se debe identificar con la mayor precisión posible a qué población va dirigido el producto o servicio que se está deseando introducir al mercado. En redes de comunicaciones, podemos identificar varios segmentos de mercado con necesidades y patrones de consumo diferenciados. Tres segmentos típicos son: El mercado residencial. Más orientado a consumo de contenidos, y por tanto, justifica la provisión de redes de acceso con velocidades asimétricas. Los periodos de máximo consumo en el sector residencial son de 19:00 a 22:00 horas. El mercado corporativo. Es un mercado en el que las aplicaciones de misión crítica pueden depender de la disponibilidad de la red, por lo la red debe garantizar niveles de servicio (SLA) rigurosos. En este mercado también suele requerirse de un alto nivel de privacidad y seguridad, así como de tecnologías avanzadas, como VPNs y enlaces MPLS. Pequeña y mediana empresa. Es un mercado que también demandará niveles de servicio y funcionalidades de red avanzadas, pero no tan rigurosas como las de los mercados corporativos. En cambio, es un mercado mucho mayor que el corporativo. Habiendo identificado los segmentos de mercado, deberá definirse su volumen. Para una zona de cobertura determinada, cuántos hogares habrá, cuántas unidades productivas pequeñas y medianas? es una zona donde existe alta densidad de corporativos? No basta con responder a estas preguntas con los datos presentes; en la medida de lo posible, se debe analizar el crecimiento (o decrecimiento) esperado, pues lo que se busca es estimar el número potencial de suscriptores a lo largo del tiempo de vida del proyecto. Estas cifras son las que definen las características demográficas de la región y distintos países las clasifican de distintas maneras. Por ejemplo, en Australia, un área urbana es aquella que tiene más de 200 habitantes por kilómetro cuadrado, mientras que en Canadá, el término se aplica para localidades con más de 400 habitantes por kilómetro cuadrado. Se trata de dos países con territorios muy grandes y con una densidad de población relativamente baja. Ejemplo 7.5 En México, la clasificación oficial y el porcentaje de población en cada categoría de acuerdo al censo 2008 del Instituto Nacional de Geografía y Estadística es la siguiente: \\(\\text{Habitantes}/\\text{km}^2\\) Porcentaje Alta densidad 12,000 26.4% Densa 6,000 21% Urbana 1,000 7% Suburbana 250 1.9% Semi rural 125 13.7% Rural 30 8.2% Aislada 12 17.7% La Ciudad de México, con \\(5,800\\,\\text{hab}/\\text{km}^2\\), es considerada en su conjunto como zona densa, pero si se eliminan las Alcaldías de Xochimilco y Milpa Alta, se trata de una zona de alta densidad. Además de los datos demográficos, el estudio de mercado debe contemplar el nivel socio-económico de los segmentos de mercado pues esto ayuda a determinar la capacidad de compra de los suscriptores, el tipo de servicios que potencialmente estarían demandando, las características de los equipos terminales que debieran ofrecerse, etcétera. Ejemplo 7.6 Potencial de mercado en México De acuerdo a la encuesta ENDUTIH 2017, en México había 71.3 millones de usuarios de Internet pero muchos de ellos no son usuarios regulares. Más importante aún, se tenían al menos 40.4 millones de ciudadanos sin acceso a Internet. En Estados como Baja California, Sonora y la Ciudad de México, el porcentaje de usuarios de internet rebasa el 77%, pero en Guerrero, Oaxaca y Chiapas, el porcentaje es menor a 50%. A nivel nacional, sólo el 39% de la pobalción rural tiene acceso a Internet. Por nivel socio-económico, 78% del quartil más alto accede a Internet; el porcentaje baja a 34% en el quartil más bajo de la población El porcentaje de hogares con acceso a Internet en zonas urbanas era ligeramente inferior al 50%, pero zonas rurales no llegaba al 10%, lo que nos coloca muy por debajo de países como Uruguay, Costa Rica y Chile en América Latina. De acuerdo a México Evalúa, sólo el 26% de las escuelas tenía acceso a Internet en ese año. Es una priodidad de la Administración actual abatir estas brechas de acceso (y uso, y apropiación) a Internet. Sin embargo, la demanda depende de la capacidad para poder pagar los servicios de telecomunicaciones. En 2006, el gasto promedio por hogar en servicios de TIC en los países de la OCDE, era de 2.3% de sus ingresos, mientras que en México oscilaba entre el 3% y el 6%. Martin Hilbert, un investigador muy reconocido en temas de brecha digital, considera que el umbral en el que las TIC transitan de ser un bien necesario a un bien de lujo, es de 10 USD por persona por mes. Con estas cifras, más de 15 millones de mexicanos jamás podrán acceder a Internet. Otro elemento a considerar en el análisis de mercado, son las tasas de adopción tecnológica, pues ellas ayudan a tener un referente de los flujos de ingresos esperados, y de los puntos donde el mercado puede empezar a presentar condiciones de saturación. En la figura 7.5, la imagen de la izquierda muestra la típica curva \"S\" de absorción tecnológica y, a manera de ejemplo, la curva de la derecha muestra la penetración de Internet en los hogares mexicanos según INEGI. Figura 7.5: Curva de absorción tecnológica Se puede concluir que en México todavía hay un alto potencial de crecimiento... si las condiciones económicas lo permiten. La forma S de absorción tecnológica se basa en una teoría muy aceptada propuesta por Everett Rogers en 1962 (y actualizada en 2003). Si se acepta esta forma de difusión para analizar la penetración de la red a desplegar, también se debe aceptar el riesgo de que una nueva tecnología surja y desplace a la anterior antes de que alcance una masa crítica. Es una tímida referencia a la teoría de las destrucciones creativas de Joseph Schumpeter. Tratándose de un despliegue de red, al hacer el análisis demográfico también es conveniente incluir información relacionada con las características geográficas de la zona a atender. Ya se ha comentado en varias ocasiones que una región con una orografía muy accidentada, con zonas boscosas presentará retos de despliegue distintos a los que se presentan en un valle. Las zonas urbanas densas son particularmente complejas por la dificultad para desplegar infraestructura subterránea (para medios cableados) y por la pésima propagación de señales electromagnéticas en calles angostas con edificios altos (para medios inalámbricos). Por otro lado, el análisis de mercado debe incluir un análisis de la competencia. Como mínimo, debe identificarse el número, su participación de mercado, cuáles son sus estrategias y fuentes de ventaja competitiva, si existen o pueden imponer barreras de entrada y si el contexto regulatorio permite establecer alianzas de competencia y cooperación entre ellos. Al analizar el mercado de competencia en telecomunicaciones, se debe tomar en consideración que este sector presenta características similares a las de un Monopolio Natural. A excepción de algunos mercados en tecnologías de acceso altamente competidas, es muy frecuente encontrar un número muy pequeño (entre tres y cinco) de operadores establecidos. Por último, dado que en México como en muchos otros países el acceso a Internet se ha admitido como un Derecho Humano (de tercera generación), también debe contemplar, junto con el análisis de escenarios, modelos de incentivos, financiamiento alterno, u otro tipo de apoyos que contribuyan a reducir las barreras de entrada para el despliegue de infraestructura. Algunas estrategias que han probado su éxito en distintas latitudes son: Facilidades de acceso a infraestructura La participación del Gobierno para fomentar el despliegue de infraestructura de red y promover su adopción puede darse en diversos ámbitos. Los acuerdos de compartición (que en México son obligatorios) pueden ayudar a reducir drásticamente los costos de despliegue, sobre todo en áreas rurales. En algunos países de Escandinavia se ha fomentado hasta la compartición de distintos elementos de la red. En México también se contempla que todos los edificios públicos que puedan hacerlo, se pondrán a disposición para montar sobre ellos infraestructura de telecomunicaciones. Por desgracia, esta iniciativa sólo es aplicable en el ámbito federal, mientras que los mayores retos para el despliegue de infraestructura se dan a nivel municipal. También está en manos del Estado el garantizar la disponibilidad de espectro para servicios de telecomunicaciones, así como el de facilitar los derechos de vía para el despliegue de infraestructura cableada. Mercado competitivo Uno de los factores más importantes al analizar la competitividad de un país, es la fortaleza y estabilidad de sus instituciones. En este caso, los marcos regulatorios deben contribuir a garantizar que los operadores de redes pueden prestar sus servicios en condiciones de un mercado estable y equilibrado. Esa es la función principal del Instituto Federal de Telecomunicaciones. Así mismo, las instituciones legislativas y judiciales deben contribuir a asegurar la estabilidad de las grandes inversiones que se hagan en el país. Mitigación de riesgos financieros Como se ha comentado, el despliegue de redes de telecomunicaciones de gran escala, conlleva fuertes inversiones en largos periodos de tiempo. Existen varias formas de mitigar los riesgos inherentes a este tipo de inversiones, como lo son las Asociaciones Público-Privadas (APP), que es la figura con la que se ha desplegado la Red Compartida en nuestro país, el acceder a financiamiento a través de las Bancas de Desarrollo nacionales o internacionales -sobre todo para proyectos de impacto social-, y el flexibilizar los modelos de concesionamiento y el pago de contraprestaciones. Definición de servicios Una vez identificados los segmentos de mercado relevantes para el proyecto, se deben definir los servicios y las características para su aprovisionamiento en función del perfil de suscriptores en cada segmento. Esta es una tarea sumamente compleja pues en los últimos años los patrones de consumo de tráfico han cambiado radicalmente en todo el mundo tanto a nivel empresarial como en el segmento residencial. En 2007 se estimaban velocidades de acceso de 1 Mb/s para servicios residenciales y 2 Mb/s para el segmento PyME, con tasas de crecimiento de 20% anual. En ambos sectores, pero sobre todo en el segmento residencial, estas cifras han cambiado sustancialmente. Este cambio se explica por el surgimiento de nuevos dispositivos, una creciente transición a la provisión de servicios en la nube, nuevos modelos de negocio y nuevas formas de interacción en los llamados ecosistemas digitales. Por ejemplo, la figura 7.6 muestra cómo ha evolucionado el tipo de dispositivos en el hogar que requieren de servicios de acceso a Internet. La gráfica está tomada de un estudio reciente hecho por Ofcom, el regulador de telecomunicaciones del Reino Unido. Figura 7.6: Penetración de dispositivos en el hogar que requieren de acceso a Internet. Fuente: Ofcom En México, como en la mayoría de los países latinoamericanos más avanzados, suele observarse una penetración tecnológica similar con cinco años de desfase y con picos de absorción un poco más atenuados. Ejemplo 7.7 La consultora Pyramid Research estimó en 2009 el potencial de servicios demandados para México hasta 2014 como se muestra en la figura 7.7. La realidad fue muy distinta a lo proyectado por los especialistas. Figura 7.7: Estimación de la evolución del mercado en México* La demanda de ancho de banda ha crecido sustancialmente debido a la creciente importancia en el consumo de contenido de video. De acuerdo a estimaciones de Cisco, en 2017 el 70% del tráfico en Internet era video. La consultora WIK Consult toma algunos de estos datos y proyecta la estimación de ancho de banda de varios servicios para 2025. Los resultados se presentan en la siguiente tabla. Llama la atención el crecimiento de video (consistente con las estimaciones de Cisco) así como de consumo de juegos y e-servicios. Por supuesto, el despliegue de estos servicios depende en gran medida de que las tecnologías para soportar este consumo estén listas y de que los suscriptores estén dispuestos a pagar por las capacidades ofertadas. El mismo estudio de WIK Consult presenta varios escenarios de absorción en los hogares del Reino Unido. En la siguiente tabla se muestran dos de ellos: A la izquierda, un escenario optimista con un pronóstico de alto consumo de ancho de banda, y a la derecha, uno un poco más conservador donde no se despliega masivamente el uso de contenidos 8K ni realidad virtual (excepto para videojuegos). Aún en el escenario conservador, se prevé que más del 50% de los hogares demandarán velocidades descendentes de al menos 300 Mb/s y 8% estarán preparados a contratar servicios de 1 Gb/s. Tabla 7.1: Estimación del porcentaje de demanda de ancho de banda en hogares en el Reino Unido en 2025 Demanda Optimista Conservador Muy alta (\\(&gt;1Gb/s \\downarrow\\); \\(600Mb/s \\uparrow\\)) 40% 20% Alta (\\(300 Mb/s -1Gb/s \\downarrow\\); \\(300Mb/s - 600 Mb/s\\uparrow\\)) 42% 56% Baja (\\(&lt; 300 Mb/s \\downarrow\\); \\(&lt; 300 Mb/s \\uparrow\\)) 10% 15% Sin banda ancha 7% 7% Para el segmento empresarial, sobre todo para el corporativo, la calidad de servicio debe ser una prioridad en el diseño de la red. En los acuerdos de nivel de servicio deben especificarse las características técnicas que el servicio debe cumplir. Para este segmento el factor de sobre-suscripción es nulo o muy bajo. El servicio a PyMEs puede ser más tolerante con el fin de reducir los costos de servicio. En el segmento residencial, sobre todo cuando la provisión de servicios se hace a través de cable, la sobre-suscripción suele alcanzar valores de 10 a 30. Finalmente, se debe tener una estimación de las tarifas a las que se pueden ofertar los servicios, pues esto determina los flujos de ingresos de la red. Es un ejercicio particularmente complejo pues los costos de servicios de telecomunicaciones han venido a la baja en los últimos años. Al mismo tiempo, los usuarios van demandando más capacidad y mayor calidad de las redes. Aunque este aumento en la demanda tienda a empujar el ARPU Average Revenue per User a la alza, la realidad es que en la mayoría de los países desarrollados, la presión competitiva ha sido dominante y las empresas de telecomunicaciones han visto una caída neta en su ARPU. Esto ha hecho que las empresas diversifiquen su oferta de servicios o que modifiquen sus modelos de negocio para mantener su rentabilidad. Un ejemplo de estas modificaciones es que son cada vez menos las empresas que absorben el costo del equipo terminal para ofrecerlo en arrendamiento a sus abonados. 7.3.2 Despliegue y operación de la red A grandes rasgos, se puede decir que el análisis del mercado y de los servicios permite tener una estimación de los ingresos directos que tendrá la red. Para el análisis de factibilidad financiera, será necesario analizar los costos de adquisición, operación e implementación de la red. Por supuesto, estos costos dependen de las tecnologías, de la escala, las condiciones de cobertura, y de casi todo lo que se ha mencionado en este capítulo. A manera de ejemplo deberán tomarse en consideración, entre muchos otros factores: Las bandas de frecuencia asignada . El primer punto debe ser el análisis del costo por hertz, el tamaño del bloque asignado y la negociación para pagar los derechos de uso de ese bloque. Pero este es sólo uno de muchos otros factores. Por ejemplo, es muy probable que el bloque se encuentre rigurosamente acotado tanto en frecuencia como en área de cobertura. En este caso, se debe incluir equipo adicional para gestión de interferencia, control de potencia y monitoreo de ancho de banda. Componentes . Se deben incluir todos los componentes que conforman la red: Estaciones base, elementos para las redes de acceso, backhaul y red dorsal, equipo en las premisas del cliente CPE, Customer Premises Equipment y sus posibles costos de instalación, etcétera. Este análisis debe hacerse con todo detalle, aunque para fines didácticos en esta sección únicamente se consideran los componentes principales. Elementos de servicio. Aquí se incluyen todos los gastos indirectos relacionados con la provisión de servicios de la red, casi todos vinculados con los costos de operación. Elementos como marketing, ventas, OA&amp;M, arrendamiento de sitios, licenciamiento de software, equipos y espectro(de ser el caso), costos de interconexión, entre otros. Dado que los despliegues de red responden a estimaciones de penetración y al calendario establecido en el plan maestro, las tasas reales de penetración deben ser estimadas para poder planificar los gastos de implementación y la evolución de los gastos de servicio En esta sección se utilizará como hilo conductor el despliegue de una red WiMAX IEEE 802.16 para ofrecer servicios de acceso a Internet. Está fuertemente inspirado en los trabajos de Smura et al. (2008)21. Antes de entrar en el ejemplo, conviene recordar que una red se diseña con base en la cobertura deseada, en la capacidad requerida o en una combinación de ambas. El bloque de frecuencias asignadas a un operador móvil suele dividirse en sectores. La capacidad (en b/s) de un sector depende de: El ancho de banda disponible, es decir, del tamaño del bloque del sector Las bandas de frecuencia, pues unas frecuencias son más susceptibles a interferencias que otras La eficiencia de la modulación espectral, es decir, de la cantidad de bits que pueden inyectarse en cada baudio Las condiciones ambientales, tanto por las interferencias generadas por objetos como bosques y edificios, como -en nuestro caso- por el hecho de que el equipo terminal (o su antena) se encuentren en el interior o en el exterior de edificios y si se tiene o no línea de vista con la radio base. Los protocolos de red. Como sabemos, las dinámicas de los protocolos de comunicaciones en las capas superiores, pueden afectar drásticamente la capacidad real de la red. Sin entrar en detalles técnicos, si en 2011 se estimaba que una celda debía ofrecer 1 Mb/s por \\(\\text{km}^2\\) y, como se ha mencionado en la sección anterior, la tendencia esperada es de 100 a 1000 \\(\\text{Mbps}/\\text{km}^2\\), el radio medio de una celda 3G/HSDPA debería ser de unos 500 metros; los despliegues de redes celulares están transitando de macro a micro-celdas. En las redes IEEE 802.16 cada equipo receptor (cada CPE) puede elegir su propio esquema de modulación. A mayor distancia, tiende a usarse un modulador más robusto, como se muestra en la figura 7.8. Figura 7.8: Modulación vs distancia para distintos escenarios La figura 7.8 se estima para un sector de 7 MHz en la banda de frecuencia de 3.5 GHz. También muestra cómo la capacidad del sector disminuye con las condiciones del entorno: Los despliegues en el exterior tienen mayor que capacidad que aquéllos con el CPE en el interior y los despliegues urbanos, en esa banda de frecuencia, tienen una degradación mucho mayor que los despliegues suburbanos. En un entorno urbano con CPEs en el interior de los hogares, si la radio base está a 750 metros se distancia, se podrá ofrecer una velocidad de 10 Mbps con un Códec BPSK; sólo podrá ofrecer la velocidad máxima de 25 Mbps en aproximadamente el 40% del área de cobertura. La siguiente tabla las coberturas máximas en kilómetros para WiMAX con bloques de 7 MHz en dos bandas de frecuencia distintas para ambientes donde el CPE se encuentra en el exterior, en el interior y en el exterior, puede tener línea de vista (LOS) hacia la radio base, o no tenerla (NLOS). Zona Urbano Suburbano Rural Banda 2.5 GHz 3.5 GHz 2.5 GHz 3.5 GHz 2.5 GHz 3.5 GHz NLOS CPE interior 0.83 0.7 1.02 0.85   NLOS CPE exterior 2.40 2.00 3.25 2.70   LOS CPE exterior     12.0 10.0 En el estudio, el único escenario en el que se consideran enlaces con línea de vista, es un despliegue rural en el que se ponen pequeñas antenas rectangulares, como la de la figura 7.9, en las azoteas o en los balcones de los hogares. Una arquitectura similar se utilizó en México para ofrecer servicios de telefonía y datos en zonas rurales en la banda de 450 MHz a través del Fondo de Cobertura Social. Figura 7.9: Antena residencial para enlaces con (casi) línea de vista En la figura 7.10 se muestra una arquitectura muy general de una red WiMAX. Figura 7.10: Principales componentes de una arquitectura de red WiMax De estos componentes, sólo se tomarán en consideración los relacionados con la red inalámbrica para el análisis de costos, y casi exclusivamente tomaremos costos de adquisición y, para estimación de Impex, se mencionan los porcentajes de reducción de costos en algunos equipos. En la tabla siguiente los costos promedio de los componentes para una red WiMAX a 3.5 GHz con seis sectores por radio base. Los precios presentados son los costos promedio de esos equipos en Europa en 2006. El despliegue se hizo en un país nórdico y el CPE era adquirido por el operador y arrendado al cliente. Aunque el CPE en exterior es mucho más caro que el CPE en interiores ($100 USD del equipo más $100 USD de la instalación), se necesitarían menos radio bases para despliegues iniciales, sobre todo en entornos rurales y suburbanos, como se mostrará más adelante. Como referencia muy imprecisa porque se trata de redes con características distintas, en la siguiente tabla se presentan los costos estimados por Del Villar (2009) para un despliegue de una red WiMAX en la banda de 2.5 GHz en México. A pesar de que se trata de redes con muchas diferencias (en particular, las fechas del estudio, las bandas de frecuencia y las tecnologías y topologías del backhaul, que no se incluyen en el estudio) se muestran en azul algunos puntos que conviene resaltar. En primer lugar, los costos de la estación base, de los sectores y los descuentos anuales esperado son muy distintos en el estudio de Smura para un país nórdico, y el de Del Villar para México. Desgraciadamente, la causa principal de estas diferencias se explica porque en la región nórdica se genera la tecnología, mientras que en América Latina ésta se adquiere y se consume. Con relación a los costos de arrendamiento de los sitios, son dos las causas principales de las diferencias. En primer lugar, el estudio de Smura contempla mayoritariamente despliegues suburbanos y rurales, donde el costo de la propiedad es mucho menor. En segundo, y sobre todo, en el país nórdico la co-ubicación y compartición de infraestructura era exigida por ley. En México, hoy se tiene la misma regulación, pero en la época del estudio de Del Villar, cada operador debía conseguir y arrendar sus propios sitios. Finalmente, los costos de operación en México son notablemente más bajos que en el estudio de Smura (aunque solamente se están considerando los costos asociados al backhaul). Esto refleja la gran diferencia en salarios y costos de capital humano entre los países de América Latina y los del norte de Europa. Ha llegado el momento de integrar toda la información recabada a lo largo del estudio, para determinar cuántos componentes de red serán necesarios para su despliegue. En la siguiente tabla se presentan tres de los escenarios analizados por Smura: Despliegues urbanos en la banda 3.5 GHz para zonas con densidades de población de 2,000, 1,000 y 500 habitantes por \\(\\text{km}^2\\). En todos los casos, se busca cubrir una población objetivo de 50,000 hogares. Para el bloque de frecuencias asignado, se estima que un sector puede ofrecer en promedio 15 Mb/s y que una radio base puede tener hasta seis sectores. La tabla muestra un escenario de penetración en el que se cubre el 100% de la población objetivo en cinco años. Aunque en el estudio no se menciona, se puede suponer que la tecnología desplegada se adapta a las necesidades crecientes de la población durante ese periodo de tiempo. Hay varios puntos a resaltar. Se pueden observar las limitaciones de capacidad y ancho de banda. Sabemos que con la banda de 3.5 GHz, la cobertura es baja. Por ello, en la región con la menor densidad de población (tercer escenario) se requiere de más estaciones base y más sectores. Conforme el número de abonados va en aumento, se debe aumentar el número de radio bases (y por consiguiente, el número de sectores). Sin embargo, en el escenario de alta densidad (2000) el número de radio bases crece cinco veces, mientras que en el de baja densidad (500) crece al doble. Esto se explica por el gran número de radio bases que se tuvo que desplegar desde un inicio. Con un número mayor de radio bases, la distancia media entre el CPE y la radio base disminuye. Esto permite tener modulaciones con mayor densidad espectral. 7.3.2.1 Análisis financiero De la sección anterior se obtiene el número de componentes estimados para desplegar la red conforme al plan maestro. También se identificaron los costos de equipos, arrendamiento, licenciamiento y gastos de operación, entre otros. Para llevar a cabo el análisis financiero, en esta etapa se requiere definir el valor de los principales parámetros financieros, como las tasas de interés, la tasa de descuento para el análisis de valor presente, las tasas fiscales y de depreciación, etcétera. El análisis financiero reportará algunas de las métricas que se presentaron al inicio de este capítulo, como el costo total de propiedad, la tasa interna de retorno, y la utilidad a valor presente neto. Las gráficas en la figura 7.11 presentan los flujos de capital a valor presente de los escenarios analizados por Smura bajo los siguientes supuestos: No se consideran costos administrativos ni pago de frecuencias ni gastos de interconexión Los CPE son adquiridos por el operador y arrendado a los usuarios Los ARPU mensuales considerados eran de 30 USD para el usuario residencial y de 200 USD para el comercial. Se consideran dos bandas de frecuencia. Bandas a 2.5 GHz con bloques de 5.5 MHz y bandas a 3.5 GHZ con bloques de 7 MHz. Figura 7.11: Flujos de capital a valor presente para los escenarios evaluados por Smura En áreas urbanas con mayor densidad poblacional, se tienen VPN claramente positivos, aunque con densidades de 500 hogares por \\(\\text{km}^2\\), la rentabilidad se empieza a ver amenazada. Por la misma razón, en los escenarios suburbanos es limitadamente rentable sólo para áreas de 200 hogares por \\(\\text{km}^2\\). En los demás casos, el ingreso esperado por los relativamente pocos abonados, no cubre los gastos de despliegue a valor presente. El análisis de las zonas rurales es de llamar la atención: En todos los casos el proyecto tiene alta rentabilidad a valor presente y periodos de recuperación muy cortos. Lo que ocurre es que a pesar de que hay muy poca población atendida, también se despliegan pocas celdas, pues éstas nunca se saturan. En las áreas urbanas y rurales, los despliegues en la banda de 3.5 GHz con bloques de 7 MHz resultan más rentables que los despliegues de 2.5 GHz con bloques de 5.5 MHz. Aunque esta última frecuencia tiene mayor cobertura, su capacidad más limitada requiere que se desplieguen más celdas. En el caso suburbano, hay una densidad menor y se puede aprovechar mejor la cobertura de la banda a 2.5 GHz. Algunos de los supuestos en el análisis anterior son muy aventurados. No considerar costos administrativos, pago de concesión de frecuencias o costos de interconexión, pone en grave riesgo la viabilidad del proyecto. En este ejercicio se omiten únicamente para simplificar el ejemplo. De manera similar, es aventurado suponer que en las comunidades rurales se puede tener el mismo ARPU que en los entornos urbanos, o que el CPE se pueda adquirir al mayoreo a un determinado precio que se recuperará con su arrendamiento a los abonados. Por estas razones, los análisis financieros deben incluir un análisis de sensibilidad. Este análisis consiste en seleccionar aquellas variables en las que el cambio en los valores supuestos, pueden tener un fuerte impacto en el resultado del análisis. Para el ejemplo que se ha estado analizando, las tres variables clave que fueron consideras son el ARPU, el costo del CPE (y su instalación, si es en exterior) y el costo de los elementos de la radio base (BS, Base Station). En las gráficas de la figura 7.12 se muestran los resultados para tres de los escenarios analizados. En el extremo izquierdo se presenta el urbano a 3.5 GHz con una densidad de 1,000 habitantes por \\(\\text{km}^2\\); al centro el suburbano a 3.5 GHz con 100 hab/\\(\\text{km}^2\\) y a la derecha el rural a 3.5 GHz con 10 hab/\\(\\text{km}^2\\). Figura 7.12: Análisis de sensibilidad para los tres escenarios Las líneas continuas sólidas corresponden las variaciones en el ARPU, las punteadas rojas a variaciones en el costo del CPE y las punteadas verdes a variaciones en el costo de la BS. Para entender estas curvas, tomemos, por ejemplo, el escenario urbano con 1000 habitantes. En la tabla anterior se había estimado un VPN de 0.695 M al cabo de cinco años. Ese es el punto en el que convergen las tres líneas con los supuestos de ARPU, CPE y BS considerados. Si el ARPU disminuye, por ejemplo porque las condiciones de mercado hacen que no se pueda cobrar más que el 90% del estimado original (es decir, una disminución del 10% en el ARPU), entonces el VPN llegaría prácticamente a cero. En cambio, si logra aumentar el ARPU a 20% más de lo estimado, el VPN subiría hasta aproximadamente 1.4 M. El análisis de sensibilidad nos dice que el ARPU es la variable que más influye en el análisis de factibilidad financiera. Esto es particularmente cierto en el escenario rural pues con muy pocos usuarios, cualquier cambio en el costo de los servicios tendrá un fuerte impacto en los ingresos de la empresa. 1Los ejemplos en esta sección son sumamente triviales con el fin de asimilar el concepto sin perdernos en los detalles. Una estimación de TCO formal tomaría en consideración muchos más elementos. Los costos en este ejemplo están en dólares americanos y fueron estimados a valor de mercado en 2007. T. Smura, H. Hämmäinen, T. Rokkas and D. Katsianis, Technoeconomic analysis of fixed WiMAX network deployments, in Mobile WiMAX  Toward Broadband Wireless Metropolitan Area Networks, New York: Auerbach Publications, 2008. "],["respuestas-a-problemas-seleccionados.html", "Capítulo 8 Respuestas a problemas seleccionados 8.1 Metodología de diseño de redes 8.2 Requerimientos técnicos 8.3 Caracterización de la red 8.4 Diseño lógico 8.5 Administración de Redes", " Capítulo 8 Respuestas a problemas seleccionados 8.1 Metodología de diseño de redes Problema 1.2 Requerimientos incompletos Falta de involucramiento del usuario Falta de recursos Problema 1.5 Sí: Para el desarrollo de infraestructura, si hemos hecho un buen trabajo de pruebas e integración en la fase de desarrollo, la estabilización de la solución puede incorporarse a la fase de despliegue. Problema 1.7 Para evitar las principales causas de fracaso identificadas en los reportes CHAOS. Una visión clara y compartida ayuda a que todos los involucrados en el proyecto entiendan con precisión lo que se busca y lo que se obtendrá. Problema 1.12 No: No cumple con los objetivos SMART. No están definidos claramente en términos cuantitativos. Problema 1.15 Gerente de programa.: Es el arquitecto principal del proyecto y lo administra. Mantiene los compromisos adquiridos en el Plan Maestro y Calendario Maestro. Coordina y facilita la comunicación con los demás miembros del equipo. Gestiona y evalúa el plan de riesgos. Gerente de producto.: Interfaz con el cliente, es responsable de definir y mantener la visión conjunta del proyecto a través de la identificación de objetivos realistas y su transformación en requerimientos específicos. Desarrollo.: Diseña la solución y dimensiona tiempos y recursos necesarios. La implementa o supervisa su implementación y prepara la etapa de despliegue. Pruebas.: Comprueba la correcta funcionalidad de la solución a través del diseño y puesta en marcha del programa de evaluación. Experiencia del usuario.: O capacitación, administra los requerimientos del usuario, participa en la decisión al confrontar facilidad de uso contra rendimiento, capacita al usuario. Administrador de liberaciones.: Controla la logística para liberar y desplegar la solución. Administra las operaciones de soporte y entrega. Problema 1.20 Mitigar el riesgo significa tomar las medidas necesarias para anularlo o al menos para minimizar que éste se manifieste. El plan de contingencia consiste en definir las acciones a tomar si el riesgo se manifiesta con el fin de minimizar su impacto. 8.2 Requerimientos técnicos Problema 2.1 Porque los modelos de trabajo, en particular en lo que se refiere al almacenamiento y difusión de información en las empresas, están cambiando. Por ejemplo, la decisión de centralizar los servidores (granjas de servidores) el acceso centralizado a información de la compañía a través de servidores WWW en intranets provocan un enorme flujo de información entre la LAN departamental y la LAN donde se concentran los servidores. Problema 2.4 Contar con un muy buen sistema de administración y monitoreo que permita detectar anticipadamente fallos o condiciones potenciales de fallo en la red. Documentar los incidentes (fallos, causas y pasos para su reparación) y contar con un sistema de mesa de ayuda que permita minimizar el tiempo de reparación y puesta en funcionamiento. Contar con equipos y enlaces redundantes y/o de respaldo para mantener la continuidad de operaciones. Problema 2.8 Se pierde dinero durante el tiempo de reparación, MTTR. Un año = \\(365\\times 24\\times 60 = 525,600\\,min\\) (a) \\[\\texttt{MTTR}= \\frac{525,600\\times (1-0.999)}{ 0.999} = 526.126\\,min \\rightarrow 526.126\\times \\$500.00 = \\$263,063.00\\] (b) \\[\\texttt{MTTR}= 52.56\\,min \\rightarrow 52.56\\times \\$500.00 = \\$26,282.62\\] (c) La empresa puede tener hasta 60 min de caídas al año, por lo que la disponibilidad de su red debe ser: \\[A = \\frac{\\texttt{MTBF}}{\\texttt{MTBF}+\\texttt{MTTR}} =\\frac{525,540}{525,600} = 99.988\\%\\] Problema 2.13 Ignorando todos los demás elementos, el throughput, (\\(\\zeta\\)), estará determinado por la tasa a la que se pueden emitir ventanas. Esta tasa puede estar limitada por el retardo de propagación o por la capacidad del enlace. El retardo de propagación es: \\[\\frac{4\\times 36,000}{300,000}=0.48\\,s\\] En el primer caso, el retardo de transmisión es: \\[\\frac{512\\times 8}{64000}=64\\,ms\\] En este caso, la latencia es el elemento determinante. El throughput es: \\[\\zeta=\\frac{512\\times 8}{0.48}=8533\\,\\text{b/s}\\] En el segundo caso, el retardo de transmisión es: \\[\\frac{15\\times 512\\times 8}{64,000}=0.960\\,s\\] Ahora, y en el tercer caso, la transmisión está limitada por la capacidad del enlace, por lo que \\(\\zeta=64\\,\\text{kb/s}\\). Problema 2.15 (a) Cada paquete \"consume\" un espacio de: \\(b=(1,518+8+12)*8 =12,304\\,bits\\). En una red FastEthernet (\\(100\\,Mb/s\\)), se pueden enviar: \\[\\frac{100 Mb}{12,304 b} = 8,127\\,p/s\\] (b) \\[\\frac{8\\,127\\times 1,518\\times 8}{100\\,M} = 98.694\\%\\] Problema 2.20 Problema 2.26 (a) El retardo de propagación es de: \\(\\frac{1,000\\, km}{200,000\\,km/s} = 5\\,ms.\\) (b) Suponiendo que se transmiten ventanas completas, pueden enviarse \\(24 \\times 1,024 \\times 8 = 196,608\\,bits\\) antes de recibir un acuse de recibo. El tiempo de transmisión es de: \\[\\frac{196,608 bits}{622\\,Mb/s} = 309\\,\\mu s;\\] La red está limitada en latencia. (c) Se necesita un tiempo de ida y vuelta (RTT) para recibir el acuse de recibo y poder enviar otra ventana. Por consiguiente, el throughput máximo es: \\[\\frac{196,608\\,bits}{0.01\\,s} = 19.7\\,Mb/s\\] (d) La eficiencia es: \\[\\frac{19.7\\,Mb/s}{622\\,Mb/s} = 3.16\\%\\] 8.3 Caracterización de la red Problema 3.1 El baselining permite obtener un punto de referencia contra el cual evaluar el desempeño de la red propuesta. Además permite identificar problemas con la red actual. Básicamente consiste en evaluar el desempeño de la red actual y se realiza mediante las herramientas apropiadas de colección de información (monitores, analizadores, herramientas de administración, etc.). Las principales dificultades para este tipo de estudio son la definición de un período y frecuencia de recolección apropiados. Problema 3.7 La congestión es una degradación en el rendimiento debido a un exceso de paquetes en la red o en un segmento de ésta. Para contenerla, se pueden usar mecanismos como: (a) de lazo abierto.: La fuente es responsable de no emitir más paquetes que los convenidos con el proveedor a fin de que el dimensionamiento estimado cumpla con lo previsto (traffic engineering). Mecanismos típicos para conformar el tráfico a lo convenido son Leaky bucket y Token bucket. (b) de lazo cerrado en los extremos.: El extremo receptor monitorea la calidad de la información recibida (p.e. pérdidas de paquetes) y notifica a la fuente. Si se detectan pérdidas, la fuente reduce su tasa de transmisión. Ejemplos: control de congestión en TCP; mecanismo RTP/RTCP. (c) reactivo en los nodos de conmutación.: Al detectar congestión, los nodos envían notificaciones a los puntos extremos. Ejemplos: FECN, BECN en Frame Relay; mensajes Source Quench, mecanismo ECN en TCP/IP. Problema 3.9 El control de congestión de TCP se basa en un mecanismo de ventanas deslizantes: en un momento dado, se puede enviar hasta una ventana de información sin haber recibido los acuses de recibo del destino. Cuando la latencia es muy grande como en una red satelital, y/o cuando el ancho de banda es muy grande como una red nacional a velocidades de gigabits por segundo, el tamaño de la ventana puede resultar demasiado pequeño para llenar el ducto de comunicación entre la fuente y el destino con información en tránsito. Si esto ocurre, la fuente debe detener su emisión, degradando la eficiencia de la red. El RFC-1323 propone varias extensiones a TCP para tratar este problema. La principal de ellas es el uso de ventanas mayores al tamaño estándar de 64kBytes. Junto con esta extensión, se proponen mecanismos para medir con mayor precisión el RTT de la conexión y protecciones contra el eventual reciclado de números de secuencia. Problema 3.17 Muchos estudios recientes han mostrado que el tráfico generado por las aplicaciones de red se desvían considerablemente de un proceso de Poisson. Un modelo más apropiado para el tráfico de red parece requerir distribuciones con cola larga como la distribución Pareto. Algo que aparentemente puede ser modelado por Poisson son los procesos humanos. En VoIP, el número de inicios de llamada en un intervalo de tiempo podría ser Poisson y la duración de una llamada podría ser exponencial, pero la generación de paquetes dentro de una llamada es muy probable que no pueda ser un proceso de Poisson. 8.4 Diseño lógico Problema 4.2 Firewall: en la capa de distribución; VLANs: en de distribución y de acceso, depende de la complejidad de la red; Mecanismo de despacho de colas: en el núcleo para implementar PHBs. Si la red es muy grande, tal vez se requieran también en las otras dos capas. Problema 4.5 NODO K=3 Vecinos Ocurrencias 1 2, 5, 6 1 2 3, 4, 5 6 3 2, 4, 5 3 4 2, 3, 5 6 5 2, 4, 6 7 6 2, 4, 5 5 7 5, 6, 8 4 8 4, 6, 7 4 9 7, 8, 10 2 10 7, 8, 9 2 Frecuencia Repeticiones 1 1 2 2 3 1 4 2 5 1 6 2 7 1 \\[\\bar v = \\Big\\lfloor\\frac{\\underset{j=1}{\\overset{F}\\Sigma} S_j\\times j}{N}\\Big\\rfloor+1 = \\frac{1+4+3+8+5+12+7}{10}= 4\\] Los mejores candidatos son aquéllos \\(&gt;\\bar v\\), es decir, \\(2, 4, 5, 6\\) Problema 4.8 Problema 4.10 Existen varias soluciones, entre otras: Problema 4.15 8.5 Administración de Redes Problema 5.1 Gestión de fallas.: Se encarga de localizar, aislar y corregir problemas en la red. Gestión de configuración.: Es el proceso de obtener datos e información de la red y utilizarlos para gestionar la configuración de los diferentes dispositivos. Gestión de seguridad.: La gestión de seguridad no se limita a los mecanismos de seguridad (protocolos, mecanismos de encripción, etc.) sino a toda la política de seguridad que debe implantarse: administración de contraseñas; responsabilidades de los usuarios; seguridad de acceso físico; etcétera. Gestión de rendimiento.: Garantizar el acceso contínuo y eficiente a la red mediante el monitoreo de los dispositivos de red y sus enlaces asociados para determinar su utilización, niveles de error, etcétera. Gestión contable.: Almacena y procesa datos referentes al consumo de los recursos de la red. Esta información puede ser utilizada para fines de cobro y también como apoyo para planear la capacidad y/o detectar fallas. Problema 5.5 Retiene las mejores propuestas de la versión 2 en cuanto a rendimiento (GetBulk, Inform, contadores &gt; 64 bits) y la comunicación administrador - administrador. Unifica los mecanismos de seguridad: encripción y autenticación. Incorpora mecanismos de administración de agentes. Define relaciones entre objetos. Proporciona más flexibilidad para definir el protocolo de transporte. Problema 5.6 02 03 FE 3A 04 // int x = 0xFE3A04; 09 02 &lt;1.23&gt; 09 02 &lt;4.0&gt; // float y[2] = {1.23, 4.0}; 16 16 // struct { 28 11 &#39;L&#39;&#39;u&#39;&#39;i&#39;&#39;s&#39;&#39; &#39;&#39;F&#39;&#39;e&#39;&#39;l&#39;&#39;i&#39;&#39;p&#39;&#39;e&#39; //char nombre =``Luis Felipe&#39;&#39;; 02 01 19 // int edad = 25; 01 01 00 //boolean casado = 0; } status; 28 01 &#39;K&#39; //char seccion = &#39;K&#39;; "]]
